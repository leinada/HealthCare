{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction of diabetes\n",
    "\n",
    "The goal is to predict the onset of diabetes in Pima Indians within five years using different  ML techniques.\n",
    "\n",
    "- Logitic regression (preprocessing, classification report, ROC curve)\n",
    "- Keras (Grid search on batch size, number of epochs, learning rate, dropout rate\n",
    ", diferent kernels, activation functions, number of neurons in each hidden layer)\n",
    "\n",
    "Original research paper [here ](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2245318/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.6.7 | packaged by conda-forge | (default, Nov 21 2018, 02:32:25) \n",
      "[GCC 4.8.2 20140120 (Red Hat 4.8.2-15)]\n"
     ]
    }
   ],
   "source": [
    "#Check Python Version\n",
    "import sys\n",
    "import scipy\n",
    "import sklearn\n",
    "import keras\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "print('Python: {}'.format(sys.version))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection \n",
    "from sklearn.model_selection  import cross_validate, GridSearchCV, train_test_split, KFold, StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_preg</th>\n",
       "      <th>glucose</th>\n",
       "      <th>BP</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_preg  glucose  BP  SkinThickness  Insulin   BMI  \\\n",
       "0       6      148  72             35        0  33.6   \n",
       "1       1       85  66             29        0  26.6   \n",
       "2       8      183  64              0        0  23.3   \n",
       "3       1       89  66             23       94  28.1   \n",
       "4       0      137  40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('diabetes.csv', sep=\",\", header=None)\n",
    "df.columns=['n_preg', 'glucose', 'BP','SkinThickness','Insulin','BMI','DiabetesPedigreeFunction','Age','Outcome']\n",
    "df.head()\n",
    "#outcome 1= diabetes, 0= no diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_preg</th>\n",
       "      <th>glucose</th>\n",
       "      <th>BP</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           n_preg     glucose          BP  SkinThickness     Insulin  \\\n",
       "count  768.000000  768.000000  768.000000     768.000000  768.000000   \n",
       "mean     3.845052  120.894531   69.105469      20.536458   79.799479   \n",
       "std      3.369578   31.972618   19.355807      15.952218  115.244002   \n",
       "min      0.000000    0.000000    0.000000       0.000000    0.000000   \n",
       "25%      1.000000   99.000000   62.000000       0.000000    0.000000   \n",
       "50%      3.000000  117.000000   72.000000      23.000000   30.500000   \n",
       "75%      6.000000  140.250000   80.000000      32.000000  127.250000   \n",
       "max     17.000000  199.000000  122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  768.000000                768.000000  768.000000  768.000000  \n",
       "mean    31.992578                  0.471876   33.240885    0.348958  \n",
       "std      7.884160                  0.331329   11.760232    0.476951  \n",
       "min      0.000000                  0.078000   21.000000    0.000000  \n",
       "25%     27.300000                  0.243750   24.000000    0.000000  \n",
       "50%     32.000000                  0.372500   29.000000    0.000000  \n",
       "75%     36.600000                  0.626250   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there (look at min) are couple of zero values in glucose, BP, SkinTHickness, Insulin and BMI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot histograms for each variable\n",
    "df.hist(figsize = (15, 15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Outcome\n",
       "0    500\n",
       "1    268\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"Outcome\").size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know that there are 768 people with an uneven distribution of the outcome (healthy:sick = 500:268)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      "n_preg                      768 non-null int64\n",
      "glucose                     768 non-null int64\n",
      "BP                          768 non-null int64\n",
      "SkinThickness               768 non-null int64\n",
      "Insulin                     768 non-null int64\n",
      "BMI                         768 non-null float64\n",
      "DiabetesPedigreeFunction    768 non-null float64\n",
      "Age                         768 non-null int64\n",
      "Outcome                     768 non-null int64\n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data\n",
    "There seems to be several zero values for couple of columns.\n",
    "In order to find the zero value, let us firts convert the zeros to nans "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_preg</th>\n",
       "      <th>glucose</th>\n",
       "      <th>BP</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>125</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.232</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>7</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.305</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.304</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>2</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.102</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>75</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.572</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>64</td>\n",
       "      <td>23</td>\n",
       "      <td>89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.731</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.256</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.174</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>6</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.189</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>5</td>\n",
       "      <td>136</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.640</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>10</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.261</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     n_preg  glucose  BP  SkinThickness  Insulin  BMI  \\\n",
       "9         8      125  96              0        0  0.0   \n",
       "49        7      105   0              0        0  0.0   \n",
       "60        2       84   0              0        0  0.0   \n",
       "81        2       74   0              0        0  0.0   \n",
       "145       0      102  75             23        0  0.0   \n",
       "371       0      118  64             23       89  0.0   \n",
       "426       0       94   0              0        0  0.0   \n",
       "494       3       80   0              0        0  0.0   \n",
       "522       6      114   0              0        0  0.0   \n",
       "684       5      136  82              0        0  0.0   \n",
       "706      10      115   0              0        0  0.0   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "9                       0.232   54        1  \n",
       "49                      0.305   24        0  \n",
       "60                      0.304   21        0  \n",
       "81                      0.102   22        0  \n",
       "145                     0.572   21        0  \n",
       "371                     1.731   21        0  \n",
       "426                     0.256   25        0  \n",
       "494                     0.174   22        0  \n",
       "522                     0.189   26        0  \n",
       "684                     0.640   69        0  \n",
       "706                     0.261   30        1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example\n",
    "df[df['BMI'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "n_preg                      0\n",
       "glucose                     0\n",
       "BP                          0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Age                         0\n",
       "Outcome                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_fields = ['glucose', 'BP', 'SkinThickness', 'Insulin', 'BMI']\n",
    "for col in zero_fields:\n",
    "    df[col].replace(0, np.NaN, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "n_preg                        0\n",
       "glucose                       5\n",
       "BP                           35\n",
       "SkinThickness               227\n",
       "Insulin                     374\n",
       "BMI                          11\n",
       "DiabetesPedigreeFunction      0\n",
       "Age                           0\n",
       "Outcome                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the nan values, so we know how many zeros are there\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it looks like 5 glucose values, 35 BP values, 227 SkinThickness and 374 insulin values and 11 BMI values are \n",
    "zero (others columns can be legitimately zero, so we don't want to  touch those)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nozeros = df.copy() \n",
    "df[zero_fields] = df[zero_fields].fillna(df_nozeros.mean()) #fill na with mean values from the non zero dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_preg</th>\n",
       "      <th>glucose</th>\n",
       "      <th>BP</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>121.686763</td>\n",
       "      <td>72.405184</td>\n",
       "      <td>29.153420</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>32.457464</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>30.435949</td>\n",
       "      <td>12.096346</td>\n",
       "      <td>8.790942</td>\n",
       "      <td>85.021108</td>\n",
       "      <td>6.875151</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>18.200000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.750000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>121.500000</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.202592</td>\n",
       "      <td>29.153420</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>32.400000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           n_preg     glucose          BP  SkinThickness     Insulin  \\\n",
       "count  768.000000  768.000000  768.000000     768.000000  768.000000   \n",
       "mean     3.845052  121.686763   72.405184      29.153420  155.548223   \n",
       "std      3.369578   30.435949   12.096346       8.790942   85.021108   \n",
       "min      0.000000   44.000000   24.000000       7.000000   14.000000   \n",
       "25%      1.000000   99.750000   64.000000      25.000000  121.500000   \n",
       "50%      3.000000  117.000000   72.202592      29.153420  155.548223   \n",
       "75%      6.000000  140.250000   80.000000      32.000000  155.548223   \n",
       "max     17.000000  199.000000  122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  768.000000                768.000000  768.000000  768.000000  \n",
       "mean    32.457464                  0.471876   33.240885    0.348958  \n",
       "std      6.875151                  0.331329   11.760232    0.476951  \n",
       "min     18.200000                  0.078000   21.000000    0.000000  \n",
       "25%     27.500000                  0.243750   24.000000    0.000000  \n",
       "50%     32.400000                  0.372500   29.000000    0.000000  \n",
       "75%     36.600000                  0.626250   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratify data\n",
    "\n",
    "Our usual test_train_split may not be appropriate here (we already have a imbalanced data set), the split might lead to more biased sets. Thus we stratify the data, so that we have proportionate data for all the classes in both the training and testing data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "# Create X and Y datasets for training\n",
    "X_full = np.array(df.drop(['Outcome'], 1))\n",
    "y_full = np.array(df['Outcome']).astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_full, y_full, test_size=0.2,random_state=0, stratify=df['Outcome'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let us start with  logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on test data: 0.7792207792207793\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train,y_train)\n",
    "LR_prediction = model.predict(X_test)\n",
    "print('Model accuracy on test data: {}'.format(accuracy_score(y_test, LR_prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on toy model: 0.6493506493506493\n"
     ]
    }
   ],
   "source": [
    "#let us check with the null accuracy (where a toy model always predicts the most frequent class)\n",
    "\n",
    "median_outcome = df['Outcome'].median()\n",
    "toymodel_prediction = [median_outcome for i in range(len(y_test))]\n",
    "print('Model accuracy on toy model: {}'.format(accuracy_score(y_test, toymodel_prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that a toy model (with out any real predictive power) that always predicts 0 would be right about 65%\n",
    "of the time. Hence accuracy may not be the best metric to evaluate success here. This is where confusion matrix come to play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[89, 11],\n",
       "       [23, 31]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, LR_prediction) #confusion matrix\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted ');ax.set_ylabel('Actual'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['0 (=no diabetes)', '1 (=diabetes)']); ax.yaxis.set_ticklabels(['0 (=no diabetes)',\n",
    "                                                                                         '1 (=diabetes)']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 31 True Positives (TP): we correctly predicted that they do have diabetes\n",
    "- 89 True Negatives (TN): we correctly predicted that they don't have diabetes\n",
    "- 11 False Positives (FP): we incorrectly predicted that they do have diabetes, but they don't\n",
    "   - (a \"Type I error\")\n",
    "- 23 False Negatives (FN): we incorrectly predicted that they don't have diabetes, but they do have\n",
    "   - (a \"Type II error\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Accuracy = TP+TN/(TP+TN+FP+FN)\n",
    "- Precision (Positive predictive value) = TP/(TP+FP)\n",
    "- Sensitivity (Recall) = TP/(TP+FN)\n",
    "- Specificity (1- false_positive_rate) = TN/(TN+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.7792207792207793\n",
      "Sensitivity :  0.89\n",
      "Specificity :  0.5740740740740741\n"
     ]
    }
   ],
   "source": [
    "total=sum(sum(cm))\n",
    "accuracy=(cm[0,0]+cm[1,1])/total\n",
    "print ('Accuracy : ', accuracy)\n",
    "\n",
    "sensitivity = cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "print('Sensitivity : ', sensitivity )\n",
    "\n",
    "specificity = cm[1,1]/(cm[1,0]+cm[1,1])\n",
    "print('Specificity : ', specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.89      0.84       100\n",
      "           1       0.74      0.57      0.65        54\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       154\n",
      "   macro avg       0.77      0.73      0.74       154\n",
      "weighted avg       0.77      0.78      0.77       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, LR_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Classification Threshold\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first 10 predicted responses\n",
    "model.predict(X_test)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.95593318, 0.04406682],\n",
       "       [0.92341606, 0.07658394],\n",
       "       [0.93603268, 0.06396732],\n",
       "       [0.61921185, 0.38078815],\n",
       "       [0.32641037, 0.67358963],\n",
       "       [0.9018689 , 0.0981311 ],\n",
       "       [0.32813477, 0.67186523],\n",
       "       [0.93921266, 0.06078734],\n",
       "       [0.87234832, 0.12765168],\n",
       "       [0.69217106, 0.30782894]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first 10 predicted probabilities of class membership\n",
    "model.predict_proba(X_test)[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, there are 2 columns for 2 classes ('Outcome' = 0 and 'Outcome' = 1)\n",
    "\n",
    "By default the classification threshold = 0.5 and model choose the class with the highest probability. Class 1 is predicted if probability > 0.5 and Class 0 is predicted if probability < 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# histogram of predicted probabilities\n",
    "save_predictions_proba = model.predict_proba(X_test)[:, 1]  # column 1\n",
    "plt.hist(save_predictions_proba, bins=10)\n",
    "plt.xlim(0,1) # x-axis limit from 0 to 1\n",
    "plt.title('Histogram of predicted probabilities')\n",
    "plt.xlabel('Predicted probability for diabetes')\n",
    "plt.grid()\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If  we want to increase the sensitivity , we need to increase TP and  this means we need to reduce the classification threshold \n",
    "from 0.5 to a lower number (this implies more patients with predicted probabilty for diabetes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Receiver Operating Characteristic (ROC) Curves\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fd7f5e3e048>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# function roc_curve\n",
    "# input: IMPORTANT: first argument is true values, \n",
    "#                   second argument is predicted probabilities\n",
    "#                   we do not use y_pred_class, because it will give incorrect results without \n",
    "#                   generating an error\n",
    "# output: FPR, TPR, thresholds\n",
    "# FPR: false positive rate\n",
    "# TPR: true positive rate\n",
    "#######\n",
    "##AUC AUC is the percentage of the ROC plot that is underneath the curve\n",
    "# Higher AUC = better classifier\n",
    "\n",
    "FPR, TPR, thresholds = roc_curve(y_test, save_predictions_proba)\n",
    "\n",
    "plt.figure(figsize=(10,5))  \n",
    "plt.plot(FPR, TPR)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')  # 50%  \n",
    "plt.plot(FPR, TPR, lw=2, label='Logistic Regression (AUC = %0.2f)' % auc(FPR, TPR))\n",
    "plt.title('ROC curve for diabetes classifier')\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.grid(True)\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ROC curve can help you to choose a threshold that balances sensitivity and specificity in a way that makes sense for our context. We can't actually see the thresholds used to generate the curve on the ROC curve itself. However, the function and plot below shows it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fd7f5e10908>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spec = []\n",
    "sens = []\n",
    "thres = []\n",
    "\n",
    "threshold = 0.00\n",
    "for x in range(0, 90):\n",
    "    thres.append(threshold)\n",
    "    sens.append(TPR[thresholds > threshold][-1])\n",
    "    spec.append(1 - FPR[thresholds > threshold][-1])\n",
    "    threshold += 0.01\n",
    "    \n",
    "plt.plot(thres, sens, lw=2, label='Sensitivity')\n",
    "plt.plot(thres, spec, lw=2, label='Specificity')\n",
    "ax = plt.gca()\n",
    "ax.set_xticks(np.arange(0, 1, 0.1))\n",
    "ax.set_yticks(np.arange(0, 1, 0.1))\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.title('Sensitivity vs. Specificity')\n",
    "plt.xlabel('Threshold')\n",
    "plt.grid(True)\n",
    "plt.legend(loc=\"center right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above plots means a classification threshold of 0.35, we get a sensitivity and specificity of about 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on test data: 0.8051948051948052\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(X_train,y_train)\n",
    "xgb_prediction = model.predict(X_test)\n",
    "print('Model accuracy on test data: {}'.format(accuracy_score(y_test, xgb_prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.055      0.17333333 0.08333334 0.07       0.10333333 0.19666667\n",
      " 0.18833333 0.13      ]\n"
     ]
    }
   ],
   "source": [
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb.plot_importance(model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning XGBmodel parameters\n",
    "\n",
    "Note: \n",
    "\n",
    "Learning rate or shrinkage (learning_rate in XGBoost) should be set to 0.1 or lower , and smaller values will require the addition of more trees. The depth of trees (tree_depth in XGBoost) should be configured in the range \n",
    "of 2-to-8, where not much benefit is seen with deeper trees.  Row sampling (subsample in XGBoost) should be configured in the range of 30% to 80% of the training dataset, and compared to a value of 100% for no sampling.\n",
    "The scikit-learn framework provides the capability to search combinations of parameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.500367 using {'learning_rate': 0.1}\n",
      "-0.539876 (0.032551) with: {'learning_rate': 0.01}\n",
      "-0.500367 (0.078253) with: {'learning_rate': 0.1}\n",
      "-0.550088 (0.104767) with: {'learning_rate': 0.2}\n",
      "-0.587154 (0.127509) with: {'learning_rate': 0.3}\n",
      "-0.665030 (0.142283) with: {'learning_rate': 0.4}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lr = [0.01, 0.1, 0.2, 0.3, 0.4] #learning rate\n",
    "#md=[2,3,4,5,6] # depth\n",
    "#ne= [10,15,50,75,100] #n_estimators is how many round of boosting\n",
    "\n",
    "#param_grid = dict(learning_rate=lr,max_depth=md,n_estimators=ne)\n",
    "param_grid = dict(learning_rate=lr)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "model = XGBClassifier()\n",
    "grid_search = GridSearchCV(model, param_grid, scoring=\"neg_log_loss\", cv=kfold)\n",
    "grid_result = grid_search.fit(X_train,y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on test data: 0.8051948051948052\n"
     ]
    }
   ],
   "source": [
    "#now us the best learning rate and change the metric to accuracy\n",
    "\n",
    "#model = XGBClassifier(learning_rate=0.1,max_depth=2, n_estimators=75)\n",
    "model = XGBClassifier(learning_rate=0.1)\n",
    "model.fit(X_train,y_train)\n",
    "xgb_prediction = model.predict(X_test)\n",
    "print('Model accuracy on test data: {}'.format(accuracy_score(y_test, xgb_prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  KERAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data using sklearn StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler().fit(X_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n"
     ]
    }
   ],
   "source": [
    "print(scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.680000e+02</td>\n",
       "      <td>7.680000e+02</td>\n",
       "      <td>7.680000e+02</td>\n",
       "      <td>7.680000e+02</td>\n",
       "      <td>7.680000e+02</td>\n",
       "      <td>7.680000e+02</td>\n",
       "      <td>7.680000e+02</td>\n",
       "      <td>7.680000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.544261e-17</td>\n",
       "      <td>-3.301757e-16</td>\n",
       "      <td>6.966722e-16</td>\n",
       "      <td>6.866252e-16</td>\n",
       "      <td>-2.352033e-16</td>\n",
       "      <td>3.090699e-16</td>\n",
       "      <td>2.398978e-16</td>\n",
       "      <td>1.857600e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000652e+00</td>\n",
       "      <td>1.000652e+00</td>\n",
       "      <td>1.000652e+00</td>\n",
       "      <td>1.000652e+00</td>\n",
       "      <td>1.000652e+00</td>\n",
       "      <td>1.000652e+00</td>\n",
       "      <td>1.000652e+00</td>\n",
       "      <td>1.000652e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.141852e+00</td>\n",
       "      <td>-2.554131e+00</td>\n",
       "      <td>-4.004245e+00</td>\n",
       "      <td>-2.521670e+00</td>\n",
       "      <td>-1.665945e+00</td>\n",
       "      <td>-2.075119e+00</td>\n",
       "      <td>-1.189553e+00</td>\n",
       "      <td>-1.041549e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-8.448851e-01</td>\n",
       "      <td>-7.212214e-01</td>\n",
       "      <td>-6.953060e-01</td>\n",
       "      <td>-4.727737e-01</td>\n",
       "      <td>-4.007289e-01</td>\n",
       "      <td>-7.215397e-01</td>\n",
       "      <td>-6.889685e-01</td>\n",
       "      <td>-7.862862e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-2.509521e-01</td>\n",
       "      <td>-1.540881e-01</td>\n",
       "      <td>-1.675912e-02</td>\n",
       "      <td>8.087936e-16</td>\n",
       "      <td>-3.345079e-16</td>\n",
       "      <td>-8.363615e-03</td>\n",
       "      <td>-3.001282e-01</td>\n",
       "      <td>-3.608474e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.399473e-01</td>\n",
       "      <td>6.103090e-01</td>\n",
       "      <td>6.282695e-01</td>\n",
       "      <td>3.240194e-01</td>\n",
       "      <td>-3.345079e-16</td>\n",
       "      <td>6.029301e-01</td>\n",
       "      <td>4.662269e-01</td>\n",
       "      <td>6.602056e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.906578e+00</td>\n",
       "      <td>2.541850e+00</td>\n",
       "      <td>4.102655e+00</td>\n",
       "      <td>7.950467e+00</td>\n",
       "      <td>8.126238e+00</td>\n",
       "      <td>5.042087e+00</td>\n",
       "      <td>5.883565e+00</td>\n",
       "      <td>4.063716e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0             1             2             3             4  \\\n",
       "count  7.680000e+02  7.680000e+02  7.680000e+02  7.680000e+02  7.680000e+02   \n",
       "mean   2.544261e-17 -3.301757e-16  6.966722e-16  6.866252e-16 -2.352033e-16   \n",
       "std    1.000652e+00  1.000652e+00  1.000652e+00  1.000652e+00  1.000652e+00   \n",
       "min   -1.141852e+00 -2.554131e+00 -4.004245e+00 -2.521670e+00 -1.665945e+00   \n",
       "25%   -8.448851e-01 -7.212214e-01 -6.953060e-01 -4.727737e-01 -4.007289e-01   \n",
       "50%   -2.509521e-01 -1.540881e-01 -1.675912e-02  8.087936e-16 -3.345079e-16   \n",
       "75%    6.399473e-01  6.103090e-01  6.282695e-01  3.240194e-01 -3.345079e-16   \n",
       "max    3.906578e+00  2.541850e+00  4.102655e+00  7.950467e+00  8.126238e+00   \n",
       "\n",
       "                  5             6             7  \n",
       "count  7.680000e+02  7.680000e+02  7.680000e+02  \n",
       "mean   3.090699e-16  2.398978e-16  1.857600e-16  \n",
       "std    1.000652e+00  1.000652e+00  1.000652e+00  \n",
       "min   -2.075119e+00 -1.189553e+00 -1.041549e+00  \n",
       "25%   -7.215397e-01 -6.889685e-01 -7.862862e-01  \n",
       "50%   -8.363615e-03 -3.001282e-01 -3.608474e-01  \n",
       "75%    6.029301e-01  4.662269e-01  6.602056e-01  \n",
       "max    5.042087e+00  5.883565e+00  4.063716e+00  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform and display the training data\n",
    "X_standardized = scaler.transform(X_full)\n",
    "\n",
    "data_train = pd.DataFrame(X_standardized)\n",
    "data_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 113\n",
      "Trainable params: 113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define a random seed\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Start defining the model\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim = 8, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(4, input_dim = 8, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # compile the model\n",
    "    adam = Adam(lr = 0.01)\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = adam, metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "512/512 [==============================] - 0s 559us/step - loss: 0.6498 - acc: 0.7383\n",
      "Epoch 2/10\n",
      "512/512 [==============================] - 0s 122us/step - loss: 0.5734 - acc: 0.7715\n",
      "Epoch 3/10\n",
      "512/512 [==============================] - 0s 134us/step - loss: 0.5352 - acc: 0.7676\n",
      "Epoch 4/10\n",
      "512/512 [==============================] - 0s 126us/step - loss: 0.5128 - acc: 0.7734\n",
      "Epoch 5/10\n",
      "512/512 [==============================] - 0s 132us/step - loss: 0.5005 - acc: 0.7812\n",
      "Epoch 6/10\n",
      "512/512 [==============================] - 0s 123us/step - loss: 0.4948 - acc: 0.7754\n",
      "Epoch 7/10\n",
      "512/512 [==============================] - 0s 122us/step - loss: 0.4852 - acc: 0.7832\n",
      "Epoch 8/10\n",
      "512/512 [==============================] - 0s 120us/step - loss: 0.4774 - acc: 0.7637\n",
      "Epoch 9/10\n",
      "512/512 [==============================] - 0s 127us/step - loss: 0.4760 - acc: 0.7773\n",
      "Epoch 10/10\n",
      "512/512 [==============================] - 0s 121us/step - loss: 0.4662 - acc: 0.7871\n",
      "256/256 [==============================] - 0s 175us/step\n",
      "512/512 [==============================] - 0s 69us/step\n",
      "[CV]  batch_size=10, epochs=10, score=0.7460937558207661, total=   1.4s\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "512/512 [==============================] - 0s 537us/step - loss: 0.6061 - acc: 0.6914\n",
      "Epoch 2/10\n",
      "512/512 [==============================] - 0s 115us/step - loss: 0.4748 - acc: 0.7734\n",
      "Epoch 3/10\n",
      "512/512 [==============================] - 0s 130us/step - loss: 0.4514 - acc: 0.7852\n",
      "Epoch 4/10\n",
      "512/512 [==============================] - 0s 126us/step - loss: 0.4416 - acc: 0.7832\n",
      "Epoch 5/10\n",
      "512/512 [==============================] - 0s 118us/step - loss: 0.4419 - acc: 0.7812\n",
      "Epoch 6/10\n",
      "512/512 [==============================] - 0s 129us/step - loss: 0.4320 - acc: 0.7734\n",
      "Epoch 7/10\n",
      "512/512 [==============================] - 0s 122us/step - loss: 0.4286 - acc: 0.7832\n",
      "Epoch 8/10\n",
      "512/512 [==============================] - 0s 122us/step - loss: 0.4253 - acc: 0.7832\n",
      "Epoch 9/10\n",
      "512/512 [==============================] - 0s 124us/step - loss: 0.4243 - acc: 0.7930\n",
      "Epoch 10/10\n",
      "512/512 [==============================] - 0s 133us/step - loss: 0.4193 - acc: 0.7969\n",
      "256/256 [==============================] - 0s 226us/step\n",
      "512/512 [==============================] - 0s 70us/step\n",
      "[CV]  batch_size=10, epochs=10, score=0.7578124974388629, total=   1.3s\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "512/512 [==============================] - 0s 569us/step - loss: 0.5920 - acc: 0.6387\n",
      "Epoch 2/10\n",
      "512/512 [==============================] - 0s 112us/step - loss: 0.5222 - acc: 0.7012\n",
      "Epoch 3/10\n",
      "512/512 [==============================] - 0s 121us/step - loss: 0.5092 - acc: 0.7637\n",
      "Epoch 4/10\n",
      "512/512 [==============================] - 0s 116us/step - loss: 0.4939 - acc: 0.7676\n",
      "Epoch 5/10\n",
      "512/512 [==============================] - 0s 124us/step - loss: 0.4864 - acc: 0.7715\n",
      "Epoch 6/10\n",
      "512/512 [==============================] - 0s 121us/step - loss: 0.4784 - acc: 0.7656\n",
      "Epoch 7/10\n",
      "512/512 [==============================] - 0s 118us/step - loss: 0.4768 - acc: 0.7754\n",
      "Epoch 8/10\n",
      "512/512 [==============================] - 0s 122us/step - loss: 0.4690 - acc: 0.7793\n",
      "Epoch 9/10\n",
      "512/512 [==============================] - 0s 121us/step - loss: 0.4652 - acc: 0.7754\n",
      "Epoch 10/10\n",
      "512/512 [==============================] - 0s 124us/step - loss: 0.4615 - acc: 0.7891\n",
      "256/256 [==============================] - 0s 253us/step\n",
      "512/512 [==============================] - 0s 76us/step\n",
      "[CV]  batch_size=10, epochs=10, score=0.7929687476716936, total=   1.4s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    4.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "512/512 [==============================] - 0s 590us/step - loss: 0.5506 - acc: 0.7051\n",
      "Epoch 2/50\n",
      "512/512 [==============================] - 0s 123us/step - loss: 0.4572 - acc: 0.7754\n",
      "Epoch 3/50\n",
      "512/512 [==============================] - 0s 122us/step - loss: 0.4414 - acc: 0.7949\n",
      "Epoch 4/50\n",
      "512/512 [==============================] - 0s 119us/step - loss: 0.4339 - acc: 0.7988\n",
      "Epoch 5/50\n",
      "512/512 [==============================] - 0s 126us/step - loss: 0.4237 - acc: 0.8027\n",
      "Epoch 6/50\n",
      "512/512 [==============================] - 0s 130us/step - loss: 0.4292 - acc: 0.8086\n",
      "Epoch 7/50\n",
      "512/512 [==============================] - 0s 137us/step - loss: 0.4178 - acc: 0.8086\n",
      "Epoch 8/50\n",
      "512/512 [==============================] - 0s 118us/step - loss: 0.4145 - acc: 0.8086\n",
      "Epoch 9/50\n",
      "512/512 [==============================] - 0s 116us/step - loss: 0.4136 - acc: 0.8164\n",
      "Epoch 10/50\n",
      "512/512 [==============================] - 0s 115us/step - loss: 0.4150 - acc: 0.8105\n",
      "Epoch 11/50\n",
      "512/512 [==============================] - 0s 123us/step - loss: 0.4144 - acc: 0.7969\n",
      "Epoch 12/50\n",
      "512/512 [==============================] - 0s 116us/step - loss: 0.4056 - acc: 0.8164\n",
      "Epoch 13/50\n",
      "512/512 [==============================] - 0s 117us/step - loss: 0.3982 - acc: 0.8320\n",
      "Epoch 14/50\n",
      "512/512 [==============================] - 0s 148us/step - loss: 0.4007 - acc: 0.8223\n",
      "Epoch 15/50\n",
      "512/512 [==============================] - 0s 145us/step - loss: 0.3954 - acc: 0.8164\n",
      "Epoch 16/50\n",
      "512/512 [==============================] - 0s 146us/step - loss: 0.3942 - acc: 0.8242\n",
      "Epoch 17/50\n",
      "512/512 [==============================] - 0s 131us/step - loss: 0.3901 - acc: 0.8125\n",
      "Epoch 18/50\n",
      "512/512 [==============================] - 0s 152us/step - loss: 0.3963 - acc: 0.8203\n",
      "Epoch 19/50\n",
      "512/512 [==============================] - 0s 139us/step - loss: 0.3882 - acc: 0.8223\n",
      "Epoch 20/50\n",
      "512/512 [==============================] - 0s 134us/step - loss: 0.3927 - acc: 0.8105\n",
      "Epoch 21/50\n",
      "512/512 [==============================] - 0s 126us/step - loss: 0.3888 - acc: 0.8203\n",
      "Epoch 22/50\n",
      "512/512 [==============================] - 0s 138us/step - loss: 0.3835 - acc: 0.8262\n",
      "Epoch 23/50\n",
      "512/512 [==============================] - 0s 132us/step - loss: 0.3856 - acc: 0.8125\n",
      "Epoch 24/50\n",
      "512/512 [==============================] - 0s 141us/step - loss: 0.3821 - acc: 0.8320\n",
      "Epoch 25/50\n",
      "512/512 [==============================] - 0s 133us/step - loss: 0.3727 - acc: 0.8242\n",
      "Epoch 26/50\n",
      "512/512 [==============================] - 0s 137us/step - loss: 0.3785 - acc: 0.8320\n",
      "Epoch 27/50\n",
      "512/512 [==============================] - 0s 133us/step - loss: 0.3740 - acc: 0.8301\n",
      "Epoch 28/50\n",
      "512/512 [==============================] - 0s 153us/step - loss: 0.3684 - acc: 0.8359\n",
      "Epoch 29/50\n",
      "512/512 [==============================] - 0s 150us/step - loss: 0.3710 - acc: 0.8281\n",
      "Epoch 30/50\n",
      "512/512 [==============================] - 0s 143us/step - loss: 0.3686 - acc: 0.8262\n",
      "Epoch 31/50\n",
      "512/512 [==============================] - 0s 140us/step - loss: 0.3676 - acc: 0.8398\n",
      "Epoch 32/50\n",
      "512/512 [==============================] - 0s 135us/step - loss: 0.3629 - acc: 0.8398\n",
      "Epoch 33/50\n",
      "512/512 [==============================] - 0s 139us/step - loss: 0.3656 - acc: 0.8301\n",
      "Epoch 34/50\n",
      "512/512 [==============================] - 0s 136us/step - loss: 0.3648 - acc: 0.8242\n",
      "Epoch 35/50\n",
      "512/512 [==============================] - 0s 150us/step - loss: 0.3550 - acc: 0.8418\n",
      "Epoch 36/50\n",
      "512/512 [==============================] - 0s 143us/step - loss: 0.3576 - acc: 0.8320\n",
      "Epoch 37/50\n",
      "512/512 [==============================] - 0s 132us/step - loss: 0.3552 - acc: 0.8359\n",
      "Epoch 38/50\n",
      "512/512 [==============================] - 0s 129us/step - loss: 0.3545 - acc: 0.8340\n",
      "Epoch 39/50\n",
      "512/512 [==============================] - 0s 133us/step - loss: 0.3495 - acc: 0.8418\n",
      "Epoch 40/50\n",
      "512/512 [==============================] - 0s 128us/step - loss: 0.3460 - acc: 0.8340\n",
      "Epoch 41/50\n",
      "512/512 [==============================] - 0s 135us/step - loss: 0.3445 - acc: 0.8437\n",
      "Epoch 42/50\n",
      "512/512 [==============================] - 0s 144us/step - loss: 0.3445 - acc: 0.8379\n",
      "Epoch 43/50\n",
      "512/512 [==============================] - 0s 143us/step - loss: 0.3458 - acc: 0.8437\n",
      "Epoch 44/50\n",
      "512/512 [==============================] - 0s 131us/step - loss: 0.3426 - acc: 0.8398\n",
      "Epoch 45/50\n",
      "512/512 [==============================] - 0s 145us/step - loss: 0.3395 - acc: 0.8359\n",
      "Epoch 46/50\n",
      "512/512 [==============================] - 0s 136us/step - loss: 0.3465 - acc: 0.8379\n",
      "Epoch 47/50\n",
      "512/512 [==============================] - 0s 123us/step - loss: 0.3377 - acc: 0.8418\n",
      "Epoch 48/50\n",
      "512/512 [==============================] - 0s 135us/step - loss: 0.3294 - acc: 0.8535\n",
      "Epoch 49/50\n",
      "512/512 [==============================] - 0s 144us/step - loss: 0.3395 - acc: 0.8418\n",
      "Epoch 50/50\n",
      "512/512 [==============================] - 0s 147us/step - loss: 0.3317 - acc: 0.8496\n",
      "256/256 [==============================] - 0s 285us/step\n",
      "512/512 [==============================] - 0s 89us/step\n",
      "[CV]  batch_size=10, epochs=50, score=0.7304687490686774, total=   4.2s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    8.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "512/512 [==============================] - 0s 654us/step - loss: 0.5393 - acc: 0.7051\n",
      "Epoch 2/50\n",
      "512/512 [==============================] - 0s 148us/step - loss: 0.4665 - acc: 0.7617\n",
      "Epoch 3/50\n",
      "512/512 [==============================] - 0s 144us/step - loss: 0.4532 - acc: 0.7754\n",
      "Epoch 4/50\n",
      "512/512 [==============================] - 0s 145us/step - loss: 0.4449 - acc: 0.7656\n",
      "Epoch 5/50\n",
      "512/512 [==============================] - 0s 143us/step - loss: 0.4414 - acc: 0.7773\n",
      "Epoch 6/50\n",
      "512/512 [==============================] - 0s 141us/step - loss: 0.4357 - acc: 0.7812\n",
      "Epoch 7/50\n",
      "512/512 [==============================] - 0s 156us/step - loss: 0.4263 - acc: 0.7871\n",
      "Epoch 8/50\n",
      "512/512 [==============================] - 0s 161us/step - loss: 0.4248 - acc: 0.7812\n",
      "Epoch 9/50\n",
      "512/512 [==============================] - 0s 157us/step - loss: 0.4228 - acc: 0.7852\n",
      "Epoch 10/50\n",
      "512/512 [==============================] - 0s 160us/step - loss: 0.4160 - acc: 0.7871\n",
      "Epoch 11/50\n",
      "512/512 [==============================] - 0s 137us/step - loss: 0.4162 - acc: 0.8027\n",
      "Epoch 12/50\n",
      "512/512 [==============================] - 0s 143us/step - loss: 0.4135 - acc: 0.7930\n",
      "Epoch 13/50\n",
      "512/512 [==============================] - 0s 136us/step - loss: 0.4115 - acc: 0.7930\n",
      "Epoch 14/50\n",
      "512/512 [==============================] - 0s 147us/step - loss: 0.4078 - acc: 0.7949\n",
      "Epoch 15/50\n",
      "512/512 [==============================] - 0s 139us/step - loss: 0.4039 - acc: 0.7891\n",
      "Epoch 16/50\n",
      "512/512 [==============================] - 0s 142us/step - loss: 0.4015 - acc: 0.8008\n",
      "Epoch 17/50\n",
      "512/512 [==============================] - 0s 151us/step - loss: 0.4065 - acc: 0.7949\n",
      "Epoch 18/50\n",
      "512/512 [==============================] - 0s 169us/step - loss: 0.4006 - acc: 0.7969\n",
      "Epoch 19/50\n",
      "512/512 [==============================] - 0s 151us/step - loss: 0.4050 - acc: 0.7988\n",
      "Epoch 20/50\n",
      "512/512 [==============================] - 0s 138us/step - loss: 0.3996 - acc: 0.7910\n",
      "Epoch 21/50\n",
      "512/512 [==============================] - 0s 138us/step - loss: 0.3958 - acc: 0.8203\n",
      "Epoch 22/50\n",
      "512/512 [==============================] - 0s 146us/step - loss: 0.4006 - acc: 0.8027\n",
      "Epoch 23/50\n",
      "512/512 [==============================] - 0s 158us/step - loss: 0.3983 - acc: 0.8066\n",
      "Epoch 24/50\n",
      "512/512 [==============================] - 0s 153us/step - loss: 0.4001 - acc: 0.8105\n",
      "Epoch 25/50\n",
      "512/512 [==============================] - 0s 139us/step - loss: 0.3989 - acc: 0.7988\n",
      "Epoch 26/50\n",
      "512/512 [==============================] - 0s 143us/step - loss: 0.3944 - acc: 0.8105\n",
      "Epoch 27/50\n",
      "512/512 [==============================] - 0s 145us/step - loss: 0.3873 - acc: 0.8105\n",
      "Epoch 28/50\n",
      "512/512 [==============================] - 0s 142us/step - loss: 0.3856 - acc: 0.8145\n",
      "Epoch 29/50\n",
      "512/512 [==============================] - 0s 158us/step - loss: 0.3952 - acc: 0.8164\n",
      "Epoch 30/50\n",
      "512/512 [==============================] - 0s 150us/step - loss: 0.3944 - acc: 0.7988\n",
      "Epoch 31/50\n",
      "512/512 [==============================] - 0s 133us/step - loss: 0.3807 - acc: 0.8223\n",
      "Epoch 32/50\n",
      "512/512 [==============================] - 0s 139us/step - loss: 0.3932 - acc: 0.8086\n",
      "Epoch 33/50\n",
      "512/512 [==============================] - 0s 143us/step - loss: 0.3866 - acc: 0.8008\n",
      "Epoch 34/50\n",
      "512/512 [==============================] - 0s 136us/step - loss: 0.3862 - acc: 0.8145\n",
      "Epoch 35/50\n",
      "512/512 [==============================] - 0s 149us/step - loss: 0.3873 - acc: 0.7949\n",
      "Epoch 36/50\n",
      "512/512 [==============================] - 0s 139us/step - loss: 0.3801 - acc: 0.8047\n",
      "Epoch 37/50\n",
      "512/512 [==============================] - 0s 137us/step - loss: 0.3880 - acc: 0.8027\n",
      "Epoch 38/50\n",
      "512/512 [==============================] - 0s 135us/step - loss: 0.3872 - acc: 0.8105\n",
      "Epoch 39/50\n",
      "512/512 [==============================] - 0s 141us/step - loss: 0.3818 - acc: 0.8105\n",
      "Epoch 40/50\n",
      "512/512 [==============================] - 0s 141us/step - loss: 0.3846 - acc: 0.8008\n",
      "Epoch 41/50\n",
      "512/512 [==============================] - 0s 138us/step - loss: 0.3747 - acc: 0.8125\n",
      "Epoch 42/50\n",
      "512/512 [==============================] - 0s 148us/step - loss: 0.3773 - acc: 0.8164\n",
      "Epoch 43/50\n",
      "512/512 [==============================] - 0s 138us/step - loss: 0.3800 - acc: 0.8066\n",
      "Epoch 44/50\n",
      "512/512 [==============================] - 0s 140us/step - loss: 0.3764 - acc: 0.8066\n",
      "Epoch 45/50\n",
      "512/512 [==============================] - 0s 148us/step - loss: 0.3657 - acc: 0.8145\n",
      "Epoch 46/50\n",
      "512/512 [==============================] - 0s 150us/step - loss: 0.3731 - acc: 0.8066\n",
      "Epoch 47/50\n",
      "512/512 [==============================] - 0s 131us/step - loss: 0.3644 - acc: 0.8203\n",
      "Epoch 48/50\n",
      "512/512 [==============================] - 0s 147us/step - loss: 0.3748 - acc: 0.7988\n",
      "Epoch 49/50\n",
      "512/512 [==============================] - 0s 136us/step - loss: 0.3635 - acc: 0.8145\n",
      "Epoch 50/50\n",
      "512/512 [==============================] - 0s 127us/step - loss: 0.3854 - acc: 0.8125\n",
      "256/256 [==============================] - 0s 347us/step\n",
      "512/512 [==============================] - 0s 87us/step\n",
      "[CV]  batch_size=10, epochs=50, score=0.7265624969732016, total=   4.5s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   13.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "512/512 [==============================] - 0s 709us/step - loss: 0.5801 - acc: 0.6953\n",
      "Epoch 2/50\n",
      "512/512 [==============================] - 0s 148us/step - loss: 0.5017 - acc: 0.7598\n",
      "Epoch 3/50\n",
      "512/512 [==============================] - 0s 150us/step - loss: 0.4926 - acc: 0.7598\n",
      "Epoch 4/50\n",
      "512/512 [==============================] - 0s 161us/step - loss: 0.4838 - acc: 0.7695\n",
      "Epoch 5/50\n",
      "512/512 [==============================] - 0s 155us/step - loss: 0.4764 - acc: 0.7734\n",
      "Epoch 6/50\n",
      "512/512 [==============================] - 0s 134us/step - loss: 0.4742 - acc: 0.7559\n",
      "Epoch 7/50\n",
      "512/512 [==============================] - 0s 153us/step - loss: 0.4723 - acc: 0.7656\n",
      "Epoch 8/50\n",
      "512/512 [==============================] - 0s 155us/step - loss: 0.4696 - acc: 0.7617\n",
      "Epoch 9/50\n",
      "512/512 [==============================] - 0s 141us/step - loss: 0.4737 - acc: 0.7754\n",
      "Epoch 10/50\n",
      "512/512 [==============================] - 0s 156us/step - loss: 0.4614 - acc: 0.7754\n",
      "Epoch 11/50\n",
      "512/512 [==============================] - 0s 149us/step - loss: 0.4657 - acc: 0.7754\n",
      "Epoch 12/50\n",
      "512/512 [==============================] - 0s 147us/step - loss: 0.4594 - acc: 0.7715\n",
      "Epoch 13/50\n",
      "512/512 [==============================] - 0s 154us/step - loss: 0.4558 - acc: 0.7832\n",
      "Epoch 14/50\n",
      "512/512 [==============================] - 0s 155us/step - loss: 0.4514 - acc: 0.7930\n",
      "Epoch 15/50\n",
      "512/512 [==============================] - 0s 137us/step - loss: 0.4505 - acc: 0.7832\n",
      "Epoch 16/50\n",
      "512/512 [==============================] - 0s 139us/step - loss: 0.4477 - acc: 0.7812\n",
      "Epoch 17/50\n",
      "512/512 [==============================] - 0s 150us/step - loss: 0.4442 - acc: 0.8047\n",
      "Epoch 18/50\n",
      "512/512 [==============================] - 0s 136us/step - loss: 0.4426 - acc: 0.7969\n",
      "Epoch 19/50\n",
      "512/512 [==============================] - 0s 148us/step - loss: 0.4438 - acc: 0.8066\n",
      "Epoch 20/50\n",
      "512/512 [==============================] - 0s 143us/step - loss: 0.4373 - acc: 0.7969\n",
      "Epoch 21/50\n",
      "512/512 [==============================] - 0s 152us/step - loss: 0.4369 - acc: 0.7988\n",
      "Epoch 22/50\n",
      "512/512 [==============================] - 0s 136us/step - loss: 0.4436 - acc: 0.7988\n",
      "Epoch 23/50\n",
      "512/512 [==============================] - 0s 153us/step - loss: 0.4424 - acc: 0.7891\n",
      "Epoch 24/50\n",
      "512/512 [==============================] - 0s 138us/step - loss: 0.4361 - acc: 0.8086\n",
      "Epoch 25/50\n",
      "512/512 [==============================] - 0s 155us/step - loss: 0.4301 - acc: 0.8145\n",
      "Epoch 26/50\n",
      "512/512 [==============================] - 0s 144us/step - loss: 0.4291 - acc: 0.8066\n",
      "Epoch 27/50\n",
      "512/512 [==============================] - 0s 142us/step - loss: 0.4274 - acc: 0.8066\n",
      "Epoch 28/50\n",
      "512/512 [==============================] - 0s 140us/step - loss: 0.4261 - acc: 0.7988\n",
      "Epoch 29/50\n",
      "512/512 [==============================] - 0s 142us/step - loss: 0.4345 - acc: 0.7949\n",
      "Epoch 30/50\n",
      "512/512 [==============================] - 0s 139us/step - loss: 0.4255 - acc: 0.8184\n",
      "Epoch 31/50\n",
      "512/512 [==============================] - 0s 140us/step - loss: 0.4245 - acc: 0.8125\n",
      "Epoch 32/50\n",
      "512/512 [==============================] - 0s 137us/step - loss: 0.4244 - acc: 0.8164\n",
      "Epoch 33/50\n",
      "512/512 [==============================] - 0s 145us/step - loss: 0.4246 - acc: 0.8086\n",
      "Epoch 34/50\n",
      "512/512 [==============================] - 0s 147us/step - loss: 0.4218 - acc: 0.8184\n",
      "Epoch 35/50\n",
      "512/512 [==============================] - 0s 144us/step - loss: 0.4250 - acc: 0.8242\n",
      "Epoch 36/50\n",
      "512/512 [==============================] - 0s 151us/step - loss: 0.4221 - acc: 0.8184\n",
      "Epoch 37/50\n",
      "512/512 [==============================] - 0s 136us/step - loss: 0.4197 - acc: 0.8184\n",
      "Epoch 38/50\n",
      "512/512 [==============================] - 0s 135us/step - loss: 0.4228 - acc: 0.8008\n",
      "Epoch 39/50\n",
      "512/512 [==============================] - 0s 129us/step - loss: 0.4230 - acc: 0.8086\n",
      "Epoch 40/50\n",
      "512/512 [==============================] - 0s 135us/step - loss: 0.4191 - acc: 0.8242\n",
      "Epoch 41/50\n",
      "512/512 [==============================] - 0s 142us/step - loss: 0.4145 - acc: 0.8105\n",
      "Epoch 42/50\n",
      "512/512 [==============================] - 0s 137us/step - loss: 0.4209 - acc: 0.8223\n",
      "Epoch 43/50\n",
      "512/512 [==============================] - 0s 143us/step - loss: 0.4187 - acc: 0.8145\n",
      "Epoch 44/50\n",
      "512/512 [==============================] - 0s 145us/step - loss: 0.4161 - acc: 0.8145\n",
      "Epoch 45/50\n",
      "512/512 [==============================] - 0s 130us/step - loss: 0.4165 - acc: 0.8105\n",
      "Epoch 46/50\n",
      "512/512 [==============================] - 0s 146us/step - loss: 0.4137 - acc: 0.8164\n",
      "Epoch 47/50\n",
      "512/512 [==============================] - 0s 145us/step - loss: 0.4103 - acc: 0.8184\n",
      "Epoch 48/50\n",
      "512/512 [==============================] - 0s 142us/step - loss: 0.4166 - acc: 0.8223\n",
      "Epoch 49/50\n",
      "512/512 [==============================] - 0s 134us/step - loss: 0.4150 - acc: 0.8164\n",
      "Epoch 50/50\n",
      "512/512 [==============================] - 0s 142us/step - loss: 0.4137 - acc: 0.8086\n",
      "256/256 [==============================] - 0s 382us/step\n",
      "512/512 [==============================] - 0s 86us/step\n",
      "[CV]  batch_size=10, epochs=50, score=0.7968749986030161, total=   4.5s\n",
      "[CV] batch_size=10, epochs=100 .......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   17.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "512/512 [==============================] - 0s 760us/step - loss: 0.5640 - acc: 0.6621\n",
      "Epoch 2/100\n",
      "512/512 [==============================] - 0s 136us/step - loss: 0.4754 - acc: 0.7500\n",
      "Epoch 3/100\n",
      "512/512 [==============================] - 0s 143us/step - loss: 0.4544 - acc: 0.7930\n",
      "Epoch 4/100\n",
      "512/512 [==============================] - 0s 133us/step - loss: 0.4389 - acc: 0.7949\n",
      "Epoch 5/100\n",
      "512/512 [==============================] - 0s 151us/step - loss: 0.4237 - acc: 0.8027\n",
      "Epoch 6/100\n",
      "512/512 [==============================] - 0s 146us/step - loss: 0.4210 - acc: 0.7949\n",
      "Epoch 7/100\n",
      "512/512 [==============================] - 0s 142us/step - loss: 0.4144 - acc: 0.8105\n",
      "Epoch 8/100\n",
      "512/512 [==============================] - 0s 156us/step - loss: 0.4064 - acc: 0.8066\n",
      "Epoch 9/100\n",
      "512/512 [==============================] - 0s 146us/step - loss: 0.4072 - acc: 0.8105\n",
      "Epoch 10/100\n",
      "512/512 [==============================] - 0s 136us/step - loss: 0.3997 - acc: 0.8047\n",
      "Epoch 11/100\n",
      "512/512 [==============================] - 0s 151us/step - loss: 0.3939 - acc: 0.8125\n",
      "Epoch 12/100\n",
      "512/512 [==============================] - 0s 136us/step - loss: 0.3865 - acc: 0.8223\n",
      "Epoch 13/100\n",
      "512/512 [==============================] - 0s 169us/step - loss: 0.3977 - acc: 0.8086\n",
      "Epoch 14/100\n",
      "512/512 [==============================] - 0s 148us/step - loss: 0.3927 - acc: 0.8066\n",
      "Epoch 15/100\n",
      "512/512 [==============================] - 0s 148us/step - loss: 0.3883 - acc: 0.8105\n",
      "Epoch 16/100\n",
      "512/512 [==============================] - 0s 151us/step - loss: 0.3909 - acc: 0.8164\n",
      "Epoch 17/100\n",
      "512/512 [==============================] - 0s 149us/step - loss: 0.3776 - acc: 0.8203\n",
      "Epoch 18/100\n",
      "512/512 [==============================] - 0s 119us/step - loss: 0.3713 - acc: 0.8301\n",
      "Epoch 19/100\n",
      "512/512 [==============================] - 0s 145us/step - loss: 0.3729 - acc: 0.8301\n",
      "Epoch 20/100\n",
      "512/512 [==============================] - 0s 141us/step - loss: 0.3795 - acc: 0.8203\n",
      "Epoch 21/100\n",
      "512/512 [==============================] - 0s 141us/step - loss: 0.3777 - acc: 0.8262\n",
      "Epoch 22/100\n",
      "512/512 [==============================] - 0s 142us/step - loss: 0.3758 - acc: 0.8262\n",
      "Epoch 23/100\n",
      "512/512 [==============================] - 0s 150us/step - loss: 0.3713 - acc: 0.8359\n",
      "Epoch 24/100\n",
      "512/512 [==============================] - 0s 135us/step - loss: 0.3836 - acc: 0.8418\n",
      "Epoch 25/100\n",
      "512/512 [==============================] - 0s 145us/step - loss: 0.3802 - acc: 0.8379\n",
      "Epoch 26/100\n",
      "512/512 [==============================] - 0s 150us/step - loss: 0.3669 - acc: 0.8281\n",
      "Epoch 27/100\n",
      "512/512 [==============================] - 0s 148us/step - loss: 0.3687 - acc: 0.8418\n",
      "Epoch 28/100\n",
      "512/512 [==============================] - 0s 156us/step - loss: 0.3695 - acc: 0.8496\n",
      "Epoch 29/100\n",
      "512/512 [==============================] - 0s 147us/step - loss: 0.3684 - acc: 0.8398\n",
      "Epoch 30/100\n",
      "512/512 [==============================] - 0s 127us/step - loss: 0.3648 - acc: 0.8340\n",
      "Epoch 31/100\n",
      "512/512 [==============================] - 0s 131us/step - loss: 0.3703 - acc: 0.8340\n",
      "Epoch 32/100\n",
      "512/512 [==============================] - 0s 134us/step - loss: 0.3741 - acc: 0.8281\n",
      "Epoch 33/100\n",
      "512/512 [==============================] - 0s 143us/step - loss: 0.3644 - acc: 0.8398\n",
      "Epoch 34/100\n",
      "512/512 [==============================] - 0s 147us/step - loss: 0.3649 - acc: 0.8477\n",
      "Epoch 35/100\n",
      "512/512 [==============================] - 0s 143us/step - loss: 0.3690 - acc: 0.8477\n",
      "Epoch 36/100\n",
      "512/512 [==============================] - 0s 136us/step - loss: 0.3695 - acc: 0.8340\n",
      "Epoch 37/100\n",
      "512/512 [==============================] - 0s 139us/step - loss: 0.3564 - acc: 0.8457\n",
      "Epoch 38/100\n",
      "512/512 [==============================] - 0s 129us/step - loss: 0.3514 - acc: 0.8457\n",
      "Epoch 39/100\n",
      "512/512 [==============================] - 0s 154us/step - loss: 0.3528 - acc: 0.8418\n",
      "Epoch 40/100\n",
      "512/512 [==============================] - 0s 151us/step - loss: 0.3511 - acc: 0.8535\n",
      "Epoch 41/100\n",
      "512/512 [==============================] - 0s 145us/step - loss: 0.3539 - acc: 0.8516\n",
      "Epoch 42/100\n",
      "512/512 [==============================] - 0s 138us/step - loss: 0.3476 - acc: 0.8535\n",
      "Epoch 43/100\n",
      "512/512 [==============================] - 0s 131us/step - loss: 0.3436 - acc: 0.8477\n",
      "Epoch 44/100\n",
      "512/512 [==============================] - 0s 130us/step - loss: 0.3556 - acc: 0.8477\n",
      "Epoch 45/100\n",
      "512/512 [==============================] - 0s 145us/step - loss: 0.3470 - acc: 0.8535\n",
      "Epoch 46/100\n",
      "512/512 [==============================] - 0s 143us/step - loss: 0.3496 - acc: 0.8477\n",
      "Epoch 47/100\n",
      "512/512 [==============================] - 0s 139us/step - loss: 0.3409 - acc: 0.8535\n",
      "Epoch 48/100\n",
      "512/512 [==============================] - 0s 151us/step - loss: 0.3404 - acc: 0.8594\n",
      "Epoch 49/100\n",
      "512/512 [==============================] - 0s 147us/step - loss: 0.3443 - acc: 0.8574\n",
      "Epoch 50/100\n",
      "512/512 [==============================] - 0s 131us/step - loss: 0.3402 - acc: 0.8594\n",
      "Epoch 51/100\n",
      "512/512 [==============================] - 0s 135us/step - loss: 0.3411 - acc: 0.8574\n",
      "Epoch 52/100\n",
      "512/512 [==============================] - 0s 148us/step - loss: 0.3398 - acc: 0.8535\n",
      "Epoch 53/100\n",
      "512/512 [==============================] - 0s 139us/step - loss: 0.3404 - acc: 0.8672\n",
      "Epoch 54/100\n",
      "512/512 [==============================] - 0s 135us/step - loss: 0.3386 - acc: 0.8516\n",
      "Epoch 55/100\n",
      "512/512 [==============================] - 0s 148us/step - loss: 0.3420 - acc: 0.8555\n",
      "Epoch 56/100\n",
      "512/512 [==============================] - 0s 130us/step - loss: 0.3367 - acc: 0.8535\n",
      "Epoch 57/100\n",
      "512/512 [==============================] - 0s 150us/step - loss: 0.3362 - acc: 0.8574\n",
      "Epoch 58/100\n",
      "512/512 [==============================] - 0s 144us/step - loss: 0.3422 - acc: 0.8574\n",
      "Epoch 59/100\n",
      "512/512 [==============================] - 0s 148us/step - loss: 0.3361 - acc: 0.8594\n",
      "Epoch 60/100\n",
      "512/512 [==============================] - 0s 137us/step - loss: 0.3383 - acc: 0.8535\n",
      "Epoch 61/100\n",
      "512/512 [==============================] - 0s 132us/step - loss: 0.3473 - acc: 0.8477\n",
      "Epoch 62/100\n",
      "512/512 [==============================] - 0s 135us/step - loss: 0.3380 - acc: 0.8613\n",
      "Epoch 63/100\n",
      "512/512 [==============================] - 0s 140us/step - loss: 0.3596 - acc: 0.8418\n",
      "Epoch 64/100\n",
      "512/512 [==============================] - 0s 149us/step - loss: 0.3388 - acc: 0.8477\n",
      "Epoch 65/100\n",
      "512/512 [==============================] - 0s 132us/step - loss: 0.3369 - acc: 0.8594\n",
      "Epoch 66/100\n",
      "512/512 [==============================] - 0s 139us/step - loss: 0.3304 - acc: 0.8613\n",
      "Epoch 67/100\n",
      "512/512 [==============================] - 0s 140us/step - loss: 0.3303 - acc: 0.8672\n",
      "Epoch 68/100\n",
      "512/512 [==============================] - 0s 126us/step - loss: 0.3369 - acc: 0.8516\n",
      "Epoch 69/100\n",
      "512/512 [==============================] - 0s 136us/step - loss: 0.3423 - acc: 0.8516\n",
      "Epoch 70/100\n",
      "512/512 [==============================] - 0s 138us/step - loss: 0.3362 - acc: 0.8613\n",
      "Epoch 71/100\n",
      "512/512 [==============================] - 0s 140us/step - loss: 0.3289 - acc: 0.8535\n",
      "Epoch 72/100\n",
      "512/512 [==============================] - 0s 148us/step - loss: 0.3339 - acc: 0.8613\n",
      "Epoch 73/100\n",
      "512/512 [==============================] - 0s 142us/step - loss: 0.3309 - acc: 0.8535\n",
      "Epoch 74/100\n",
      "512/512 [==============================] - 0s 127us/step - loss: 0.3347 - acc: 0.8516\n",
      "Epoch 75/100\n",
      "512/512 [==============================] - 0s 146us/step - loss: 0.3281 - acc: 0.8613\n",
      "Epoch 76/100\n",
      "512/512 [==============================] - 0s 137us/step - loss: 0.3334 - acc: 0.8437\n",
      "Epoch 77/100\n",
      "512/512 [==============================] - 0s 135us/step - loss: 0.3295 - acc: 0.8594\n",
      "Epoch 78/100\n",
      "512/512 [==============================] - 0s 133us/step - loss: 0.3398 - acc: 0.8496\n",
      "Epoch 79/100\n",
      "512/512 [==============================] - 0s 127us/step - loss: 0.3479 - acc: 0.8398\n",
      "Epoch 80/100\n",
      "512/512 [==============================] - 0s 133us/step - loss: 0.3284 - acc: 0.8574\n",
      "Epoch 81/100\n",
      "512/512 [==============================] - 0s 133us/step - loss: 0.3318 - acc: 0.8574\n",
      "Epoch 82/100\n",
      "512/512 [==============================] - 0s 142us/step - loss: 0.3270 - acc: 0.8633\n",
      "Epoch 83/100\n",
      "512/512 [==============================] - 0s 134us/step - loss: 0.3452 - acc: 0.8496\n",
      "Epoch 84/100\n",
      "512/512 [==============================] - 0s 145us/step - loss: 0.3296 - acc: 0.8613\n",
      "Epoch 85/100\n",
      "512/512 [==============================] - 0s 144us/step - loss: 0.3285 - acc: 0.8535\n",
      "Epoch 86/100\n",
      "512/512 [==============================] - 0s 149us/step - loss: 0.3430 - acc: 0.8574\n",
      "Epoch 87/100\n",
      "512/512 [==============================] - 0s 155us/step - loss: 0.3332 - acc: 0.8711\n",
      "Epoch 88/100\n",
      "512/512 [==============================] - 0s 149us/step - loss: 0.3314 - acc: 0.8594\n",
      "Epoch 89/100\n",
      "512/512 [==============================] - 0s 147us/step - loss: 0.3234 - acc: 0.8516\n",
      "Epoch 90/100\n",
      "512/512 [==============================] - 0s 136us/step - loss: 0.3273 - acc: 0.8691\n",
      "Epoch 91/100\n",
      "512/512 [==============================] - 0s 164us/step - loss: 0.3248 - acc: 0.8613\n",
      "Epoch 92/100\n",
      "512/512 [==============================] - 0s 133us/step - loss: 0.3250 - acc: 0.8633\n",
      "Epoch 93/100\n",
      "512/512 [==============================] - 0s 143us/step - loss: 0.3282 - acc: 0.8457\n",
      "Epoch 94/100\n",
      "512/512 [==============================] - 0s 175us/step - loss: 0.3275 - acc: 0.8555\n",
      "Epoch 95/100\n",
      "512/512 [==============================] - 0s 146us/step - loss: 0.3349 - acc: 0.8574\n",
      "Epoch 96/100\n",
      "512/512 [==============================] - 0s 146us/step - loss: 0.3282 - acc: 0.8457\n",
      "Epoch 97/100\n",
      "512/512 [==============================] - 0s 139us/step - loss: 0.3313 - acc: 0.8574\n",
      "Epoch 98/100\n",
      "512/512 [==============================] - 0s 149us/step - loss: 0.3213 - acc: 0.8535\n",
      "Epoch 99/100\n",
      "512/512 [==============================] - 0s 154us/step - loss: 0.3294 - acc: 0.8516\n",
      "Epoch 100/100\n",
      "512/512 [==============================] - 0s 127us/step - loss: 0.3272 - acc: 0.8652\n",
      "256/256 [==============================] - 0s 460us/step\n",
      "512/512 [==============================] - 0s 116us/step\n",
      "[CV]  batch_size=10, epochs=100, score=0.7070312546566129, total=   8.2s\n",
      "[CV] batch_size=10, epochs=100 .......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   25.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "512/512 [==============================] - 0s 837us/step - loss: 0.5669 - acc: 0.7109\n",
      "Epoch 2/100\n",
      "512/512 [==============================] - 0s 167us/step - loss: 0.4691 - acc: 0.7617\n",
      "Epoch 3/100\n",
      "512/512 [==============================] - 0s 150us/step - loss: 0.4443 - acc: 0.7949\n",
      "Epoch 4/100\n",
      "512/512 [==============================] - 0s 157us/step - loss: 0.4432 - acc: 0.7891\n",
      "Epoch 5/100\n",
      "512/512 [==============================] - 0s 147us/step - loss: 0.4432 - acc: 0.7734\n",
      "Epoch 6/100\n",
      "512/512 [==============================] - 0s 161us/step - loss: 0.4331 - acc: 0.7793\n",
      "Epoch 7/100\n",
      "512/512 [==============================] - 0s 141us/step - loss: 0.4354 - acc: 0.7930\n",
      "Epoch 8/100\n",
      "512/512 [==============================] - 0s 152us/step - loss: 0.4271 - acc: 0.7832\n",
      "Epoch 9/100\n",
      "512/512 [==============================] - 0s 132us/step - loss: 0.4279 - acc: 0.7930\n",
      "Epoch 10/100\n",
      "512/512 [==============================] - 0s 163us/step - loss: 0.4244 - acc: 0.7930\n",
      "Epoch 11/100\n",
      "512/512 [==============================] - 0s 152us/step - loss: 0.4259 - acc: 0.7891\n",
      "Epoch 12/100\n",
      "512/512 [==============================] - 0s 139us/step - loss: 0.4183 - acc: 0.7891\n",
      "Epoch 13/100\n",
      "512/512 [==============================] - 0s 155us/step - loss: 0.4200 - acc: 0.7852\n",
      "Epoch 14/100\n",
      "512/512 [==============================] - 0s 135us/step - loss: 0.4179 - acc: 0.7832\n",
      "Epoch 15/100\n",
      "512/512 [==============================] - 0s 146us/step - loss: 0.4224 - acc: 0.8008\n",
      "Epoch 16/100\n",
      "512/512 [==============================] - 0s 154us/step - loss: 0.4155 - acc: 0.7910\n",
      "Epoch 17/100\n",
      "512/512 [==============================] - 0s 164us/step - loss: 0.4148 - acc: 0.7910\n",
      "Epoch 18/100\n",
      "512/512 [==============================] - 0s 153us/step - loss: 0.4158 - acc: 0.8008\n",
      "Epoch 19/100\n",
      "512/512 [==============================] - 0s 135us/step - loss: 0.4118 - acc: 0.7871\n",
      "Epoch 20/100\n",
      "512/512 [==============================] - 0s 150us/step - loss: 0.4080 - acc: 0.7988\n",
      "Epoch 21/100\n",
      "512/512 [==============================] - 0s 143us/step - loss: 0.4109 - acc: 0.7988\n",
      "Epoch 22/100\n",
      "512/512 [==============================] - 0s 142us/step - loss: 0.4112 - acc: 0.7910\n",
      "Epoch 23/100\n",
      "512/512 [==============================] - 0s 146us/step - loss: 0.4100 - acc: 0.8066\n",
      "Epoch 24/100\n",
      "512/512 [==============================] - 0s 132us/step - loss: 0.4061 - acc: 0.8105\n",
      "Epoch 25/100\n",
      "512/512 [==============================] - 0s 139us/step - loss: 0.4077 - acc: 0.8066\n",
      "Epoch 26/100\n",
      "512/512 [==============================] - 0s 146us/step - loss: 0.4027 - acc: 0.8047\n",
      "Epoch 27/100\n",
      "512/512 [==============================] - 0s 146us/step - loss: 0.4024 - acc: 0.7949\n",
      "Epoch 28/100\n",
      "512/512 [==============================] - 0s 150us/step - loss: 0.4027 - acc: 0.8105\n",
      "Epoch 29/100\n",
      "512/512 [==============================] - 0s 157us/step - loss: 0.4021 - acc: 0.8027\n",
      "Epoch 30/100\n",
      "512/512 [==============================] - 0s 139us/step - loss: 0.3976 - acc: 0.8047\n",
      "Epoch 31/100\n",
      "512/512 [==============================] - 0s 148us/step - loss: 0.4003 - acc: 0.8086\n",
      "Epoch 32/100\n",
      "512/512 [==============================] - 0s 141us/step - loss: 0.4009 - acc: 0.7988\n",
      "Epoch 33/100\n",
      "512/512 [==============================] - 0s 143us/step - loss: 0.3922 - acc: 0.8164\n",
      "Epoch 34/100\n",
      "512/512 [==============================] - 0s 137us/step - loss: 0.3924 - acc: 0.8125\n",
      "Epoch 35/100\n",
      "512/512 [==============================] - 0s 129us/step - loss: 0.3952 - acc: 0.8145\n",
      "Epoch 36/100\n",
      "512/512 [==============================] - 0s 135us/step - loss: 0.3995 - acc: 0.8125\n",
      "Epoch 37/100\n",
      "512/512 [==============================] - 0s 137us/step - loss: 0.3909 - acc: 0.8164\n",
      "Epoch 38/100\n",
      "512/512 [==============================] - 0s 145us/step - loss: 0.3936 - acc: 0.8184\n",
      "Epoch 39/100\n",
      "512/512 [==============================] - 0s 129us/step - loss: 0.3965 - acc: 0.8066\n",
      "Epoch 40/100\n",
      "512/512 [==============================] - 0s 131us/step - loss: 0.3926 - acc: 0.8066\n",
      "Epoch 41/100\n",
      "512/512 [==============================] - 0s 146us/step - loss: 0.3877 - acc: 0.8145\n",
      "Epoch 42/100\n",
      "512/512 [==============================] - 0s 152us/step - loss: 0.3867 - acc: 0.8242\n",
      "Epoch 43/100\n",
      "512/512 [==============================] - 0s 139us/step - loss: 0.3891 - acc: 0.8086\n",
      "Epoch 44/100\n",
      "512/512 [==============================] - 0s 154us/step - loss: 0.3834 - acc: 0.8125\n",
      "Epoch 45/100\n",
      "512/512 [==============================] - 0s 143us/step - loss: 0.3878 - acc: 0.8262\n",
      "Epoch 46/100\n",
      "512/512 [==============================] - 0s 138us/step - loss: 0.3904 - acc: 0.8164\n",
      "Epoch 47/100\n",
      "512/512 [==============================] - 0s 140us/step - loss: 0.3881 - acc: 0.8164\n",
      "Epoch 48/100\n",
      "512/512 [==============================] - 0s 151us/step - loss: 0.3839 - acc: 0.8184\n",
      "Epoch 49/100\n",
      "512/512 [==============================] - 0s 128us/step - loss: 0.3837 - acc: 0.8125\n",
      "Epoch 50/100\n",
      "512/512 [==============================] - 0s 136us/step - loss: 0.3820 - acc: 0.8223\n",
      "Epoch 51/100\n",
      "512/512 [==============================] - 0s 142us/step - loss: 0.3911 - acc: 0.8125\n",
      "Epoch 52/100\n",
      "512/512 [==============================] - 0s 134us/step - loss: 0.3846 - acc: 0.8145\n",
      "Epoch 53/100\n",
      "512/512 [==============================] - 0s 145us/step - loss: 0.3913 - acc: 0.8125\n",
      "Epoch 54/100\n",
      "512/512 [==============================] - 0s 138us/step - loss: 0.3778 - acc: 0.8223\n",
      "Epoch 55/100\n",
      "512/512 [==============================] - 0s 142us/step - loss: 0.3865 - acc: 0.8223\n",
      "Epoch 56/100\n",
      "512/512 [==============================] - 0s 148us/step - loss: 0.3873 - acc: 0.8105\n",
      "Epoch 57/100\n",
      "512/512 [==============================] - 0s 143us/step - loss: 0.3803 - acc: 0.8203\n",
      "Epoch 58/100\n",
      "512/512 [==============================] - 0s 140us/step - loss: 0.3788 - acc: 0.8281\n",
      "Epoch 59/100\n",
      "512/512 [==============================] - 0s 132us/step - loss: 0.3791 - acc: 0.8125\n",
      "Epoch 60/100\n",
      "512/512 [==============================] - 0s 144us/step - loss: 0.3895 - acc: 0.8145\n",
      "Epoch 61/100\n",
      "512/512 [==============================] - 0s 135us/step - loss: 0.3831 - acc: 0.8203\n",
      "Epoch 62/100\n",
      "512/512 [==============================] - 0s 142us/step - loss: 0.3799 - acc: 0.8105\n",
      "Epoch 63/100\n",
      "512/512 [==============================] - 0s 144us/step - loss: 0.3751 - acc: 0.8184\n",
      "Epoch 64/100\n",
      "512/512 [==============================] - 0s 139us/step - loss: 0.3742 - acc: 0.8301\n",
      "Epoch 65/100\n",
      "512/512 [==============================] - 0s 131us/step - loss: 0.3818 - acc: 0.8242\n",
      "Epoch 66/100\n",
      "512/512 [==============================] - 0s 151us/step - loss: 0.3717 - acc: 0.8203\n",
      "Epoch 67/100\n",
      "512/512 [==============================] - 0s 140us/step - loss: 0.3732 - acc: 0.8223\n",
      "Epoch 68/100\n",
      "512/512 [==============================] - 0s 135us/step - loss: 0.3732 - acc: 0.8242\n",
      "Epoch 69/100\n",
      "512/512 [==============================] - 0s 136us/step - loss: 0.3758 - acc: 0.8203\n",
      "Epoch 70/100\n",
      "512/512 [==============================] - 0s 146us/step - loss: 0.3698 - acc: 0.8398\n",
      "Epoch 71/100\n",
      "512/512 [==============================] - 0s 131us/step - loss: 0.3743 - acc: 0.8359\n",
      "Epoch 72/100\n",
      "512/512 [==============================] - 0s 141us/step - loss: 0.3746 - acc: 0.8184\n",
      "Epoch 73/100\n",
      "512/512 [==============================] - 0s 136us/step - loss: 0.3817 - acc: 0.8164\n",
      "Epoch 74/100\n",
      "512/512 [==============================] - 0s 124us/step - loss: 0.3689 - acc: 0.8203\n",
      "Epoch 75/100\n",
      "512/512 [==============================] - 0s 138us/step - loss: 0.3843 - acc: 0.8145\n",
      "Epoch 76/100\n",
      "512/512 [==============================] - 0s 139us/step - loss: 0.3827 - acc: 0.8145\n",
      "Epoch 77/100\n",
      "512/512 [==============================] - 0s 122us/step - loss: 0.3839 - acc: 0.8223\n",
      "Epoch 78/100\n",
      "512/512 [==============================] - 0s 131us/step - loss: 0.3746 - acc: 0.8105\n",
      "Epoch 79/100\n",
      "512/512 [==============================] - 0s 134us/step - loss: 0.3696 - acc: 0.8203\n",
      "Epoch 80/100\n",
      "512/512 [==============================] - 0s 135us/step - loss: 0.3709 - acc: 0.8203\n",
      "Epoch 81/100\n",
      "512/512 [==============================] - 0s 145us/step - loss: 0.3707 - acc: 0.8320\n",
      "Epoch 82/100\n",
      "512/512 [==============================] - 0s 137us/step - loss: 0.3683 - acc: 0.8164\n",
      "Epoch 83/100\n",
      "512/512 [==============================] - 0s 135us/step - loss: 0.3705 - acc: 0.8281\n",
      "Epoch 84/100\n",
      "512/512 [==============================] - 0s 156us/step - loss: 0.3745 - acc: 0.8184\n",
      "Epoch 85/100\n",
      "512/512 [==============================] - 0s 151us/step - loss: 0.3660 - acc: 0.8164\n",
      "Epoch 86/100\n",
      "512/512 [==============================] - 0s 140us/step - loss: 0.3731 - acc: 0.8301\n",
      "Epoch 87/100\n",
      "512/512 [==============================] - 0s 147us/step - loss: 0.3696 - acc: 0.8320\n",
      "Epoch 88/100\n",
      "512/512 [==============================] - 0s 148us/step - loss: 0.3646 - acc: 0.8301\n",
      "Epoch 89/100\n",
      "512/512 [==============================] - 0s 141us/step - loss: 0.3654 - acc: 0.8379\n",
      "Epoch 90/100\n",
      "512/512 [==============================] - 0s 146us/step - loss: 0.3659 - acc: 0.8281\n",
      "Epoch 91/100\n",
      "512/512 [==============================] - 0s 153us/step - loss: 0.3632 - acc: 0.8242\n",
      "Epoch 92/100\n",
      "512/512 [==============================] - 0s 141us/step - loss: 0.3694 - acc: 0.8203\n",
      "Epoch 93/100\n",
      "512/512 [==============================] - 0s 145us/step - loss: 0.3610 - acc: 0.8418\n",
      "Epoch 94/100\n",
      "512/512 [==============================] - 0s 148us/step - loss: 0.3681 - acc: 0.8262\n",
      "Epoch 95/100\n",
      "512/512 [==============================] - 0s 146us/step - loss: 0.3595 - acc: 0.8379\n",
      "Epoch 96/100\n",
      "512/512 [==============================] - 0s 151us/step - loss: 0.3710 - acc: 0.8184\n",
      "Epoch 97/100\n",
      "512/512 [==============================] - 0s 154us/step - loss: 0.3646 - acc: 0.8301\n",
      "Epoch 98/100\n",
      "512/512 [==============================] - 0s 139us/step - loss: 0.3641 - acc: 0.8184\n",
      "Epoch 99/100\n",
      "512/512 [==============================] - 0s 153us/step - loss: 0.3723 - acc: 0.8223\n",
      "Epoch 100/100\n",
      "512/512 [==============================] - 0s 155us/step - loss: 0.3674 - acc: 0.8242\n",
      "256/256 [==============================] - 0s 458us/step\n",
      "512/512 [==============================] - 0s 88us/step\n",
      "[CV]  batch_size=10, epochs=100, score=0.7304687513969839, total=   8.3s\n",
      "[CV] batch_size=10, epochs=100 .......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   34.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "512/512 [==============================] - 0s 831us/step - loss: 0.5963 - acc: 0.6992\n",
      "Epoch 2/100\n",
      "512/512 [==============================] - 0s 134us/step - loss: 0.5022 - acc: 0.7598\n",
      "Epoch 3/100\n",
      "512/512 [==============================] - 0s 137us/step - loss: 0.4883 - acc: 0.7617\n",
      "Epoch 4/100\n",
      "512/512 [==============================] - 0s 142us/step - loss: 0.4828 - acc: 0.7598\n",
      "Epoch 5/100\n",
      "512/512 [==============================] - 0s 135us/step - loss: 0.4711 - acc: 0.7578\n",
      "Epoch 6/100\n",
      "512/512 [==============================] - 0s 139us/step - loss: 0.4748 - acc: 0.7676\n",
      "Epoch 7/100\n",
      "512/512 [==============================] - 0s 150us/step - loss: 0.4661 - acc: 0.7754\n",
      "Epoch 8/100\n",
      "512/512 [==============================] - 0s 133us/step - loss: 0.4720 - acc: 0.7734\n",
      "Epoch 9/100\n",
      "512/512 [==============================] - 0s 149us/step - loss: 0.4651 - acc: 0.7812\n",
      "Epoch 10/100\n",
      "512/512 [==============================] - 0s 138us/step - loss: 0.4591 - acc: 0.7715\n",
      "Epoch 11/100\n",
      "512/512 [==============================] - 0s 142us/step - loss: 0.4610 - acc: 0.7715\n",
      "Epoch 12/100\n",
      "512/512 [==============================] - 0s 144us/step - loss: 0.4536 - acc: 0.7930\n",
      "Epoch 13/100\n",
      "512/512 [==============================] - 0s 141us/step - loss: 0.4528 - acc: 0.7793\n",
      "Epoch 14/100\n",
      "512/512 [==============================] - 0s 142us/step - loss: 0.4477 - acc: 0.7871\n",
      "Epoch 15/100\n",
      "512/512 [==============================] - 0s 147us/step - loss: 0.4512 - acc: 0.7773\n",
      "Epoch 16/100\n",
      "512/512 [==============================] - 0s 153us/step - loss: 0.4463 - acc: 0.7871\n",
      "Epoch 17/100\n",
      "512/512 [==============================] - 0s 140us/step - loss: 0.4446 - acc: 0.7852\n",
      "Epoch 18/100\n",
      "512/512 [==============================] - 0s 150us/step - loss: 0.4493 - acc: 0.8008\n",
      "Epoch 19/100\n",
      "512/512 [==============================] - 0s 143us/step - loss: 0.4386 - acc: 0.8008\n",
      "Epoch 20/100\n",
      "512/512 [==============================] - 0s 159us/step - loss: 0.4419 - acc: 0.7949\n",
      "Epoch 21/100\n",
      "512/512 [==============================] - 0s 154us/step - loss: 0.4426 - acc: 0.7910\n",
      "Epoch 22/100\n",
      "512/512 [==============================] - 0s 134us/step - loss: 0.4396 - acc: 0.7832\n",
      "Epoch 23/100\n",
      "512/512 [==============================] - 0s 137us/step - loss: 0.4315 - acc: 0.8047\n",
      "Epoch 24/100\n",
      "512/512 [==============================] - 0s 148us/step - loss: 0.4299 - acc: 0.8066\n",
      "Epoch 25/100\n",
      "512/512 [==============================] - 0s 138us/step - loss: 0.4346 - acc: 0.8047\n",
      "Epoch 26/100\n",
      "512/512 [==============================] - 0s 138us/step - loss: 0.4353 - acc: 0.8066\n",
      "Epoch 27/100\n",
      "512/512 [==============================] - 0s 146us/step - loss: 0.4332 - acc: 0.8125\n",
      "Epoch 28/100\n",
      "512/512 [==============================] - 0s 131us/step - loss: 0.4361 - acc: 0.8066\n",
      "Epoch 29/100\n",
      "512/512 [==============================] - 0s 139us/step - loss: 0.4338 - acc: 0.8145\n",
      "Epoch 30/100\n",
      "512/512 [==============================] - 0s 143us/step - loss: 0.4285 - acc: 0.8105\n",
      "Epoch 31/100\n",
      "512/512 [==============================] - 0s 144us/step - loss: 0.4253 - acc: 0.8145\n",
      "Epoch 32/100\n",
      "512/512 [==============================] - 0s 131us/step - loss: 0.4288 - acc: 0.8066\n",
      "Epoch 33/100\n",
      "512/512 [==============================] - 0s 132us/step - loss: 0.4320 - acc: 0.8066\n",
      "Epoch 34/100\n",
      "512/512 [==============================] - 0s 145us/step - loss: 0.4214 - acc: 0.8184\n",
      "Epoch 35/100\n",
      "512/512 [==============================] - 0s 131us/step - loss: 0.4259 - acc: 0.8125\n",
      "Epoch 36/100\n",
      "512/512 [==============================] - 0s 137us/step - loss: 0.4226 - acc: 0.8086\n",
      "Epoch 37/100\n",
      "512/512 [==============================] - 0s 140us/step - loss: 0.4201 - acc: 0.8125\n",
      "Epoch 38/100\n",
      "512/512 [==============================] - 0s 141us/step - loss: 0.4180 - acc: 0.8125\n",
      "Epoch 39/100\n",
      "512/512 [==============================] - 0s 148us/step - loss: 0.4152 - acc: 0.8164\n",
      "Epoch 40/100\n",
      "512/512 [==============================] - 0s 129us/step - loss: 0.4167 - acc: 0.8125\n",
      "Epoch 41/100\n",
      "512/512 [==============================] - 0s 139us/step - loss: 0.4159 - acc: 0.8125\n",
      "Epoch 42/100\n",
      "512/512 [==============================] - 0s 149us/step - loss: 0.4161 - acc: 0.8223\n",
      "Epoch 43/100\n",
      "512/512 [==============================] - 0s 149us/step - loss: 0.4096 - acc: 0.8203\n",
      "Epoch 44/100\n",
      "512/512 [==============================] - 0s 161us/step - loss: 0.4142 - acc: 0.8184\n",
      "Epoch 45/100\n",
      "512/512 [==============================] - 0s 146us/step - loss: 0.4099 - acc: 0.8242\n",
      "Epoch 46/100\n",
      "512/512 [==============================] - 0s 142us/step - loss: 0.4184 - acc: 0.8242\n",
      "Epoch 47/100\n",
      "512/512 [==============================] - 0s 143us/step - loss: 0.4119 - acc: 0.8223\n",
      "Epoch 48/100\n",
      "512/512 [==============================] - 0s 138us/step - loss: 0.4093 - acc: 0.8184\n",
      "Epoch 49/100\n",
      "512/512 [==============================] - 0s 141us/step - loss: 0.4000 - acc: 0.8301\n",
      "Epoch 50/100\n",
      "512/512 [==============================] - 0s 133us/step - loss: 0.4015 - acc: 0.8242\n",
      "Epoch 51/100\n",
      "512/512 [==============================] - 0s 143us/step - loss: 0.4012 - acc: 0.8223\n",
      "Epoch 52/100\n",
      "512/512 [==============================] - 0s 138us/step - loss: 0.3978 - acc: 0.8379\n",
      "Epoch 53/100\n",
      "512/512 [==============================] - 0s 134us/step - loss: 0.4013 - acc: 0.8320\n",
      "Epoch 54/100\n",
      "512/512 [==============================] - 0s 159us/step - loss: 0.3964 - acc: 0.8223\n",
      "Epoch 55/100\n",
      "512/512 [==============================] - 0s 136us/step - loss: 0.3976 - acc: 0.8359\n",
      "Epoch 56/100\n",
      "512/512 [==============================] - 0s 143us/step - loss: 0.3989 - acc: 0.8340\n",
      "Epoch 57/100\n",
      "512/512 [==============================] - 0s 143us/step - loss: 0.3943 - acc: 0.8418\n",
      "Epoch 58/100\n",
      "512/512 [==============================] - 0s 123us/step - loss: 0.3880 - acc: 0.8262\n",
      "Epoch 59/100\n",
      "512/512 [==============================] - 0s 139us/step - loss: 0.4088 - acc: 0.8301\n",
      "Epoch 60/100\n",
      "512/512 [==============================] - 0s 137us/step - loss: 0.3943 - acc: 0.8262\n",
      "Epoch 61/100\n",
      "512/512 [==============================] - 0s 135us/step - loss: 0.4006 - acc: 0.8359\n",
      "Epoch 62/100\n",
      "512/512 [==============================] - 0s 139us/step - loss: 0.3943 - acc: 0.8320\n",
      "Epoch 63/100\n",
      "512/512 [==============================] - 0s 139us/step - loss: 0.3882 - acc: 0.8242\n",
      "Epoch 64/100\n",
      "512/512 [==============================] - 0s 132us/step - loss: 0.3881 - acc: 0.8418\n",
      "Epoch 65/100\n",
      "512/512 [==============================] - 0s 135us/step - loss: 0.3811 - acc: 0.8418\n",
      "Epoch 66/100\n",
      "512/512 [==============================] - 0s 139us/step - loss: 0.3826 - acc: 0.8340\n",
      "Epoch 67/100\n",
      "512/512 [==============================] - 0s 126us/step - loss: 0.3793 - acc: 0.8437\n",
      "Epoch 68/100\n",
      "512/512 [==============================] - 0s 132us/step - loss: 0.3767 - acc: 0.8477\n",
      "Epoch 69/100\n",
      "512/512 [==============================] - 0s 131us/step - loss: 0.3739 - acc: 0.8437\n",
      "Epoch 70/100\n",
      "512/512 [==============================] - 0s 142us/step - loss: 0.3777 - acc: 0.8496\n",
      "Epoch 71/100\n",
      "512/512 [==============================] - 0s 145us/step - loss: 0.3784 - acc: 0.8496\n",
      "Epoch 72/100\n",
      "512/512 [==============================] - 0s 141us/step - loss: 0.3674 - acc: 0.8477\n",
      "Epoch 73/100\n",
      "512/512 [==============================] - 0s 147us/step - loss: 0.3638 - acc: 0.8535\n",
      "Epoch 74/100\n",
      "512/512 [==============================] - 0s 133us/step - loss: 0.3671 - acc: 0.8457\n",
      "Epoch 75/100\n",
      "512/512 [==============================] - 0s 130us/step - loss: 0.3772 - acc: 0.8457\n",
      "Epoch 76/100\n",
      "512/512 [==============================] - 0s 133us/step - loss: 0.3724 - acc: 0.8437\n",
      "Epoch 77/100\n",
      "512/512 [==============================] - 0s 135us/step - loss: 0.3626 - acc: 0.8613\n",
      "Epoch 78/100\n",
      "512/512 [==============================] - 0s 136us/step - loss: 0.3681 - acc: 0.8535\n",
      "Epoch 79/100\n",
      "512/512 [==============================] - 0s 134us/step - loss: 0.3706 - acc: 0.8594\n",
      "Epoch 80/100\n",
      "512/512 [==============================] - 0s 130us/step - loss: 0.3653 - acc: 0.8535\n",
      "Epoch 81/100\n",
      "512/512 [==============================] - 0s 143us/step - loss: 0.3566 - acc: 0.8477\n",
      "Epoch 82/100\n",
      "512/512 [==============================] - 0s 136us/step - loss: 0.3566 - acc: 0.8535\n",
      "Epoch 83/100\n",
      "512/512 [==============================] - 0s 138us/step - loss: 0.3577 - acc: 0.8477\n",
      "Epoch 84/100\n",
      "512/512 [==============================] - 0s 136us/step - loss: 0.3503 - acc: 0.8555\n",
      "Epoch 85/100\n",
      "512/512 [==============================] - 0s 159us/step - loss: 0.3502 - acc: 0.8496\n",
      "Epoch 86/100\n",
      "512/512 [==============================] - 0s 148us/step - loss: 0.3545 - acc: 0.8496\n",
      "Epoch 87/100\n",
      "512/512 [==============================] - 0s 139us/step - loss: 0.3476 - acc: 0.8633\n",
      "Epoch 88/100\n",
      "512/512 [==============================] - 0s 143us/step - loss: 0.3461 - acc: 0.8594\n",
      "Epoch 89/100\n",
      "512/512 [==============================] - 0s 147us/step - loss: 0.3583 - acc: 0.8477\n",
      "Epoch 90/100\n",
      "512/512 [==============================] - 0s 132us/step - loss: 0.3430 - acc: 0.8613\n",
      "Epoch 91/100\n",
      "512/512 [==============================] - 0s 140us/step - loss: 0.3524 - acc: 0.8613\n",
      "Epoch 92/100\n",
      "512/512 [==============================] - 0s 149us/step - loss: 0.3506 - acc: 0.8594\n",
      "Epoch 93/100\n",
      "512/512 [==============================] - 0s 141us/step - loss: 0.3465 - acc: 0.8516\n",
      "Epoch 94/100\n",
      "512/512 [==============================] - 0s 145us/step - loss: 0.3639 - acc: 0.8437\n",
      "Epoch 95/100\n",
      "512/512 [==============================] - 0s 150us/step - loss: 0.3484 - acc: 0.8516\n",
      "Epoch 96/100\n",
      "512/512 [==============================] - 0s 144us/step - loss: 0.3426 - acc: 0.8535\n",
      "Epoch 97/100\n",
      "512/512 [==============================] - 0s 147us/step - loss: 0.3452 - acc: 0.8633\n",
      "Epoch 98/100\n",
      "512/512 [==============================] - 0s 146us/step - loss: 0.3428 - acc: 0.8516\n",
      "Epoch 99/100\n",
      "512/512 [==============================] - 0s 148us/step - loss: 0.3289 - acc: 0.8652\n",
      "Epoch 100/100\n",
      "512/512 [==============================] - 0s 138us/step - loss: 0.3325 - acc: 0.8672\n",
      "256/256 [==============================] - 0s 501us/step\n",
      "512/512 [==============================] - 0s 104us/step\n",
      "[CV]  batch_size=10, epochs=100, score=0.781249990221113, total=   8.1s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   42.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "512/512 [==============================] - 0s 813us/step - loss: 0.6750 - acc: 0.6582\n",
      "Epoch 2/10\n",
      "512/512 [==============================] - 0s 73us/step - loss: 0.6204 - acc: 0.7734\n",
      "Epoch 3/10\n",
      "512/512 [==============================] - 0s 73us/step - loss: 0.5736 - acc: 0.7715\n",
      "Epoch 4/10\n",
      "512/512 [==============================] - 0s 71us/step - loss: 0.5461 - acc: 0.7812\n",
      "Epoch 5/10\n",
      "512/512 [==============================] - 0s 75us/step - loss: 0.5230 - acc: 0.7754\n",
      "Epoch 6/10\n",
      "512/512 [==============================] - 0s 78us/step - loss: 0.5045 - acc: 0.7793\n",
      "Epoch 7/10\n",
      "512/512 [==============================] - 0s 73us/step - loss: 0.4940 - acc: 0.7988\n",
      "Epoch 8/10\n",
      "512/512 [==============================] - 0s 69us/step - loss: 0.4872 - acc: 0.7812\n",
      "Epoch 9/10\n",
      "512/512 [==============================] - 0s 66us/step - loss: 0.4758 - acc: 0.7891\n",
      "Epoch 10/10\n",
      "512/512 [==============================] - 0s 67us/step - loss: 0.4681 - acc: 0.8047\n",
      "256/256 [==============================] - 0s 484us/step\n",
      "512/512 [==============================] - 0s 65us/step\n",
      "[CV]  batch_size=20, epochs=10, score=0.7343749990686774, total=   1.3s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n",
      "Epoch 1/10\n",
      "512/512 [==============================] - 0s 853us/step - loss: 0.6344 - acc: 0.6387\n",
      "Epoch 2/10\n",
      "512/512 [==============================] - 0s 82us/step - loss: 0.5096 - acc: 0.6465\n",
      "Epoch 3/10\n",
      "512/512 [==============================] - 0s 66us/step - loss: 0.4858 - acc: 0.7285\n",
      "Epoch 4/10\n",
      "512/512 [==============================] - 0s 67us/step - loss: 0.4731 - acc: 0.7754\n",
      "Epoch 5/10\n",
      "512/512 [==============================] - 0s 90us/step - loss: 0.4629 - acc: 0.7773\n",
      "Epoch 6/10\n",
      "512/512 [==============================] - 0s 63us/step - loss: 0.4544 - acc: 0.7754\n",
      "Epoch 7/10\n",
      "512/512 [==============================] - 0s 77us/step - loss: 0.4429 - acc: 0.7949\n",
      "Epoch 8/10\n",
      "512/512 [==============================] - 0s 82us/step - loss: 0.4384 - acc: 0.7910\n",
      "Epoch 9/10\n",
      "512/512 [==============================] - 0s 65us/step - loss: 0.4357 - acc: 0.7949\n",
      "Epoch 10/10\n",
      "512/512 [==============================] - 0s 75us/step - loss: 0.4309 - acc: 0.7949\n",
      "256/256 [==============================] - 0s 537us/step\n",
      "512/512 [==============================] - 0s 52us/step\n",
      "[CV]  batch_size=20, epochs=10, score=0.7499999981373549, total=   1.3s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n",
      "Epoch 1/10\n",
      "512/512 [==============================] - 0s 909us/step - loss: 0.6262 - acc: 0.6777\n",
      "Epoch 2/10\n",
      "512/512 [==============================] - 0s 86us/step - loss: 0.5046 - acc: 0.7500\n",
      "Epoch 3/10\n",
      "512/512 [==============================] - 0s 80us/step - loss: 0.4866 - acc: 0.7598\n",
      "Epoch 4/10\n",
      "512/512 [==============================] - 0s 70us/step - loss: 0.4778 - acc: 0.7617\n",
      "Epoch 5/10\n",
      "512/512 [==============================] - 0s 70us/step - loss: 0.4747 - acc: 0.7715\n",
      "Epoch 6/10\n",
      "512/512 [==============================] - 0s 72us/step - loss: 0.4712 - acc: 0.7637\n",
      "Epoch 7/10\n",
      "512/512 [==============================] - 0s 68us/step - loss: 0.4666 - acc: 0.7656\n",
      "Epoch 8/10\n",
      "512/512 [==============================] - 0s 70us/step - loss: 0.4664 - acc: 0.7734\n",
      "Epoch 9/10\n",
      "512/512 [==============================] - 0s 68us/step - loss: 0.4698 - acc: 0.7637\n",
      "Epoch 10/10\n",
      "512/512 [==============================] - 0s 62us/step - loss: 0.4639 - acc: 0.7676\n",
      "256/256 [==============================] - 0s 589us/step\n",
      "512/512 [==============================] - 0s 46us/step\n",
      "[CV]  batch_size=20, epochs=10, score=0.7929687546566129, total=   1.3s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "Epoch 1/50\n",
      "512/512 [==============================] - 0s 967us/step - loss: 0.6106 - acc: 0.6523\n",
      "Epoch 2/50\n",
      "512/512 [==============================] - 0s 78us/step - loss: 0.4955 - acc: 0.6680\n",
      "Epoch 3/50\n",
      "512/512 [==============================] - 0s 73us/step - loss: 0.4707 - acc: 0.7480\n",
      "Epoch 4/50\n",
      "512/512 [==============================] - 0s 67us/step - loss: 0.4541 - acc: 0.7852\n",
      "Epoch 5/50\n",
      "512/512 [==============================] - 0s 70us/step - loss: 0.4447 - acc: 0.7910\n",
      "Epoch 6/50\n",
      "512/512 [==============================] - 0s 65us/step - loss: 0.4331 - acc: 0.8105\n",
      "Epoch 7/50\n",
      "512/512 [==============================] - 0s 66us/step - loss: 0.4307 - acc: 0.7949\n",
      "Epoch 8/50\n",
      "512/512 [==============================] - 0s 75us/step - loss: 0.4202 - acc: 0.8086\n",
      "Epoch 9/50\n",
      "512/512 [==============================] - 0s 70us/step - loss: 0.4189 - acc: 0.8047\n",
      "Epoch 10/50\n",
      "512/512 [==============================] - 0s 68us/step - loss: 0.4104 - acc: 0.7988\n",
      "Epoch 11/50\n",
      "512/512 [==============================] - 0s 72us/step - loss: 0.4050 - acc: 0.8086\n",
      "Epoch 12/50\n",
      "512/512 [==============================] - 0s 68us/step - loss: 0.4024 - acc: 0.8008\n",
      "Epoch 13/50\n",
      "512/512 [==============================] - 0s 73us/step - loss: 0.3965 - acc: 0.8164\n",
      "Epoch 14/50\n",
      "512/512 [==============================] - 0s 74us/step - loss: 0.3961 - acc: 0.8105\n",
      "Epoch 15/50\n",
      "512/512 [==============================] - 0s 73us/step - loss: 0.3909 - acc: 0.8184\n",
      "Epoch 16/50\n",
      "512/512 [==============================] - 0s 69us/step - loss: 0.3998 - acc: 0.8027\n",
      "Epoch 17/50\n",
      "512/512 [==============================] - 0s 74us/step - loss: 0.3981 - acc: 0.8145\n",
      "Epoch 18/50\n",
      "512/512 [==============================] - 0s 70us/step - loss: 0.3984 - acc: 0.8027\n",
      "Epoch 19/50\n",
      "512/512 [==============================] - 0s 78us/step - loss: 0.3963 - acc: 0.8223\n",
      "Epoch 20/50\n",
      "512/512 [==============================] - 0s 67us/step - loss: 0.3968 - acc: 0.8086\n",
      "Epoch 21/50\n",
      "512/512 [==============================] - 0s 70us/step - loss: 0.3952 - acc: 0.8164\n",
      "Epoch 22/50\n",
      "512/512 [==============================] - 0s 70us/step - loss: 0.3926 - acc: 0.8105\n",
      "Epoch 23/50\n",
      "512/512 [==============================] - 0s 73us/step - loss: 0.3928 - acc: 0.8145\n",
      "Epoch 24/50\n",
      "512/512 [==============================] - 0s 76us/step - loss: 0.3846 - acc: 0.8242\n",
      "Epoch 25/50\n",
      "512/512 [==============================] - 0s 77us/step - loss: 0.3893 - acc: 0.8203\n",
      "Epoch 26/50\n",
      "512/512 [==============================] - 0s 65us/step - loss: 0.3847 - acc: 0.8281\n",
      "Epoch 27/50\n",
      "512/512 [==============================] - 0s 77us/step - loss: 0.3873 - acc: 0.8184\n",
      "Epoch 28/50\n",
      "512/512 [==============================] - 0s 73us/step - loss: 0.3815 - acc: 0.8242\n",
      "Epoch 29/50\n",
      "512/512 [==============================] - 0s 63us/step - loss: 0.3800 - acc: 0.8242\n",
      "Epoch 30/50\n",
      "512/512 [==============================] - 0s 67us/step - loss: 0.3858 - acc: 0.8301\n",
      "Epoch 31/50\n",
      "512/512 [==============================] - 0s 70us/step - loss: 0.3787 - acc: 0.8301\n",
      "Epoch 32/50\n",
      "512/512 [==============================] - 0s 72us/step - loss: 0.3757 - acc: 0.8340\n",
      "Epoch 33/50\n",
      "512/512 [==============================] - 0s 68us/step - loss: 0.3778 - acc: 0.8262\n",
      "Epoch 34/50\n",
      "512/512 [==============================] - 0s 63us/step - loss: 0.3761 - acc: 0.8223\n",
      "Epoch 35/50\n",
      "512/512 [==============================] - 0s 65us/step - loss: 0.3751 - acc: 0.8359\n",
      "Epoch 36/50\n",
      "512/512 [==============================] - 0s 75us/step - loss: 0.3750 - acc: 0.8281\n",
      "Epoch 37/50\n",
      "512/512 [==============================] - 0s 64us/step - loss: 0.3720 - acc: 0.8223\n",
      "Epoch 38/50\n",
      "512/512 [==============================] - 0s 61us/step - loss: 0.3689 - acc: 0.8281\n",
      "Epoch 39/50\n",
      "512/512 [==============================] - 0s 69us/step - loss: 0.3722 - acc: 0.8320\n",
      "Epoch 40/50\n",
      "512/512 [==============================] - 0s 68us/step - loss: 0.3677 - acc: 0.8242\n",
      "Epoch 41/50\n",
      "512/512 [==============================] - 0s 74us/step - loss: 0.3706 - acc: 0.8281\n",
      "Epoch 42/50\n",
      "512/512 [==============================] - 0s 69us/step - loss: 0.3657 - acc: 0.8320\n",
      "Epoch 43/50\n",
      "512/512 [==============================] - 0s 72us/step - loss: 0.3661 - acc: 0.8320\n",
      "Epoch 44/50\n",
      "512/512 [==============================] - 0s 67us/step - loss: 0.3663 - acc: 0.8398\n",
      "Epoch 45/50\n",
      "512/512 [==============================] - 0s 74us/step - loss: 0.3691 - acc: 0.8340\n",
      "Epoch 46/50\n",
      "512/512 [==============================] - 0s 72us/step - loss: 0.3649 - acc: 0.8359\n",
      "Epoch 47/50\n",
      "512/512 [==============================] - 0s 76us/step - loss: 0.3560 - acc: 0.8359\n",
      "Epoch 48/50\n",
      "512/512 [==============================] - 0s 65us/step - loss: 0.3575 - acc: 0.8457\n",
      "Epoch 49/50\n",
      "512/512 [==============================] - 0s 72us/step - loss: 0.3561 - acc: 0.8457\n",
      "Epoch 50/50\n",
      "512/512 [==============================] - 0s 73us/step - loss: 0.3551 - acc: 0.8398\n",
      "256/256 [==============================] - 0s 626us/step\n",
      "512/512 [==============================] - 0s 53us/step\n",
      "[CV]  batch_size=20, epochs=50, score=0.7343749981373549, total=   3.0s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "Epoch 1/50\n",
      "512/512 [==============================] - 1s 1ms/step - loss: 0.6247 - acc: 0.6465\n",
      "Epoch 2/50\n",
      "512/512 [==============================] - 0s 83us/step - loss: 0.5082 - acc: 0.6465\n",
      "Epoch 3/50\n",
      "512/512 [==============================] - 0s 76us/step - loss: 0.4837 - acc: 0.7617\n",
      "Epoch 4/50\n",
      "512/512 [==============================] - 0s 76us/step - loss: 0.4724 - acc: 0.7773\n",
      "Epoch 5/50\n",
      "512/512 [==============================] - 0s 82us/step - loss: 0.4627 - acc: 0.7871\n",
      "Epoch 6/50\n",
      "512/512 [==============================] - 0s 72us/step - loss: 0.4552 - acc: 0.7832\n",
      "Epoch 7/50\n",
      "512/512 [==============================] - 0s 71us/step - loss: 0.4481 - acc: 0.7969\n",
      "Epoch 8/50\n",
      "512/512 [==============================] - 0s 73us/step - loss: 0.4416 - acc: 0.7930\n",
      "Epoch 9/50\n",
      "512/512 [==============================] - 0s 78us/step - loss: 0.4337 - acc: 0.7930\n",
      "Epoch 10/50\n",
      "512/512 [==============================] - 0s 85us/step - loss: 0.4352 - acc: 0.7930\n",
      "Epoch 11/50\n",
      "512/512 [==============================] - 0s 72us/step - loss: 0.4248 - acc: 0.7969\n",
      "Epoch 12/50\n",
      "512/512 [==============================] - 0s 80us/step - loss: 0.4241 - acc: 0.7988\n",
      "Epoch 13/50\n",
      "512/512 [==============================] - 0s 72us/step - loss: 0.4201 - acc: 0.7949\n",
      "Epoch 14/50\n",
      "512/512 [==============================] - 0s 73us/step - loss: 0.4210 - acc: 0.8008\n",
      "Epoch 15/50\n",
      "512/512 [==============================] - 0s 76us/step - loss: 0.4120 - acc: 0.7930\n",
      "Epoch 16/50\n",
      "512/512 [==============================] - 0s 79us/step - loss: 0.4118 - acc: 0.7969\n",
      "Epoch 17/50\n",
      "512/512 [==============================] - 0s 75us/step - loss: 0.4105 - acc: 0.8086\n",
      "Epoch 18/50\n",
      "512/512 [==============================] - 0s 76us/step - loss: 0.4037 - acc: 0.8125\n",
      "Epoch 19/50\n",
      "512/512 [==============================] - 0s 76us/step - loss: 0.4196 - acc: 0.7949\n",
      "Epoch 20/50\n",
      "512/512 [==============================] - 0s 73us/step - loss: 0.4009 - acc: 0.8145\n",
      "Epoch 21/50\n",
      "512/512 [==============================] - 0s 69us/step - loss: 0.4060 - acc: 0.8262\n",
      "Epoch 22/50\n",
      "512/512 [==============================] - 0s 66us/step - loss: 0.4040 - acc: 0.8184\n",
      "Epoch 23/50\n",
      "512/512 [==============================] - 0s 71us/step - loss: 0.3976 - acc: 0.8184\n",
      "Epoch 24/50\n",
      "512/512 [==============================] - 0s 66us/step - loss: 0.3987 - acc: 0.8047\n",
      "Epoch 25/50\n",
      "512/512 [==============================] - 0s 72us/step - loss: 0.3940 - acc: 0.8164\n",
      "Epoch 26/50\n",
      "512/512 [==============================] - 0s 66us/step - loss: 0.3951 - acc: 0.8164\n",
      "Epoch 27/50\n",
      "512/512 [==============================] - 0s 73us/step - loss: 0.3979 - acc: 0.8320\n",
      "Epoch 28/50\n",
      "512/512 [==============================] - 0s 68us/step - loss: 0.3906 - acc: 0.8320\n",
      "Epoch 29/50\n",
      "512/512 [==============================] - 0s 69us/step - loss: 0.3918 - acc: 0.8184\n",
      "Epoch 30/50\n",
      "512/512 [==============================] - 0s 70us/step - loss: 0.3961 - acc: 0.8164\n",
      "Epoch 31/50\n",
      "512/512 [==============================] - 0s 65us/step - loss: 0.3900 - acc: 0.8223\n",
      "Epoch 32/50\n",
      "512/512 [==============================] - 0s 79us/step - loss: 0.3853 - acc: 0.8320\n",
      "Epoch 33/50\n",
      "512/512 [==============================] - 0s 73us/step - loss: 0.3859 - acc: 0.8262\n",
      "Epoch 34/50\n",
      "512/512 [==============================] - 0s 74us/step - loss: 0.3873 - acc: 0.8262\n",
      "Epoch 35/50\n",
      "512/512 [==============================] - 0s 70us/step - loss: 0.3857 - acc: 0.8320\n",
      "Epoch 36/50\n",
      "512/512 [==============================] - 0s 75us/step - loss: 0.3852 - acc: 0.8262\n",
      "Epoch 37/50\n",
      "512/512 [==============================] - 0s 72us/step - loss: 0.3817 - acc: 0.8262\n",
      "Epoch 38/50\n",
      "512/512 [==============================] - 0s 74us/step - loss: 0.3837 - acc: 0.8457\n",
      "Epoch 39/50\n",
      "512/512 [==============================] - 0s 75us/step - loss: 0.3889 - acc: 0.8184\n",
      "Epoch 40/50\n",
      "512/512 [==============================] - 0s 74us/step - loss: 0.3861 - acc: 0.8301\n",
      "Epoch 41/50\n",
      "512/512 [==============================] - 0s 72us/step - loss: 0.3917 - acc: 0.8184\n",
      "Epoch 42/50\n",
      "512/512 [==============================] - 0s 70us/step - loss: 0.3843 - acc: 0.8262\n",
      "Epoch 43/50\n",
      "512/512 [==============================] - 0s 71us/step - loss: 0.3848 - acc: 0.8145\n",
      "Epoch 44/50\n",
      "512/512 [==============================] - 0s 61us/step - loss: 0.3784 - acc: 0.8359\n",
      "Epoch 45/50\n",
      "512/512 [==============================] - 0s 73us/step - loss: 0.3753 - acc: 0.8340\n",
      "Epoch 46/50\n",
      "512/512 [==============================] - 0s 71us/step - loss: 0.3831 - acc: 0.8320\n",
      "Epoch 47/50\n",
      "512/512 [==============================] - 0s 68us/step - loss: 0.3745 - acc: 0.8281\n",
      "Epoch 48/50\n",
      "512/512 [==============================] - 0s 75us/step - loss: 0.3827 - acc: 0.8164\n",
      "Epoch 49/50\n",
      "512/512 [==============================] - 0s 69us/step - loss: 0.3746 - acc: 0.8242\n",
      "Epoch 50/50\n",
      "512/512 [==============================] - 0s 88us/step - loss: 0.3729 - acc: 0.8301\n",
      "256/256 [==============================] - 0s 656us/step\n",
      "512/512 [==============================] - 0s 49us/step\n",
      "[CV]  batch_size=20, epochs=50, score=0.7343749897554517, total=   2.9s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "Epoch 1/50\n",
      "512/512 [==============================] - 1s 1ms/step - loss: 0.6396 - acc: 0.7070\n",
      "Epoch 2/50\n",
      "512/512 [==============================] - 0s 71us/step - loss: 0.5039 - acc: 0.7578\n",
      "Epoch 3/50\n",
      "512/512 [==============================] - 0s 66us/step - loss: 0.4907 - acc: 0.7598\n",
      "Epoch 4/50\n",
      "512/512 [==============================] - 0s 69us/step - loss: 0.4796 - acc: 0.7637\n",
      "Epoch 5/50\n",
      "512/512 [==============================] - 0s 79us/step - loss: 0.4744 - acc: 0.7734\n",
      "Epoch 6/50\n",
      "512/512 [==============================] - 0s 72us/step - loss: 0.4744 - acc: 0.7832\n",
      "Epoch 7/50\n",
      "512/512 [==============================] - 0s 65us/step - loss: 0.4747 - acc: 0.7617\n",
      "Epoch 8/50\n",
      "512/512 [==============================] - 0s 65us/step - loss: 0.4701 - acc: 0.7715\n",
      "Epoch 9/50\n",
      "512/512 [==============================] - 0s 66us/step - loss: 0.4628 - acc: 0.7832\n",
      "Epoch 10/50\n",
      "512/512 [==============================] - 0s 66us/step - loss: 0.4602 - acc: 0.7812\n",
      "Epoch 11/50\n",
      "512/512 [==============================] - 0s 74us/step - loss: 0.4637 - acc: 0.7793\n",
      "Epoch 12/50\n",
      "512/512 [==============================] - 0s 66us/step - loss: 0.4575 - acc: 0.7754\n",
      "Epoch 13/50\n",
      "512/512 [==============================] - 0s 66us/step - loss: 0.4581 - acc: 0.7773\n",
      "Epoch 14/50\n",
      "512/512 [==============================] - 0s 65us/step - loss: 0.4540 - acc: 0.7813\n",
      "Epoch 15/50\n",
      "512/512 [==============================] - 0s 67us/step - loss: 0.4599 - acc: 0.7793\n",
      "Epoch 16/50\n",
      "512/512 [==============================] - 0s 68us/step - loss: 0.4504 - acc: 0.7891\n",
      "Epoch 17/50\n",
      "512/512 [==============================] - 0s 67us/step - loss: 0.4514 - acc: 0.7891\n",
      "Epoch 18/50\n",
      "512/512 [==============================] - 0s 75us/step - loss: 0.4464 - acc: 0.7910\n",
      "Epoch 19/50\n",
      "512/512 [==============================] - 0s 72us/step - loss: 0.4459 - acc: 0.7930\n",
      "Epoch 20/50\n",
      "512/512 [==============================] - 0s 74us/step - loss: 0.4409 - acc: 0.7871\n",
      "Epoch 21/50\n",
      "512/512 [==============================] - 0s 67us/step - loss: 0.4440 - acc: 0.7871\n",
      "Epoch 22/50\n",
      "512/512 [==============================] - 0s 65us/step - loss: 0.4465 - acc: 0.7852\n",
      "Epoch 23/50\n",
      "512/512 [==============================] - 0s 75us/step - loss: 0.4472 - acc: 0.7813\n",
      "Epoch 24/50\n",
      "512/512 [==============================] - 0s 76us/step - loss: 0.4438 - acc: 0.7988\n",
      "Epoch 25/50\n",
      "512/512 [==============================] - 0s 73us/step - loss: 0.4376 - acc: 0.7969\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 68us/step - loss: 0.4341 - acc: 0.7930\n",
      "Epoch 27/50\n",
      "512/512 [==============================] - 0s 66us/step - loss: 0.4366 - acc: 0.7910\n",
      "Epoch 28/50\n",
      "512/512 [==============================] - 0s 72us/step - loss: 0.4369 - acc: 0.7969\n",
      "Epoch 29/50\n",
      "512/512 [==============================] - 0s 87us/step - loss: 0.4372 - acc: 0.7969\n",
      "Epoch 30/50\n",
      "512/512 [==============================] - 0s 80us/step - loss: 0.4335 - acc: 0.7969\n",
      "Epoch 31/50\n",
      "512/512 [==============================] - 0s 74us/step - loss: 0.4354 - acc: 0.7949\n",
      "Epoch 32/50\n",
      "512/512 [==============================] - 0s 74us/step - loss: 0.4297 - acc: 0.7852\n",
      "Epoch 33/50\n",
      "512/512 [==============================] - 0s 74us/step - loss: 0.4313 - acc: 0.7969\n",
      "Epoch 34/50\n",
      "512/512 [==============================] - 0s 80us/step - loss: 0.4308 - acc: 0.7949\n",
      "Epoch 35/50\n",
      "512/512 [==============================] - 0s 88us/step - loss: 0.4294 - acc: 0.7891\n",
      "Epoch 36/50\n",
      "512/512 [==============================] - 0s 80us/step - loss: 0.4231 - acc: 0.7988\n",
      "Epoch 37/50\n",
      "512/512 [==============================] - 0s 85us/step - loss: 0.4242 - acc: 0.8008\n",
      "Epoch 38/50\n",
      "512/512 [==============================] - 0s 71us/step - loss: 0.4245 - acc: 0.8047\n",
      "Epoch 39/50\n",
      "512/512 [==============================] - 0s 79us/step - loss: 0.4256 - acc: 0.7969\n",
      "Epoch 40/50\n",
      "512/512 [==============================] - 0s 69us/step - loss: 0.4179 - acc: 0.8145\n",
      "Epoch 41/50\n",
      "512/512 [==============================] - 0s 72us/step - loss: 0.4239 - acc: 0.8008\n",
      "Epoch 42/50\n",
      "512/512 [==============================] - 0s 72us/step - loss: 0.4186 - acc: 0.8047\n",
      "Epoch 43/50\n",
      "512/512 [==============================] - 0s 67us/step - loss: 0.4198 - acc: 0.8066\n",
      "Epoch 44/50\n",
      "512/512 [==============================] - 0s 70us/step - loss: 0.4193 - acc: 0.7988\n",
      "Epoch 45/50\n",
      "512/512 [==============================] - 0s 73us/step - loss: 0.4163 - acc: 0.8086\n",
      "Epoch 46/50\n",
      "512/512 [==============================] - 0s 67us/step - loss: 0.4181 - acc: 0.8008\n",
      "Epoch 47/50\n",
      "512/512 [==============================] - 0s 78us/step - loss: 0.4133 - acc: 0.7988\n",
      "Epoch 48/50\n",
      "512/512 [==============================] - 0s 84us/step - loss: 0.4091 - acc: 0.8047\n",
      "Epoch 49/50\n",
      "512/512 [==============================] - 0s 79us/step - loss: 0.4083 - acc: 0.8066\n",
      "Epoch 50/50\n",
      "512/512 [==============================] - 0s 76us/step - loss: 0.4117 - acc: 0.8125\n",
      "256/256 [==============================] - 0s 700us/step\n",
      "512/512 [==============================] - 0s 58us/step\n",
      "[CV]  batch_size=20, epochs=50, score=0.785156263038516, total=   3.0s\n",
      "[CV] batch_size=20, epochs=100 .......................................\n",
      "Epoch 1/100\n",
      "512/512 [==============================] - 1s 1ms/step - loss: 0.6528 - acc: 0.7012\n",
      "Epoch 2/100\n",
      "512/512 [==============================] - 0s 68us/step - loss: 0.5130 - acc: 0.7734\n",
      "Epoch 3/100\n",
      "512/512 [==============================] - 0s 76us/step - loss: 0.4555 - acc: 0.7754\n",
      "Epoch 4/100\n",
      "512/512 [==============================] - 0s 77us/step - loss: 0.4440 - acc: 0.7773\n",
      "Epoch 5/100\n",
      "512/512 [==============================] - 0s 75us/step - loss: 0.4372 - acc: 0.7949\n",
      "Epoch 6/100\n",
      "512/512 [==============================] - 0s 72us/step - loss: 0.4347 - acc: 0.7969\n",
      "Epoch 7/100\n",
      "512/512 [==============================] - 0s 76us/step - loss: 0.4332 - acc: 0.7930\n",
      "Epoch 8/100\n",
      "512/512 [==============================] - 0s 83us/step - loss: 0.4290 - acc: 0.8086\n",
      "Epoch 9/100\n",
      "512/512 [==============================] - 0s 81us/step - loss: 0.4275 - acc: 0.7813\n",
      "Epoch 10/100\n",
      "512/512 [==============================] - 0s 75us/step - loss: 0.4277 - acc: 0.8008\n",
      "Epoch 11/100\n",
      "512/512 [==============================] - 0s 79us/step - loss: 0.4246 - acc: 0.8027\n",
      "Epoch 12/100\n",
      "512/512 [==============================] - 0s 66us/step - loss: 0.4205 - acc: 0.7949\n",
      "Epoch 13/100\n",
      "512/512 [==============================] - 0s 68us/step - loss: 0.4150 - acc: 0.8027\n",
      "Epoch 14/100\n",
      "512/512 [==============================] - 0s 68us/step - loss: 0.4139 - acc: 0.8008\n",
      "Epoch 15/100\n",
      "512/512 [==============================] - 0s 70us/step - loss: 0.4109 - acc: 0.8086\n",
      "Epoch 16/100\n",
      "512/512 [==============================] - 0s 71us/step - loss: 0.4081 - acc: 0.8145\n",
      "Epoch 17/100\n",
      "512/512 [==============================] - 0s 74us/step - loss: 0.4083 - acc: 0.8008\n",
      "Epoch 18/100\n",
      "512/512 [==============================] - 0s 76us/step - loss: 0.4062 - acc: 0.8008\n",
      "Epoch 19/100\n",
      "512/512 [==============================] - 0s 77us/step - loss: 0.4090 - acc: 0.8086\n",
      "Epoch 20/100\n",
      "512/512 [==============================] - 0s 73us/step - loss: 0.4021 - acc: 0.8086\n",
      "Epoch 21/100\n",
      "512/512 [==============================] - 0s 69us/step - loss: 0.3998 - acc: 0.8105\n",
      "Epoch 22/100\n",
      "512/512 [==============================] - 0s 70us/step - loss: 0.3944 - acc: 0.8184\n",
      "Epoch 23/100\n",
      "512/512 [==============================] - 0s 74us/step - loss: 0.3953 - acc: 0.8164\n",
      "Epoch 24/100\n",
      "512/512 [==============================] - 0s 71us/step - loss: 0.3925 - acc: 0.8184\n",
      "Epoch 25/100\n",
      "512/512 [==============================] - 0s 68us/step - loss: 0.3896 - acc: 0.8203\n",
      "Epoch 26/100\n",
      "512/512 [==============================] - 0s 74us/step - loss: 0.3875 - acc: 0.8184\n",
      "Epoch 27/100\n",
      "512/512 [==============================] - 0s 70us/step - loss: 0.3913 - acc: 0.8203\n",
      "Epoch 28/100\n",
      "512/512 [==============================] - 0s 71us/step - loss: 0.3856 - acc: 0.8242\n",
      "Epoch 29/100\n",
      "512/512 [==============================] - 0s 65us/step - loss: 0.3893 - acc: 0.8223\n",
      "Epoch 30/100\n",
      "512/512 [==============================] - 0s 68us/step - loss: 0.3872 - acc: 0.8242\n",
      "Epoch 31/100\n",
      "512/512 [==============================] - 0s 67us/step - loss: 0.3884 - acc: 0.8203\n",
      "Epoch 32/100\n",
      "512/512 [==============================] - 0s 72us/step - loss: 0.3798 - acc: 0.8242\n",
      "Epoch 33/100\n",
      "512/512 [==============================] - 0s 72us/step - loss: 0.3758 - acc: 0.8301\n",
      "Epoch 34/100\n",
      "512/512 [==============================] - 0s 66us/step - loss: 0.3734 - acc: 0.8301\n",
      "Epoch 35/100\n",
      "512/512 [==============================] - 0s 66us/step - loss: 0.3754 - acc: 0.8242\n",
      "Epoch 36/100\n",
      "512/512 [==============================] - 0s 71us/step - loss: 0.3746 - acc: 0.8320\n",
      "Epoch 37/100\n",
      "512/512 [==============================] - 0s 77us/step - loss: 0.3720 - acc: 0.8340\n",
      "Epoch 38/100\n",
      "512/512 [==============================] - 0s 75us/step - loss: 0.3666 - acc: 0.8398\n",
      "Epoch 39/100\n",
      "512/512 [==============================] - 0s 77us/step - loss: 0.3650 - acc: 0.8398\n",
      "Epoch 40/100\n",
      "512/512 [==============================] - 0s 73us/step - loss: 0.3674 - acc: 0.8340\n",
      "Epoch 41/100\n",
      "512/512 [==============================] - 0s 78us/step - loss: 0.3638 - acc: 0.8398\n",
      "Epoch 42/100\n",
      "512/512 [==============================] - 0s 72us/step - loss: 0.3639 - acc: 0.8320\n",
      "Epoch 43/100\n",
      "512/512 [==============================] - 0s 69us/step - loss: 0.3591 - acc: 0.8320\n",
      "Epoch 44/100\n",
      "512/512 [==============================] - 0s 65us/step - loss: 0.3591 - acc: 0.8398\n",
      "Epoch 45/100\n",
      "512/512 [==============================] - 0s 74us/step - loss: 0.3692 - acc: 0.8281\n",
      "Epoch 46/100\n",
      "512/512 [==============================] - 0s 71us/step - loss: 0.3642 - acc: 0.8281\n",
      "Epoch 47/100\n",
      "512/512 [==============================] - 0s 74us/step - loss: 0.3609 - acc: 0.8398\n",
      "Epoch 48/100\n",
      "512/512 [==============================] - 0s 71us/step - loss: 0.3572 - acc: 0.8457\n",
      "Epoch 49/100\n",
      "512/512 [==============================] - 0s 70us/step - loss: 0.3558 - acc: 0.8418\n",
      "Epoch 50/100\n",
      "512/512 [==============================] - 0s 70us/step - loss: 0.3568 - acc: 0.8418\n",
      "Epoch 51/100\n",
      "512/512 [==============================] - 0s 70us/step - loss: 0.3577 - acc: 0.8398\n",
      "Epoch 52/100\n",
      "512/512 [==============================] - 0s 70us/step - loss: 0.3532 - acc: 0.8418\n",
      "Epoch 53/100\n",
      "512/512 [==============================] - 0s 69us/step - loss: 0.3533 - acc: 0.8477\n",
      "Epoch 54/100\n",
      "512/512 [==============================] - 0s 71us/step - loss: 0.3582 - acc: 0.8496\n",
      "Epoch 55/100\n",
      "512/512 [==============================] - 0s 73us/step - loss: 0.3575 - acc: 0.8301\n",
      "Epoch 56/100\n",
      "512/512 [==============================] - 0s 67us/step - loss: 0.3523 - acc: 0.8477\n",
      "Epoch 57/100\n",
      "512/512 [==============================] - 0s 70us/step - loss: 0.3504 - acc: 0.8398\n",
      "Epoch 58/100\n",
      "512/512 [==============================] - 0s 73us/step - loss: 0.3527 - acc: 0.8398\n",
      "Epoch 59/100\n",
      "512/512 [==============================] - 0s 80us/step - loss: 0.3522 - acc: 0.8457\n",
      "Epoch 60/100\n",
      "512/512 [==============================] - 0s 71us/step - loss: 0.3477 - acc: 0.8457\n",
      "Epoch 61/100\n",
      "512/512 [==============================] - 0s 75us/step - loss: 0.3464 - acc: 0.8379\n",
      "Epoch 62/100\n",
      "512/512 [==============================] - 0s 75us/step - loss: 0.3557 - acc: 0.8379\n",
      "Epoch 63/100\n",
      "512/512 [==============================] - 0s 67us/step - loss: 0.3501 - acc: 0.8418\n",
      "Epoch 64/100\n",
      "512/512 [==============================] - 0s 73us/step - loss: 0.3464 - acc: 0.8340\n",
      "Epoch 65/100\n",
      "512/512 [==============================] - 0s 74us/step - loss: 0.3461 - acc: 0.8398\n",
      "Epoch 66/100\n",
      "512/512 [==============================] - 0s 73us/step - loss: 0.3450 - acc: 0.8359\n",
      "Epoch 67/100\n",
      "512/512 [==============================] - 0s 79us/step - loss: 0.3448 - acc: 0.8438\n",
      "Epoch 68/100\n",
      "512/512 [==============================] - 0s 74us/step - loss: 0.3495 - acc: 0.8438\n",
      "Epoch 69/100\n",
      "512/512 [==============================] - 0s 68us/step - loss: 0.3475 - acc: 0.8457\n",
      "Epoch 70/100\n",
      "512/512 [==============================] - 0s 80us/step - loss: 0.3458 - acc: 0.8379\n",
      "Epoch 71/100\n",
      "512/512 [==============================] - 0s 70us/step - loss: 0.3407 - acc: 0.8398\n",
      "Epoch 72/100\n",
      "512/512 [==============================] - 0s 77us/step - loss: 0.3433 - acc: 0.8359\n",
      "Epoch 73/100\n",
      "512/512 [==============================] - 0s 87us/step - loss: 0.3398 - acc: 0.8438\n",
      "Epoch 74/100\n",
      "512/512 [==============================] - 0s 71us/step - loss: 0.3386 - acc: 0.8496\n",
      "Epoch 75/100\n",
      "512/512 [==============================] - 0s 77us/step - loss: 0.3419 - acc: 0.8379\n",
      "Epoch 76/100\n",
      "512/512 [==============================] - 0s 69us/step - loss: 0.3403 - acc: 0.8477\n",
      "Epoch 77/100\n",
      "512/512 [==============================] - 0s 76us/step - loss: 0.3496 - acc: 0.8437\n",
      "Epoch 78/100\n",
      "512/512 [==============================] - 0s 78us/step - loss: 0.3425 - acc: 0.8437\n",
      "Epoch 79/100\n",
      "512/512 [==============================] - 0s 70us/step - loss: 0.3408 - acc: 0.8438\n",
      "Epoch 80/100\n",
      "512/512 [==============================] - 0s 75us/step - loss: 0.3390 - acc: 0.8418\n",
      "Epoch 81/100\n",
      "512/512 [==============================] - 0s 75us/step - loss: 0.3409 - acc: 0.8437\n",
      "Epoch 82/100\n",
      "512/512 [==============================] - 0s 72us/step - loss: 0.3346 - acc: 0.8418\n",
      "Epoch 83/100\n",
      "512/512 [==============================] - 0s 75us/step - loss: 0.3386 - acc: 0.8418\n",
      "Epoch 84/100\n",
      "512/512 [==============================] - 0s 71us/step - loss: 0.3412 - acc: 0.8477\n",
      "Epoch 85/100\n",
      "512/512 [==============================] - 0s 82us/step - loss: 0.3381 - acc: 0.8379\n",
      "Epoch 86/100\n",
      "512/512 [==============================] - 0s 76us/step - loss: 0.3369 - acc: 0.8477\n",
      "Epoch 87/100\n",
      "512/512 [==============================] - 0s 75us/step - loss: 0.3334 - acc: 0.8418\n",
      "Epoch 88/100\n",
      "512/512 [==============================] - 0s 73us/step - loss: 0.3385 - acc: 0.8359\n",
      "Epoch 89/100\n",
      "512/512 [==============================] - 0s 73us/step - loss: 0.3422 - acc: 0.8320\n",
      "Epoch 90/100\n",
      "512/512 [==============================] - 0s 72us/step - loss: 0.3382 - acc: 0.8457\n",
      "Epoch 91/100\n",
      "512/512 [==============================] - 0s 77us/step - loss: 0.3334 - acc: 0.8457\n",
      "Epoch 92/100\n",
      "512/512 [==============================] - 0s 67us/step - loss: 0.3402 - acc: 0.8496\n",
      "Epoch 93/100\n",
      "512/512 [==============================] - 0s 68us/step - loss: 0.3337 - acc: 0.8340\n",
      "Epoch 94/100\n",
      "512/512 [==============================] - 0s 76us/step - loss: 0.3399 - acc: 0.8477\n",
      "Epoch 95/100\n",
      "512/512 [==============================] - 0s 72us/step - loss: 0.3342 - acc: 0.8438\n",
      "Epoch 96/100\n",
      "512/512 [==============================] - 0s 74us/step - loss: 0.3361 - acc: 0.8398\n",
      "Epoch 97/100\n",
      "512/512 [==============================] - 0s 79us/step - loss: 0.3324 - acc: 0.8379\n",
      "Epoch 98/100\n",
      "512/512 [==============================] - 0s 70us/step - loss: 0.3322 - acc: 0.8398\n",
      "Epoch 99/100\n",
      "512/512 [==============================] - 0s 79us/step - loss: 0.3318 - acc: 0.8438\n",
      "Epoch 100/100\n",
      "512/512 [==============================] - 0s 78us/step - loss: 0.3334 - acc: 0.8496\n",
      "256/256 [==============================] - 0s 744us/step\n",
      "512/512 [==============================] - 0s 45us/step\n",
      "[CV]  batch_size=20, epochs=100, score=0.7499999972060323, total=   4.9s\n",
      "[CV] batch_size=20, epochs=100 .......................................\n",
      "Epoch 1/100\n",
      "512/512 [==============================] - 1s 1ms/step - loss: 0.6021 - acc: 0.6836\n",
      "Epoch 2/100\n",
      "512/512 [==============================] - 0s 80us/step - loss: 0.4735 - acc: 0.7695\n",
      "Epoch 3/100\n",
      "512/512 [==============================] - 0s 72us/step - loss: 0.4578 - acc: 0.7695\n",
      "Epoch 4/100\n",
      "512/512 [==============================] - 0s 70us/step - loss: 0.4393 - acc: 0.7832\n",
      "Epoch 5/100\n",
      "512/512 [==============================] - 0s 76us/step - loss: 0.4325 - acc: 0.7812\n",
      "Epoch 6/100\n",
      "512/512 [==============================] - 0s 79us/step - loss: 0.4280 - acc: 0.7773\n",
      "Epoch 7/100\n",
      "512/512 [==============================] - 0s 67us/step - loss: 0.4227 - acc: 0.7930\n",
      "Epoch 8/100\n",
      "512/512 [==============================] - 0s 70us/step - loss: 0.4203 - acc: 0.7813\n",
      "Epoch 9/100\n",
      "512/512 [==============================] - 0s 74us/step - loss: 0.4232 - acc: 0.7930\n",
      "Epoch 10/100\n",
      "512/512 [==============================] - 0s 67us/step - loss: 0.4229 - acc: 0.7754\n",
      "Epoch 11/100\n",
      "512/512 [==============================] - 0s 72us/step - loss: 0.4172 - acc: 0.7813\n",
      "Epoch 12/100\n",
      "512/512 [==============================] - 0s 69us/step - loss: 0.4120 - acc: 0.7891\n",
      "Epoch 13/100\n",
      "512/512 [==============================] - 0s 76us/step - loss: 0.4148 - acc: 0.7891\n",
      "Epoch 14/100\n",
      "512/512 [==============================] - 0s 69us/step - loss: 0.4119 - acc: 0.7930\n",
      "Epoch 15/100\n",
      "512/512 [==============================] - 0s 75us/step - loss: 0.4153 - acc: 0.7930\n",
      "Epoch 16/100\n",
      "512/512 [==============================] - 0s 72us/step - loss: 0.4086 - acc: 0.7930\n",
      "Epoch 17/100\n",
      "512/512 [==============================] - 0s 69us/step - loss: 0.4086 - acc: 0.7793\n",
      "Epoch 18/100\n",
      "512/512 [==============================] - 0s 70us/step - loss: 0.4125 - acc: 0.7988\n",
      "Epoch 19/100\n",
      "512/512 [==============================] - 0s 74us/step - loss: 0.4135 - acc: 0.7988\n",
      "Epoch 20/100\n",
      "512/512 [==============================] - 0s 71us/step - loss: 0.4077 - acc: 0.7988\n",
      "Epoch 21/100\n",
      "512/512 [==============================] - 0s 68us/step - loss: 0.4050 - acc: 0.8008\n",
      "Epoch 22/100\n",
      "512/512 [==============================] - 0s 75us/step - loss: 0.4064 - acc: 0.7988\n",
      "Epoch 23/100\n",
      "512/512 [==============================] - 0s 66us/step - loss: 0.4062 - acc: 0.7988\n",
      "Epoch 24/100\n",
      "512/512 [==============================] - 0s 67us/step - loss: 0.4069 - acc: 0.8008\n",
      "Epoch 25/100\n",
      "512/512 [==============================] - 0s 68us/step - loss: 0.4076 - acc: 0.8027\n",
      "Epoch 26/100\n",
      "512/512 [==============================] - 0s 76us/step - loss: 0.4088 - acc: 0.7871\n",
      "Epoch 27/100\n",
      "512/512 [==============================] - 0s 72us/step - loss: 0.4016 - acc: 0.8086\n",
      "Epoch 28/100\n",
      "512/512 [==============================] - 0s 66us/step - loss: 0.4048 - acc: 0.8047\n",
      "Epoch 29/100\n",
      "512/512 [==============================] - 0s 70us/step - loss: 0.4086 - acc: 0.7910\n",
      "Epoch 30/100\n",
      "512/512 [==============================] - 0s 69us/step - loss: 0.4101 - acc: 0.7871\n",
      "Epoch 31/100\n",
      "512/512 [==============================] - 0s 73us/step - loss: 0.4059 - acc: 0.7988\n",
      "Epoch 32/100\n",
      "512/512 [==============================] - 0s 75us/step - loss: 0.4037 - acc: 0.8066\n",
      "Epoch 33/100\n",
      "512/512 [==============================] - 0s 70us/step - loss: 0.4012 - acc: 0.8047\n",
      "Epoch 34/100\n",
      "512/512 [==============================] - 0s 70us/step - loss: 0.3978 - acc: 0.8047\n",
      "Epoch 35/100\n",
      "512/512 [==============================] - 0s 67us/step - loss: 0.4029 - acc: 0.8008\n",
      "Epoch 36/100\n",
      "512/512 [==============================] - 0s 72us/step - loss: 0.4066 - acc: 0.7988\n",
      "Epoch 37/100\n",
      "512/512 [==============================] - 0s 68us/step - loss: 0.4014 - acc: 0.7988\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 63us/step - loss: 0.4037 - acc: 0.8027\n",
      "Epoch 39/100\n",
      "512/512 [==============================] - 0s 74us/step - loss: 0.3999 - acc: 0.7949\n",
      "Epoch 40/100\n",
      "512/512 [==============================] - 0s 75us/step - loss: 0.3984 - acc: 0.8027\n",
      "Epoch 41/100\n",
      "512/512 [==============================] - 0s 79us/step - loss: 0.4036 - acc: 0.7930\n",
      "Epoch 42/100\n",
      "512/512 [==============================] - 0s 77us/step - loss: 0.4035 - acc: 0.7930\n",
      "Epoch 43/100\n",
      "512/512 [==============================] - 0s 66us/step - loss: 0.3975 - acc: 0.7930\n",
      "Epoch 44/100\n",
      "512/512 [==============================] - 0s 86us/step - loss: 0.4002 - acc: 0.7949\n",
      "Epoch 45/100\n",
      "512/512 [==============================] - 0s 70us/step - loss: 0.3982 - acc: 0.8008\n",
      "Epoch 46/100\n",
      "512/512 [==============================] - 0s 78us/step - loss: 0.3986 - acc: 0.7988\n",
      "Epoch 47/100\n",
      "512/512 [==============================] - 0s 80us/step - loss: 0.3952 - acc: 0.7988\n",
      "Epoch 48/100\n",
      "512/512 [==============================] - 0s 76us/step - loss: 0.3978 - acc: 0.8047\n",
      "Epoch 49/100\n",
      "512/512 [==============================] - 0s 71us/step - loss: 0.3956 - acc: 0.7930\n",
      "Epoch 50/100\n",
      "512/512 [==============================] - 0s 71us/step - loss: 0.3955 - acc: 0.7969\n",
      "Epoch 51/100\n",
      "512/512 [==============================] - 0s 73us/step - loss: 0.3936 - acc: 0.8086\n",
      "Epoch 52/100\n",
      "512/512 [==============================] - 0s 92us/step - loss: 0.3957 - acc: 0.7988\n",
      "Epoch 53/100\n",
      "512/512 [==============================] - 0s 73us/step - loss: 0.3977 - acc: 0.8027\n",
      "Epoch 54/100\n",
      "512/512 [==============================] - 0s 76us/step - loss: 0.3986 - acc: 0.8027\n",
      "Epoch 55/100\n",
      "512/512 [==============================] - 0s 84us/step - loss: 0.3973 - acc: 0.7988\n",
      "Epoch 56/100\n",
      "512/512 [==============================] - 0s 72us/step - loss: 0.3950 - acc: 0.8086\n",
      "Epoch 57/100\n",
      "512/512 [==============================] - 0s 73us/step - loss: 0.3979 - acc: 0.7988\n",
      "Epoch 58/100\n",
      "512/512 [==============================] - 0s 75us/step - loss: 0.3987 - acc: 0.8008\n",
      "Epoch 59/100\n",
      "512/512 [==============================] - 0s 86us/step - loss: 0.3949 - acc: 0.7949\n",
      "Epoch 60/100\n",
      "512/512 [==============================] - 0s 73us/step - loss: 0.3909 - acc: 0.8105\n",
      "Epoch 61/100\n",
      "512/512 [==============================] - 0s 70us/step - loss: 0.3902 - acc: 0.8047\n",
      "Epoch 62/100\n",
      "512/512 [==============================] - 0s 80us/step - loss: 0.3924 - acc: 0.8047\n",
      "Epoch 63/100\n",
      "512/512 [==============================] - 0s 76us/step - loss: 0.3887 - acc: 0.8066\n",
      "Epoch 64/100\n",
      "512/512 [==============================] - 0s 78us/step - loss: 0.3921 - acc: 0.8125\n",
      "Epoch 65/100\n",
      "512/512 [==============================] - 0s 68us/step - loss: 0.3908 - acc: 0.8105\n",
      "Epoch 66/100\n",
      "512/512 [==============================] - 0s 76us/step - loss: 0.3939 - acc: 0.8008\n",
      "Epoch 67/100\n",
      "512/512 [==============================] - 0s 73us/step - loss: 0.3899 - acc: 0.8008\n",
      "Epoch 68/100\n",
      "512/512 [==============================] - 0s 73us/step - loss: 0.3887 - acc: 0.8164\n",
      "Epoch 69/100\n",
      "512/512 [==============================] - 0s 74us/step - loss: 0.3876 - acc: 0.8203\n",
      "Epoch 70/100\n",
      "512/512 [==============================] - 0s 79us/step - loss: 0.3974 - acc: 0.8105\n",
      "Epoch 71/100\n",
      "512/512 [==============================] - 0s 67us/step - loss: 0.3832 - acc: 0.8242\n",
      "Epoch 72/100\n",
      "512/512 [==============================] - 0s 71us/step - loss: 0.3834 - acc: 0.8164\n",
      "Epoch 73/100\n",
      "512/512 [==============================] - 0s 69us/step - loss: 0.3786 - acc: 0.8125\n",
      "Epoch 74/100\n",
      "512/512 [==============================] - 0s 75us/step - loss: 0.3851 - acc: 0.8125\n",
      "Epoch 75/100\n",
      "512/512 [==============================] - 0s 85us/step - loss: 0.3793 - acc: 0.8242\n",
      "Epoch 76/100\n",
      "512/512 [==============================] - 0s 84us/step - loss: 0.3794 - acc: 0.8145\n",
      "Epoch 77/100\n",
      "512/512 [==============================] - 0s 75us/step - loss: 0.3762 - acc: 0.8320\n",
      "Epoch 78/100\n",
      "512/512 [==============================] - 0s 81us/step - loss: 0.3754 - acc: 0.8320\n",
      "Epoch 79/100\n",
      "512/512 [==============================] - 0s 65us/step - loss: 0.3796 - acc: 0.8242\n",
      "Epoch 80/100\n",
      "512/512 [==============================] - 0s 75us/step - loss: 0.3779 - acc: 0.8242\n",
      "Epoch 81/100\n",
      "512/512 [==============================] - 0s 66us/step - loss: 0.3741 - acc: 0.8125\n",
      "Epoch 82/100\n",
      "512/512 [==============================] - 0s 71us/step - loss: 0.3852 - acc: 0.8066\n",
      "Epoch 83/100\n",
      "512/512 [==============================] - 0s 81us/step - loss: 0.3735 - acc: 0.8125\n",
      "Epoch 84/100\n",
      "512/512 [==============================] - 0s 69us/step - loss: 0.3746 - acc: 0.8164\n",
      "Epoch 85/100\n",
      "512/512 [==============================] - 0s 76us/step - loss: 0.3750 - acc: 0.8223\n",
      "Epoch 86/100\n",
      "512/512 [==============================] - 0s 70us/step - loss: 0.3741 - acc: 0.8242\n",
      "Epoch 87/100\n",
      "512/512 [==============================] - 0s 75us/step - loss: 0.3714 - acc: 0.8145\n",
      "Epoch 88/100\n",
      "512/512 [==============================] - 0s 68us/step - loss: 0.3738 - acc: 0.8223\n",
      "Epoch 89/100\n",
      "512/512 [==============================] - 0s 75us/step - loss: 0.3715 - acc: 0.8164\n",
      "Epoch 90/100\n",
      "512/512 [==============================] - 0s 72us/step - loss: 0.3692 - acc: 0.8301\n",
      "Epoch 91/100\n",
      "512/512 [==============================] - 0s 75us/step - loss: 0.3716 - acc: 0.8223\n",
      "Epoch 92/100\n",
      "512/512 [==============================] - 0s 78us/step - loss: 0.3696 - acc: 0.8320\n",
      "Epoch 93/100\n",
      "512/512 [==============================] - 0s 69us/step - loss: 0.3863 - acc: 0.8203\n",
      "Epoch 94/100\n",
      "512/512 [==============================] - 0s 70us/step - loss: 0.3670 - acc: 0.8164\n",
      "Epoch 95/100\n",
      "512/512 [==============================] - 0s 75us/step - loss: 0.3688 - acc: 0.8457\n",
      "Epoch 96/100\n",
      "512/512 [==============================] - 0s 69us/step - loss: 0.3756 - acc: 0.8203\n",
      "Epoch 97/100\n",
      "512/512 [==============================] - 0s 71us/step - loss: 0.3755 - acc: 0.8164\n",
      "Epoch 98/100\n",
      "512/512 [==============================] - 0s 73us/step - loss: 0.3694 - acc: 0.8223\n",
      "Epoch 99/100\n",
      "512/512 [==============================] - 0s 72us/step - loss: 0.3711 - acc: 0.8184\n",
      "Epoch 100/100\n",
      "512/512 [==============================] - 0s 72us/step - loss: 0.3742 - acc: 0.8223\n",
      "256/256 [==============================] - 0s 809us/step\n",
      "512/512 [==============================] - 0s 43us/step\n",
      "[CV]  batch_size=20, epochs=100, score=0.7421874962747097, total=   5.1s\n",
      "[CV] batch_size=20, epochs=100 .......................................\n",
      "Epoch 1/100\n",
      "512/512 [==============================] - 1s 1ms/step - loss: 0.6237 - acc: 0.6348\n",
      "Epoch 2/100\n",
      "512/512 [==============================] - 0s 81us/step - loss: 0.5372 - acc: 0.6387\n",
      "Epoch 3/100\n",
      "512/512 [==============================] - 0s 71us/step - loss: 0.5195 - acc: 0.7207\n",
      "Epoch 4/100\n",
      "512/512 [==============================] - 0s 69us/step - loss: 0.5084 - acc: 0.7715\n",
      "Epoch 5/100\n",
      "512/512 [==============================] - 0s 69us/step - loss: 0.4983 - acc: 0.7773\n",
      "Epoch 6/100\n",
      "512/512 [==============================] - 0s 79us/step - loss: 0.4953 - acc: 0.7734\n",
      "Epoch 7/100\n",
      "512/512 [==============================] - 0s 70us/step - loss: 0.4878 - acc: 0.7754\n",
      "Epoch 8/100\n",
      "512/512 [==============================] - 0s 77us/step - loss: 0.4818 - acc: 0.7813\n",
      "Epoch 9/100\n",
      "512/512 [==============================] - 0s 80us/step - loss: 0.4767 - acc: 0.7832\n",
      "Epoch 10/100\n",
      "512/512 [==============================] - 0s 74us/step - loss: 0.4751 - acc: 0.7773\n",
      "Epoch 11/100\n",
      "512/512 [==============================] - 0s 67us/step - loss: 0.4683 - acc: 0.7871\n",
      "Epoch 12/100\n",
      "512/512 [==============================] - 0s 76us/step - loss: 0.4639 - acc: 0.7832\n",
      "Epoch 13/100\n",
      "512/512 [==============================] - 0s 65us/step - loss: 0.4679 - acc: 0.7910\n",
      "Epoch 14/100\n",
      "512/512 [==============================] - 0s 76us/step - loss: 0.4586 - acc: 0.7969\n",
      "Epoch 15/100\n",
      "512/512 [==============================] - 0s 72us/step - loss: 0.4550 - acc: 0.7852\n",
      "Epoch 16/100\n",
      "512/512 [==============================] - 0s 77us/step - loss: 0.4493 - acc: 0.7949\n",
      "Epoch 17/100\n",
      "512/512 [==============================] - 0s 75us/step - loss: 0.4458 - acc: 0.7949\n",
      "Epoch 18/100\n",
      "512/512 [==============================] - 0s 77us/step - loss: 0.4454 - acc: 0.7969\n",
      "Epoch 19/100\n",
      "512/512 [==============================] - 0s 68us/step - loss: 0.4446 - acc: 0.7930\n",
      "Epoch 20/100\n",
      "512/512 [==============================] - 0s 75us/step - loss: 0.4491 - acc: 0.7949\n",
      "Epoch 21/100\n",
      "512/512 [==============================] - 0s 87us/step - loss: 0.4400 - acc: 0.7969\n",
      "Epoch 22/100\n",
      "512/512 [==============================] - 0s 81us/step - loss: 0.4433 - acc: 0.7969\n",
      "Epoch 23/100\n",
      "512/512 [==============================] - 0s 73us/step - loss: 0.4424 - acc: 0.7930\n",
      "Epoch 24/100\n",
      "512/512 [==============================] - 0s 72us/step - loss: 0.4396 - acc: 0.7988\n",
      "Epoch 25/100\n",
      "512/512 [==============================] - 0s 76us/step - loss: 0.4356 - acc: 0.7988\n",
      "Epoch 26/100\n",
      "512/512 [==============================] - 0s 70us/step - loss: 0.4328 - acc: 0.8086\n",
      "Epoch 27/100\n",
      "512/512 [==============================] - 0s 79us/step - loss: 0.4355 - acc: 0.8066\n",
      "Epoch 28/100\n",
      "512/512 [==============================] - 0s 74us/step - loss: 0.4339 - acc: 0.7988\n",
      "Epoch 29/100\n",
      "512/512 [==============================] - 0s 79us/step - loss: 0.4291 - acc: 0.8047\n",
      "Epoch 30/100\n",
      "512/512 [==============================] - 0s 79us/step - loss: 0.4350 - acc: 0.8027\n",
      "Epoch 31/100\n",
      "512/512 [==============================] - 0s 79us/step - loss: 0.4318 - acc: 0.8086\n",
      "Epoch 32/100\n",
      "512/512 [==============================] - 0s 68us/step - loss: 0.4262 - acc: 0.8125\n",
      "Epoch 33/100\n",
      "512/512 [==============================] - 0s 81us/step - loss: 0.4324 - acc: 0.7949\n",
      "Epoch 34/100\n",
      "512/512 [==============================] - 0s 86us/step - loss: 0.4302 - acc: 0.7949\n",
      "Epoch 35/100\n",
      "512/512 [==============================] - 0s 83us/step - loss: 0.4260 - acc: 0.8008\n",
      "Epoch 36/100\n",
      "512/512 [==============================] - 0s 79us/step - loss: 0.4302 - acc: 0.8027\n",
      "Epoch 37/100\n",
      "512/512 [==============================] - 0s 71us/step - loss: 0.4247 - acc: 0.8066\n",
      "Epoch 38/100\n",
      "512/512 [==============================] - 0s 71us/step - loss: 0.4235 - acc: 0.8086\n",
      "Epoch 39/100\n",
      "512/512 [==============================] - 0s 76us/step - loss: 0.4234 - acc: 0.8125\n",
      "Epoch 40/100\n",
      "512/512 [==============================] - 0s 73us/step - loss: 0.4179 - acc: 0.8145\n",
      "Epoch 41/100\n",
      "512/512 [==============================] - 0s 76us/step - loss: 0.4216 - acc: 0.8125\n",
      "Epoch 42/100\n",
      "512/512 [==============================] - 0s 84us/step - loss: 0.4158 - acc: 0.8125\n",
      "Epoch 43/100\n",
      "512/512 [==============================] - 0s 70us/step - loss: 0.4179 - acc: 0.8184\n",
      "Epoch 44/100\n",
      "512/512 [==============================] - 0s 76us/step - loss: 0.4179 - acc: 0.8125\n",
      "Epoch 45/100\n",
      "512/512 [==============================] - 0s 71us/step - loss: 0.4181 - acc: 0.8203\n",
      "Epoch 46/100\n",
      "512/512 [==============================] - 0s 75us/step - loss: 0.4182 - acc: 0.8105\n",
      "Epoch 47/100\n",
      "512/512 [==============================] - 0s 71us/step - loss: 0.4161 - acc: 0.8184\n",
      "Epoch 48/100\n",
      "512/512 [==============================] - 0s 73us/step - loss: 0.4172 - acc: 0.8223\n",
      "Epoch 49/100\n",
      "512/512 [==============================] - 0s 69us/step - loss: 0.4160 - acc: 0.8105\n",
      "Epoch 50/100\n",
      "512/512 [==============================] - 0s 76us/step - loss: 0.4164 - acc: 0.8086\n",
      "Epoch 51/100\n",
      "512/512 [==============================] - 0s 74us/step - loss: 0.4148 - acc: 0.8242\n",
      "Epoch 52/100\n",
      "512/512 [==============================] - 0s 66us/step - loss: 0.4160 - acc: 0.8203\n",
      "Epoch 53/100\n",
      "512/512 [==============================] - 0s 80us/step - loss: 0.4143 - acc: 0.8086\n",
      "Epoch 54/100\n",
      "512/512 [==============================] - 0s 88us/step - loss: 0.4178 - acc: 0.8184\n",
      "Epoch 55/100\n",
      "512/512 [==============================] - 0s 70us/step - loss: 0.4152 - acc: 0.8223\n",
      "Epoch 56/100\n",
      "512/512 [==============================] - 0s 72us/step - loss: 0.4140 - acc: 0.8301\n",
      "Epoch 57/100\n",
      "512/512 [==============================] - 0s 67us/step - loss: 0.4154 - acc: 0.8145\n",
      "Epoch 58/100\n",
      "512/512 [==============================] - 0s 76us/step - loss: 0.4119 - acc: 0.8184\n",
      "Epoch 59/100\n",
      "512/512 [==============================] - 0s 75us/step - loss: 0.4108 - acc: 0.8242\n",
      "Epoch 60/100\n",
      "512/512 [==============================] - 0s 74us/step - loss: 0.4117 - acc: 0.8164\n",
      "Epoch 61/100\n",
      "512/512 [==============================] - 0s 72us/step - loss: 0.4104 - acc: 0.8145\n",
      "Epoch 62/100\n",
      "512/512 [==============================] - 0s 81us/step - loss: 0.4095 - acc: 0.8262\n",
      "Epoch 63/100\n",
      "512/512 [==============================] - 0s 74us/step - loss: 0.4112 - acc: 0.8281\n",
      "Epoch 64/100\n",
      "512/512 [==============================] - 0s 72us/step - loss: 0.4050 - acc: 0.8301\n",
      "Epoch 65/100\n",
      "512/512 [==============================] - 0s 70us/step - loss: 0.4066 - acc: 0.8281\n",
      "Epoch 66/100\n",
      "512/512 [==============================] - 0s 69us/step - loss: 0.4079 - acc: 0.8281\n",
      "Epoch 67/100\n",
      "512/512 [==============================] - 0s 65us/step - loss: 0.4059 - acc: 0.8184\n",
      "Epoch 68/100\n",
      "512/512 [==============================] - 0s 77us/step - loss: 0.4063 - acc: 0.8262\n",
      "Epoch 69/100\n",
      "512/512 [==============================] - 0s 73us/step - loss: 0.4087 - acc: 0.8320\n",
      "Epoch 70/100\n",
      "512/512 [==============================] - 0s 66us/step - loss: 0.4102 - acc: 0.8320\n",
      "Epoch 71/100\n",
      "512/512 [==============================] - 0s 69us/step - loss: 0.4080 - acc: 0.8359\n",
      "Epoch 72/100\n",
      "512/512 [==============================] - 0s 75us/step - loss: 0.4082 - acc: 0.8242\n",
      "Epoch 73/100\n",
      "512/512 [==============================] - 0s 79us/step - loss: 0.4062 - acc: 0.8301\n",
      "Epoch 74/100\n",
      "512/512 [==============================] - 0s 72us/step - loss: 0.4069 - acc: 0.8223\n",
      "Epoch 75/100\n",
      "512/512 [==============================] - 0s 71us/step - loss: 0.4070 - acc: 0.8301\n",
      "Epoch 76/100\n",
      "512/512 [==============================] - 0s 74us/step - loss: 0.4041 - acc: 0.8438\n",
      "Epoch 77/100\n",
      "512/512 [==============================] - 0s 69us/step - loss: 0.4051 - acc: 0.8281\n",
      "Epoch 78/100\n",
      "512/512 [==============================] - 0s 75us/step - loss: 0.4053 - acc: 0.8301\n",
      "Epoch 79/100\n",
      "512/512 [==============================] - 0s 70us/step - loss: 0.4066 - acc: 0.8242\n",
      "Epoch 80/100\n",
      "512/512 [==============================] - 0s 72us/step - loss: 0.4069 - acc: 0.8281\n",
      "Epoch 81/100\n",
      "512/512 [==============================] - 0s 72us/step - loss: 0.4061 - acc: 0.8320\n",
      "Epoch 82/100\n",
      "512/512 [==============================] - 0s 75us/step - loss: 0.4035 - acc: 0.8301\n",
      "Epoch 83/100\n",
      "512/512 [==============================] - 0s 74us/step - loss: 0.4057 - acc: 0.8320\n",
      "Epoch 84/100\n",
      "512/512 [==============================] - 0s 71us/step - loss: 0.4042 - acc: 0.8281\n",
      "Epoch 85/100\n",
      "512/512 [==============================] - 0s 77us/step - loss: 0.4010 - acc: 0.8340\n",
      "Epoch 86/100\n",
      "512/512 [==============================] - 0s 70us/step - loss: 0.4007 - acc: 0.8359\n",
      "Epoch 87/100\n",
      "512/512 [==============================] - 0s 68us/step - loss: 0.4025 - acc: 0.8340\n",
      "Epoch 88/100\n",
      "512/512 [==============================] - 0s 67us/step - loss: 0.4020 - acc: 0.8340\n",
      "Epoch 89/100\n",
      "512/512 [==============================] - 0s 68us/step - loss: 0.4089 - acc: 0.8203\n",
      "Epoch 90/100\n",
      "512/512 [==============================] - 0s 72us/step - loss: 0.4035 - acc: 0.8262\n",
      "Epoch 91/100\n",
      "512/512 [==============================] - 0s 74us/step - loss: 0.4024 - acc: 0.8437\n",
      "Epoch 92/100\n",
      "512/512 [==============================] - 0s 74us/step - loss: 0.4044 - acc: 0.8320\n",
      "Epoch 93/100\n",
      "512/512 [==============================] - 0s 71us/step - loss: 0.4020 - acc: 0.8301\n",
      "Epoch 94/100\n",
      "512/512 [==============================] - 0s 69us/step - loss: 0.4055 - acc: 0.8262\n",
      "Epoch 95/100\n",
      "512/512 [==============================] - 0s 76us/step - loss: 0.4013 - acc: 0.8418\n",
      "Epoch 96/100\n",
      "512/512 [==============================] - 0s 68us/step - loss: 0.4009 - acc: 0.8301\n",
      "Epoch 97/100\n",
      "512/512 [==============================] - 0s 78us/step - loss: 0.4028 - acc: 0.8242\n",
      "Epoch 98/100\n",
      "512/512 [==============================] - 0s 75us/step - loss: 0.3991 - acc: 0.8301\n",
      "Epoch 99/100\n",
      "512/512 [==============================] - 0s 72us/step - loss: 0.4026 - acc: 0.8301\n",
      "Epoch 100/100\n",
      "512/512 [==============================] - 0s 70us/step - loss: 0.4068 - acc: 0.8340\n",
      "256/256 [==============================] - 0s 830us/step\n",
      "512/512 [==============================] - 0s 45us/step\n",
      "[CV]  batch_size=20, epochs=100, score=0.7890625037252903, total=   5.0s\n",
      "[CV] batch_size=40, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "512/512 [==============================] - 1s 1ms/step - loss: 0.6345 - acc: 0.6641\n",
      "Epoch 2/10\n",
      "512/512 [==============================] - 0s 48us/step - loss: 0.5201 - acc: 0.6680\n",
      "Epoch 3/10\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.4963 - acc: 0.6680\n",
      "Epoch 4/10\n",
      "512/512 [==============================] - 0s 37us/step - loss: 0.4755 - acc: 0.6855\n",
      "Epoch 5/10\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.4656 - acc: 0.7891\n",
      "Epoch 6/10\n",
      "512/512 [==============================] - 0s 44us/step - loss: 0.4549 - acc: 0.7891\n",
      "Epoch 7/10\n",
      "512/512 [==============================] - 0s 37us/step - loss: 0.4476 - acc: 0.7891\n",
      "Epoch 8/10\n",
      "512/512 [==============================] - 0s 37us/step - loss: 0.4413 - acc: 0.7988\n",
      "Epoch 9/10\n",
      "512/512 [==============================] - 0s 44us/step - loss: 0.4343 - acc: 0.8008\n",
      "Epoch 10/10\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.4276 - acc: 0.8027\n",
      "256/256 [==============================] - 0s 843us/step\n",
      "512/512 [==============================] - 0s 32us/step\n",
      "[CV]  batch_size=40, epochs=10, score=0.7500000018626451, total=   1.4s\n",
      "[CV] batch_size=40, epochs=10 ........................................\n",
      "Epoch 1/10\n",
      "512/512 [==============================] - 1s 1ms/step - loss: 0.6839 - acc: 0.6211\n",
      "Epoch 2/10\n",
      "512/512 [==============================] - 0s 53us/step - loss: 0.6486 - acc: 0.6465\n",
      "Epoch 3/10\n",
      "512/512 [==============================] - 0s 44us/step - loss: 0.5607 - acc: 0.7266\n",
      "Epoch 4/10\n",
      "512/512 [==============================] - 0s 36us/step - loss: 0.4778 - acc: 0.7617\n",
      "Epoch 5/10\n",
      "512/512 [==============================] - 0s 44us/step - loss: 0.4577 - acc: 0.7813\n",
      "Epoch 6/10\n",
      "512/512 [==============================] - 0s 45us/step - loss: 0.4480 - acc: 0.7793\n",
      "Epoch 7/10\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.4387 - acc: 0.7773\n",
      "Epoch 8/10\n",
      "512/512 [==============================] - 0s 37us/step - loss: 0.4345 - acc: 0.7813\n",
      "Epoch 9/10\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.4334 - acc: 0.7754\n",
      "Epoch 10/10\n",
      "512/512 [==============================] - 0s 45us/step - loss: 0.4317 - acc: 0.7891\n",
      "256/256 [==============================] - 0s 894us/step\n",
      "512/512 [==============================] - 0s 27us/step\n",
      "[CV]  batch_size=40, epochs=10, score=0.7539062444120646, total=   1.5s\n",
      "[CV] batch_size=40, epochs=10 ........................................\n",
      "Epoch 1/10\n",
      "512/512 [==============================] - 1s 1ms/step - loss: 0.6667 - acc: 0.6602\n",
      "Epoch 2/10\n",
      "512/512 [==============================] - 0s 46us/step - loss: 0.5714 - acc: 0.7246\n",
      "Epoch 3/10\n",
      "512/512 [==============================] - 0s 44us/step - loss: 0.5040 - acc: 0.7520\n",
      "Epoch 4/10\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.4934 - acc: 0.7559\n",
      "Epoch 5/10\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.4841 - acc: 0.7793\n",
      "Epoch 6/10\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.4808 - acc: 0.7695\n",
      "Epoch 7/10\n",
      "512/512 [==============================] - 0s 45us/step - loss: 0.4786 - acc: 0.7637\n",
      "Epoch 8/10\n",
      "512/512 [==============================] - 0s 37us/step - loss: 0.4772 - acc: 0.7637\n",
      "Epoch 9/10\n",
      "512/512 [==============================] - 0s 57us/step - loss: 0.4779 - acc: 0.7598\n",
      "Epoch 10/10\n",
      "512/512 [==============================] - 0s 45us/step - loss: 0.4748 - acc: 0.7598\n",
      "256/256 [==============================] - 0s 938us/step\n",
      "512/512 [==============================] - 0s 31us/step\n",
      "[CV]  batch_size=40, epochs=10, score=0.808593763038516, total=   1.5s\n",
      "[CV] batch_size=40, epochs=50 ........................................\n",
      "Epoch 1/50\n",
      "512/512 [==============================] - 1s 1ms/step - loss: 0.6544 - acc: 0.6504\n",
      "Epoch 2/50\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.5396 - acc: 0.6680\n",
      "Epoch 3/50\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.4949 - acc: 0.6680\n",
      "Epoch 4/50\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.4767 - acc: 0.6680\n",
      "Epoch 5/50\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.4613 - acc: 0.7695\n",
      "Epoch 6/50\n",
      "512/512 [==============================] - 0s 36us/step - loss: 0.4506 - acc: 0.7969\n",
      "Epoch 7/50\n",
      "512/512 [==============================] - 0s 49us/step - loss: 0.4392 - acc: 0.7930\n",
      "Epoch 8/50\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.4275 - acc: 0.8086\n",
      "Epoch 9/50\n",
      "512/512 [==============================] - 0s 45us/step - loss: 0.4244 - acc: 0.8066\n",
      "Epoch 10/50\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.4149 - acc: 0.8145\n",
      "Epoch 11/50\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.4041 - acc: 0.8086\n",
      "Epoch 12/50\n",
      "512/512 [==============================] - 0s 46us/step - loss: 0.3939 - acc: 0.8125\n",
      "Epoch 13/50\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.3911 - acc: 0.8164\n",
      "Epoch 14/50\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.3879 - acc: 0.8223\n",
      "Epoch 15/50\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.3803 - acc: 0.8281\n",
      "Epoch 16/50\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.3825 - acc: 0.8281\n",
      "Epoch 17/50\n",
      "512/512 [==============================] - 0s 37us/step - loss: 0.3787 - acc: 0.8203\n",
      "Epoch 18/50\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.3723 - acc: 0.8281\n",
      "Epoch 19/50\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.3687 - acc: 0.8379\n",
      "Epoch 20/50\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.3710 - acc: 0.8262\n",
      "Epoch 21/50\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.3678 - acc: 0.8359\n",
      "Epoch 22/50\n",
      "512/512 [==============================] - 0s 45us/step - loss: 0.3629 - acc: 0.8340\n",
      "Epoch 23/50\n",
      "512/512 [==============================] - 0s 45us/step - loss: 0.3626 - acc: 0.8359\n",
      "Epoch 24/50\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.3622 - acc: 0.8438\n",
      "Epoch 25/50\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.3746 - acc: 0.8359\n",
      "Epoch 26/50\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.3629 - acc: 0.8379\n",
      "Epoch 27/50\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.3597 - acc: 0.8418\n",
      "Epoch 28/50\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.3605 - acc: 0.8320\n",
      "Epoch 29/50\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.3547 - acc: 0.8438\n",
      "Epoch 30/50\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.3558 - acc: 0.8477\n",
      "Epoch 31/50\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.3543 - acc: 0.8398\n",
      "Epoch 32/50\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.3554 - acc: 0.8457\n",
      "Epoch 33/50\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.3540 - acc: 0.8457\n",
      "Epoch 34/50\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.3503 - acc: 0.8379\n",
      "Epoch 35/50\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.3533 - acc: 0.8457\n",
      "Epoch 36/50\n",
      "512/512 [==============================] - 0s 46us/step - loss: 0.3492 - acc: 0.8457\n",
      "Epoch 37/50\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.3509 - acc: 0.8516\n",
      "Epoch 38/50\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.3504 - acc: 0.8516\n",
      "Epoch 39/50\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.3524 - acc: 0.8457\n",
      "Epoch 40/50\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.3473 - acc: 0.8457\n",
      "Epoch 41/50\n",
      "512/512 [==============================] - 0s 35us/step - loss: 0.3459 - acc: 0.8477\n",
      "Epoch 42/50\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.3437 - acc: 0.8535\n",
      "Epoch 43/50\n",
      "512/512 [==============================] - 0s 46us/step - loss: 0.3456 - acc: 0.8457\n",
      "Epoch 44/50\n",
      "512/512 [==============================] - 0s 44us/step - loss: 0.3436 - acc: 0.8496\n",
      "Epoch 45/50\n",
      "512/512 [==============================] - 0s 48us/step - loss: 0.3419 - acc: 0.8477\n",
      "Epoch 46/50\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.3411 - acc: 0.8418\n",
      "Epoch 47/50\n",
      "512/512 [==============================] - 0s 37us/step - loss: 0.3383 - acc: 0.8535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.3432 - acc: 0.8496\n",
      "Epoch 49/50\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.3383 - acc: 0.8555\n",
      "Epoch 50/50\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.3418 - acc: 0.8477\n",
      "256/256 [==============================] - 0s 993us/step\n",
      "512/512 [==============================] - 0s 33us/step\n",
      "[CV]  batch_size=40, epochs=50, score=0.7304687388241291, total=   2.6s\n",
      "[CV] batch_size=40, epochs=50 ........................................\n",
      "Epoch 1/50\n",
      "512/512 [==============================] - 1s 1ms/step - loss: 0.6577 - acc: 0.7441\n",
      "Epoch 2/50\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.5363 - acc: 0.7637\n",
      "Epoch 3/50\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.4547 - acc: 0.7793\n",
      "Epoch 4/50\n",
      "512/512 [==============================] - 0s 44us/step - loss: 0.4484 - acc: 0.7734\n",
      "Epoch 5/50\n",
      "512/512 [==============================] - 0s 54us/step - loss: 0.4402 - acc: 0.7832\n",
      "Epoch 6/50\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.4410 - acc: 0.7832\n",
      "Epoch 7/50\n",
      "512/512 [==============================] - 0s 44us/step - loss: 0.4357 - acc: 0.7891\n",
      "Epoch 8/50\n",
      "512/512 [==============================] - 0s 37us/step - loss: 0.4338 - acc: 0.7871\n",
      "Epoch 9/50\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.4304 - acc: 0.7910\n",
      "Epoch 10/50\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.4290 - acc: 0.7812\n",
      "Epoch 11/50\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.4286 - acc: 0.7871\n",
      "Epoch 12/50\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.4295 - acc: 0.7832\n",
      "Epoch 13/50\n",
      "512/512 [==============================] - 0s 44us/step - loss: 0.4287 - acc: 0.7969\n",
      "Epoch 14/50\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.4220 - acc: 0.7793\n",
      "Epoch 15/50\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.4186 - acc: 0.7812\n",
      "Epoch 16/50\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.4206 - acc: 0.7910\n",
      "Epoch 17/50\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.4155 - acc: 0.7910\n",
      "Epoch 18/50\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.4105 - acc: 0.8027\n",
      "Epoch 19/50\n",
      "512/512 [==============================] - 0s 36us/step - loss: 0.4088 - acc: 0.7949\n",
      "Epoch 20/50\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.4066 - acc: 0.7988\n",
      "Epoch 21/50\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.4065 - acc: 0.8008\n",
      "Epoch 22/50\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.4041 - acc: 0.8027\n",
      "Epoch 23/50\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.4018 - acc: 0.8066\n",
      "Epoch 24/50\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.4019 - acc: 0.7969\n",
      "Epoch 25/50\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.4048 - acc: 0.7930\n",
      "Epoch 26/50\n",
      "512/512 [==============================] - 0s 46us/step - loss: 0.3987 - acc: 0.8145\n",
      "Epoch 27/50\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.3908 - acc: 0.8125\n",
      "Epoch 28/50\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.3928 - acc: 0.8105\n",
      "Epoch 29/50\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.3916 - acc: 0.8105\n",
      "Epoch 30/50\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.3929 - acc: 0.8105\n",
      "Epoch 31/50\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.3903 - acc: 0.8145\n",
      "Epoch 32/50\n",
      "512/512 [==============================] - 0s 37us/step - loss: 0.3914 - acc: 0.8105\n",
      "Epoch 33/50\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.3884 - acc: 0.8125\n",
      "Epoch 34/50\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.3869 - acc: 0.8125\n",
      "Epoch 35/50\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.3898 - acc: 0.8086\n",
      "Epoch 36/50\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.3904 - acc: 0.8105\n",
      "Epoch 37/50\n",
      "512/512 [==============================] - 0s 37us/step - loss: 0.3901 - acc: 0.8125\n",
      "Epoch 38/50\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.3857 - acc: 0.8145\n",
      "Epoch 39/50\n",
      "512/512 [==============================] - 0s 44us/step - loss: 0.3903 - acc: 0.8145\n",
      "Epoch 40/50\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.3829 - acc: 0.8105\n",
      "Epoch 41/50\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.3857 - acc: 0.8125\n",
      "Epoch 42/50\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.3857 - acc: 0.8203\n",
      "Epoch 43/50\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.3868 - acc: 0.8281\n",
      "Epoch 44/50\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.3827 - acc: 0.8184\n",
      "Epoch 45/50\n",
      "512/512 [==============================] - 0s 46us/step - loss: 0.3835 - acc: 0.8145\n",
      "Epoch 46/50\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.3823 - acc: 0.8184\n",
      "Epoch 47/50\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.3889 - acc: 0.8184\n",
      "Epoch 48/50\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.3851 - acc: 0.8105\n",
      "Epoch 49/50\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.3830 - acc: 0.8262\n",
      "Epoch 50/50\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.3829 - acc: 0.8223\n",
      "256/256 [==============================] - 0s 1ms/step\n",
      "512/512 [==============================] - 0s 28us/step\n",
      "[CV]  batch_size=40, epochs=50, score=0.7421875055879354, total=   2.4s\n",
      "[CV] batch_size=40, epochs=50 ........................................\n",
      "Epoch 1/50\n",
      "512/512 [==============================] - 1s 1ms/step - loss: 0.6800 - acc: 0.6387\n",
      "Epoch 2/50\n",
      "512/512 [==============================] - 0s 37us/step - loss: 0.6350 - acc: 0.6387\n",
      "Epoch 3/50\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.5641 - acc: 0.6387\n",
      "Epoch 4/50\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.5420 - acc: 0.6387\n",
      "Epoch 5/50\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.5286 - acc: 0.6387\n",
      "Epoch 6/50\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.5197 - acc: 0.6387\n",
      "Epoch 7/50\n",
      "512/512 [==============================] - 0s 45us/step - loss: 0.5125 - acc: 0.7695\n",
      "Epoch 8/50\n",
      "512/512 [==============================] - 0s 35us/step - loss: 0.5064 - acc: 0.7754\n",
      "Epoch 9/50\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.5012 - acc: 0.7773\n",
      "Epoch 10/50\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.4967 - acc: 0.7793\n",
      "Epoch 11/50\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.4924 - acc: 0.7773\n",
      "Epoch 12/50\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.4882 - acc: 0.7773\n",
      "Epoch 13/50\n",
      "512/512 [==============================] - 0s 48us/step - loss: 0.4848 - acc: 0.7773\n",
      "Epoch 14/50\n",
      "512/512 [==============================] - 0s 45us/step - loss: 0.4811 - acc: 0.7773\n",
      "Epoch 15/50\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.4790 - acc: 0.7773\n",
      "Epoch 16/50\n",
      "512/512 [==============================] - 0s 37us/step - loss: 0.4753 - acc: 0.7734\n",
      "Epoch 17/50\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.4724 - acc: 0.7676\n",
      "Epoch 18/50\n",
      "512/512 [==============================] - 0s 37us/step - loss: 0.4704 - acc: 0.7715\n",
      "Epoch 19/50\n",
      "512/512 [==============================] - 0s 36us/step - loss: 0.4695 - acc: 0.7715\n",
      "Epoch 20/50\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.4671 - acc: 0.7734\n",
      "Epoch 21/50\n",
      "512/512 [==============================] - 0s 36us/step - loss: 0.4649 - acc: 0.7773\n",
      "Epoch 22/50\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.4626 - acc: 0.7793\n",
      "Epoch 23/50\n",
      "512/512 [==============================] - 0s 37us/step - loss: 0.4601 - acc: 0.7734\n",
      "Epoch 24/50\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.4575 - acc: 0.7813\n",
      "Epoch 25/50\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.4567 - acc: 0.7852\n",
      "Epoch 26/50\n",
      "512/512 [==============================] - 0s 45us/step - loss: 0.4559 - acc: 0.7852\n",
      "Epoch 27/50\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.4526 - acc: 0.7793\n",
      "Epoch 28/50\n",
      "512/512 [==============================] - 0s 48us/step - loss: 0.4520 - acc: 0.7930\n",
      "Epoch 29/50\n",
      "512/512 [==============================] - 0s 37us/step - loss: 0.4483 - acc: 0.7910\n",
      "Epoch 30/50\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.4475 - acc: 0.7949\n",
      "Epoch 31/50\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.4456 - acc: 0.7930\n",
      "Epoch 32/50\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.4459 - acc: 0.7930\n",
      "Epoch 33/50\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.4435 - acc: 0.7988\n",
      "Epoch 34/50\n",
      "512/512 [==============================] - 0s 44us/step - loss: 0.4450 - acc: 0.7988\n",
      "Epoch 35/50\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.4457 - acc: 0.7832\n",
      "Epoch 36/50\n",
      "512/512 [==============================] - 0s 48us/step - loss: 0.4425 - acc: 0.7969\n",
      "Epoch 37/50\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.4409 - acc: 0.8027\n",
      "Epoch 38/50\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.4406 - acc: 0.8027\n",
      "Epoch 39/50\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.4400 - acc: 0.7969\n",
      "Epoch 40/50\n",
      "512/512 [==============================] - 0s 50us/step - loss: 0.4404 - acc: 0.7949\n",
      "Epoch 41/50\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.4396 - acc: 0.7988\n",
      "Epoch 42/50\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.4381 - acc: 0.7949\n",
      "Epoch 43/50\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.4372 - acc: 0.7930\n",
      "Epoch 44/50\n",
      "512/512 [==============================] - 0s 37us/step - loss: 0.4339 - acc: 0.7969\n",
      "Epoch 45/50\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.4332 - acc: 0.8008\n",
      "Epoch 46/50\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.4342 - acc: 0.7988\n",
      "Epoch 47/50\n",
      "512/512 [==============================] - 0s 48us/step - loss: 0.4345 - acc: 0.7949\n",
      "Epoch 48/50\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.4368 - acc: 0.7969\n",
      "Epoch 49/50\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.4333 - acc: 0.8047\n",
      "Epoch 50/50\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.4307 - acc: 0.8027\n",
      "256/256 [==============================] - 0s 1ms/step\n",
      "512/512 [==============================] - 0s 31us/step\n",
      "[CV]  batch_size=40, epochs=50, score=0.7851562574505806, total=   2.5s\n",
      "[CV] batch_size=40, epochs=100 .......................................\n",
      "Epoch 1/100\n",
      "512/512 [==============================] - 1s 2ms/step - loss: 0.6810 - acc: 0.6484\n",
      "Epoch 2/100\n",
      "512/512 [==============================] - 0s 46us/step - loss: 0.6320 - acc: 0.7617\n",
      "Epoch 3/100\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.5441 - acc: 0.7695\n",
      "Epoch 4/100\n",
      "512/512 [==============================] - 0s 45us/step - loss: 0.4668 - acc: 0.7793\n",
      "Epoch 5/100\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.4455 - acc: 0.7852\n",
      "Epoch 6/100\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.4346 - acc: 0.7832\n",
      "Epoch 7/100\n",
      "512/512 [==============================] - 0s 44us/step - loss: 0.4299 - acc: 0.7871\n",
      "Epoch 8/100\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.4211 - acc: 0.7910\n",
      "Epoch 9/100\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.4153 - acc: 0.7910\n",
      "Epoch 10/100\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.4103 - acc: 0.8008\n",
      "Epoch 11/100\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.4036 - acc: 0.8008\n",
      "Epoch 12/100\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.4037 - acc: 0.7910\n",
      "Epoch 13/100\n",
      "512/512 [==============================] - 0s 37us/step - loss: 0.4003 - acc: 0.8086\n",
      "Epoch 14/100\n",
      "512/512 [==============================] - 0s 45us/step - loss: 0.3987 - acc: 0.8066\n",
      "Epoch 15/100\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.3955 - acc: 0.8008\n",
      "Epoch 16/100\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.3913 - acc: 0.8105\n",
      "Epoch 17/100\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.3940 - acc: 0.8145\n",
      "Epoch 18/100\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.3899 - acc: 0.8047\n",
      "Epoch 19/100\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.3923 - acc: 0.7930\n",
      "Epoch 20/100\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.3859 - acc: 0.8203\n",
      "Epoch 21/100\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.3865 - acc: 0.8105\n",
      "Epoch 22/100\n",
      "512/512 [==============================] - 0s 44us/step - loss: 0.3832 - acc: 0.8281\n",
      "Epoch 23/100\n",
      "512/512 [==============================] - 0s 46us/step - loss: 0.3860 - acc: 0.8164\n",
      "Epoch 24/100\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.3839 - acc: 0.8086\n",
      "Epoch 25/100\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.3832 - acc: 0.8223\n",
      "Epoch 26/100\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.3799 - acc: 0.8262\n",
      "Epoch 27/100\n",
      "512/512 [==============================] - 0s 36us/step - loss: 0.3794 - acc: 0.8223\n",
      "Epoch 28/100\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.3778 - acc: 0.8262\n",
      "Epoch 29/100\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.3796 - acc: 0.8203\n",
      "Epoch 30/100\n",
      "512/512 [==============================] - 0s 50us/step - loss: 0.3774 - acc: 0.8184\n",
      "Epoch 31/100\n",
      "512/512 [==============================] - 0s 46us/step - loss: 0.3747 - acc: 0.8242\n",
      "Epoch 32/100\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.3745 - acc: 0.8242\n",
      "Epoch 33/100\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.3753 - acc: 0.8164\n",
      "Epoch 34/100\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.3704 - acc: 0.8203\n",
      "Epoch 35/100\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.3706 - acc: 0.8242\n",
      "Epoch 36/100\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.3695 - acc: 0.8301\n",
      "Epoch 37/100\n",
      "512/512 [==============================] - 0s 48us/step - loss: 0.3718 - acc: 0.8145\n",
      "Epoch 38/100\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.3666 - acc: 0.8262\n",
      "Epoch 39/100\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.3665 - acc: 0.8262\n",
      "Epoch 40/100\n",
      "512/512 [==============================] - 0s 44us/step - loss: 0.3644 - acc: 0.8223\n",
      "Epoch 41/100\n",
      "512/512 [==============================] - 0s 37us/step - loss: 0.3661 - acc: 0.8281\n",
      "Epoch 42/100\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.3637 - acc: 0.8301\n",
      "Epoch 43/100\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.3649 - acc: 0.8340\n",
      "Epoch 44/100\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.3640 - acc: 0.8301\n",
      "Epoch 45/100\n",
      "512/512 [==============================] - 0s 36us/step - loss: 0.3675 - acc: 0.8184\n",
      "Epoch 46/100\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.3674 - acc: 0.8203\n",
      "Epoch 47/100\n",
      "512/512 [==============================] - 0s 35us/step - loss: 0.3664 - acc: 0.8262\n",
      "Epoch 48/100\n",
      "512/512 [==============================] - 0s 44us/step - loss: 0.3629 - acc: 0.8301\n",
      "Epoch 49/100\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.3627 - acc: 0.8320\n",
      "Epoch 50/100\n",
      "512/512 [==============================] - 0s 37us/step - loss: 0.3555 - acc: 0.8301\n",
      "Epoch 51/100\n",
      "512/512 [==============================] - 0s 36us/step - loss: 0.3596 - acc: 0.8262\n",
      "Epoch 52/100\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.3604 - acc: 0.8281\n",
      "Epoch 53/100\n",
      "512/512 [==============================] - 0s 35us/step - loss: 0.3571 - acc: 0.8281\n",
      "Epoch 54/100\n",
      "512/512 [==============================] - 0s 37us/step - loss: 0.3585 - acc: 0.8262\n",
      "Epoch 55/100\n",
      "512/512 [==============================] - 0s 46us/step - loss: 0.3545 - acc: 0.8242\n",
      "Epoch 56/100\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.3551 - acc: 0.8340\n",
      "Epoch 57/100\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.3535 - acc: 0.8281\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 39us/step - loss: 0.3534 - acc: 0.8301\n",
      "Epoch 59/100\n",
      "512/512 [==============================] - 0s 37us/step - loss: 0.3510 - acc: 0.8281\n",
      "Epoch 60/100\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.3504 - acc: 0.8301\n",
      "Epoch 61/100\n",
      "512/512 [==============================] - 0s 50us/step - loss: 0.3507 - acc: 0.8301\n",
      "Epoch 62/100\n",
      "512/512 [==============================] - 0s 35us/step - loss: 0.3564 - acc: 0.8262\n",
      "Epoch 63/100\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.3526 - acc: 0.8379\n",
      "Epoch 64/100\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.3524 - acc: 0.8281\n",
      "Epoch 65/100\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.3450 - acc: 0.8359\n",
      "Epoch 66/100\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.3487 - acc: 0.8262\n",
      "Epoch 67/100\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.3468 - acc: 0.8203\n",
      "Epoch 68/100\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.3449 - acc: 0.8340\n",
      "Epoch 69/100\n",
      "512/512 [==============================] - 0s 45us/step - loss: 0.3471 - acc: 0.8379\n",
      "Epoch 70/100\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.3447 - acc: 0.8281\n",
      "Epoch 71/100\n",
      "512/512 [==============================] - 0s 46us/step - loss: 0.3438 - acc: 0.8379\n",
      "Epoch 72/100\n",
      "512/512 [==============================] - 0s 44us/step - loss: 0.3421 - acc: 0.8359\n",
      "Epoch 73/100\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.3403 - acc: 0.8398\n",
      "Epoch 74/100\n",
      "512/512 [==============================] - 0s 45us/step - loss: 0.3437 - acc: 0.8457\n",
      "Epoch 75/100\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.3409 - acc: 0.8457\n",
      "Epoch 76/100\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.3443 - acc: 0.8301\n",
      "Epoch 77/100\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.3398 - acc: 0.8496\n",
      "Epoch 78/100\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.3442 - acc: 0.8340\n",
      "Epoch 79/100\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.3355 - acc: 0.8398\n",
      "Epoch 80/100\n",
      "512/512 [==============================] - 0s 48us/step - loss: 0.3389 - acc: 0.8437\n",
      "Epoch 81/100\n",
      "512/512 [==============================] - 0s 44us/step - loss: 0.3363 - acc: 0.8555\n",
      "Epoch 82/100\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.3357 - acc: 0.8379\n",
      "Epoch 83/100\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.3351 - acc: 0.8457\n",
      "Epoch 84/100\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.3391 - acc: 0.8496\n",
      "Epoch 85/100\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.3328 - acc: 0.8496\n",
      "Epoch 86/100\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.3380 - acc: 0.8398\n",
      "Epoch 87/100\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.3332 - acc: 0.8438\n",
      "Epoch 88/100\n",
      "512/512 [==============================] - 0s 37us/step - loss: 0.3343 - acc: 0.8496\n",
      "Epoch 89/100\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.3362 - acc: 0.8516\n",
      "Epoch 90/100\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.3340 - acc: 0.8516\n",
      "Epoch 91/100\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.3299 - acc: 0.8457\n",
      "Epoch 92/100\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.3277 - acc: 0.8555\n",
      "Epoch 93/100\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.3268 - acc: 0.8516\n",
      "Epoch 94/100\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.3260 - acc: 0.8496\n",
      "Epoch 95/100\n",
      "512/512 [==============================] - 0s 46us/step - loss: 0.3287 - acc: 0.8535\n",
      "Epoch 96/100\n",
      "512/512 [==============================] - 0s 44us/step - loss: 0.3328 - acc: 0.8477\n",
      "Epoch 97/100\n",
      "512/512 [==============================] - 0s 46us/step - loss: 0.3255 - acc: 0.8574\n",
      "Epoch 98/100\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.3220 - acc: 0.8574\n",
      "Epoch 99/100\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.3209 - acc: 0.8535\n",
      "Epoch 100/100\n",
      "512/512 [==============================] - 0s 37us/step - loss: 0.3246 - acc: 0.8516\n",
      "256/256 [==============================] - 0s 1ms/step\n",
      "512/512 [==============================] - 0s 28us/step\n",
      "[CV]  batch_size=40, epochs=100, score=0.6835937462747097, total=   3.6s\n",
      "[CV] batch_size=40, epochs=100 .......................................\n",
      "Epoch 1/100\n",
      "512/512 [==============================] - 1s 2ms/step - loss: 0.6556 - acc: 0.6465\n",
      "Epoch 2/100\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.5399 - acc: 0.6465\n",
      "Epoch 3/100\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.5018 - acc: 0.6797\n",
      "Epoch 4/100\n",
      "512/512 [==============================] - 0s 37us/step - loss: 0.4717 - acc: 0.7539\n",
      "Epoch 5/100\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.4561 - acc: 0.7676\n",
      "Epoch 6/100\n",
      "512/512 [==============================] - 0s 44us/step - loss: 0.4482 - acc: 0.7715\n",
      "Epoch 7/100\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.4428 - acc: 0.7734\n",
      "Epoch 8/100\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.4409 - acc: 0.7891\n",
      "Epoch 9/100\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.4369 - acc: 0.7891\n",
      "Epoch 10/100\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.4311 - acc: 0.7832\n",
      "Epoch 11/100\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.4318 - acc: 0.7910\n",
      "Epoch 12/100\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.4296 - acc: 0.7910\n",
      "Epoch 13/100\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.4273 - acc: 0.7930\n",
      "Epoch 14/100\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.4244 - acc: 0.7949\n",
      "Epoch 15/100\n",
      "512/512 [==============================] - 0s 36us/step - loss: 0.4228 - acc: 0.7930\n",
      "Epoch 16/100\n",
      "512/512 [==============================] - 0s 35us/step - loss: 0.4227 - acc: 0.8008\n",
      "Epoch 17/100\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.4212 - acc: 0.7910\n",
      "Epoch 18/100\n",
      "512/512 [==============================] - 0s 44us/step - loss: 0.4179 - acc: 0.7988\n",
      "Epoch 19/100\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.4177 - acc: 0.7969\n",
      "Epoch 20/100\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.4167 - acc: 0.8008\n",
      "Epoch 21/100\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.4157 - acc: 0.7910\n",
      "Epoch 22/100\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.4163 - acc: 0.8027\n",
      "Epoch 23/100\n",
      "512/512 [==============================] - 0s 36us/step - loss: 0.4135 - acc: 0.8027\n",
      "Epoch 24/100\n",
      "512/512 [==============================] - 0s 37us/step - loss: 0.4168 - acc: 0.7969\n",
      "Epoch 25/100\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.4125 - acc: 0.7930\n",
      "Epoch 26/100\n",
      "512/512 [==============================] - 0s 37us/step - loss: 0.4100 - acc: 0.7988\n",
      "Epoch 27/100\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.4099 - acc: 0.8086\n",
      "Epoch 28/100\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.4098 - acc: 0.7988\n",
      "Epoch 29/100\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.4058 - acc: 0.8008\n",
      "Epoch 30/100\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.4050 - acc: 0.7930\n",
      "Epoch 31/100\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.4033 - acc: 0.7969\n",
      "Epoch 32/100\n",
      "512/512 [==============================] - 0s 37us/step - loss: 0.4040 - acc: 0.7988\n",
      "Epoch 33/100\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.4013 - acc: 0.7949\n",
      "Epoch 34/100\n",
      "512/512 [==============================] - 0s 37us/step - loss: 0.3990 - acc: 0.7949\n",
      "Epoch 35/100\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.3988 - acc: 0.8105\n",
      "Epoch 36/100\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.4004 - acc: 0.7988\n",
      "Epoch 37/100\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.4022 - acc: 0.8066\n",
      "Epoch 38/100\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.4006 - acc: 0.7969\n",
      "Epoch 39/100\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.3977 - acc: 0.8125\n",
      "Epoch 40/100\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.3963 - acc: 0.8125\n",
      "Epoch 41/100\n",
      "512/512 [==============================] - 0s 46us/step - loss: 0.3948 - acc: 0.8105\n",
      "Epoch 42/100\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.3947 - acc: 0.8047\n",
      "Epoch 43/100\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.3952 - acc: 0.8223\n",
      "Epoch 44/100\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.3982 - acc: 0.8066\n",
      "Epoch 45/100\n",
      "512/512 [==============================] - 0s 44us/step - loss: 0.3928 - acc: 0.8145\n",
      "Epoch 46/100\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.3931 - acc: 0.8145\n",
      "Epoch 47/100\n",
      "512/512 [==============================] - 0s 46us/step - loss: 0.3904 - acc: 0.8145\n",
      "Epoch 48/100\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.3915 - acc: 0.8242\n",
      "Epoch 49/100\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.3901 - acc: 0.8164\n",
      "Epoch 50/100\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.3912 - acc: 0.8066\n",
      "Epoch 51/100\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.3907 - acc: 0.8145\n",
      "Epoch 52/100\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.3895 - acc: 0.8164\n",
      "Epoch 53/100\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.3909 - acc: 0.8125\n",
      "Epoch 54/100\n",
      "512/512 [==============================] - 0s 51us/step - loss: 0.3884 - acc: 0.8223\n",
      "Epoch 55/100\n",
      "512/512 [==============================] - 0s 46us/step - loss: 0.3864 - acc: 0.8086\n",
      "Epoch 56/100\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.3860 - acc: 0.8184\n",
      "Epoch 57/100\n",
      "512/512 [==============================] - 0s 37us/step - loss: 0.3849 - acc: 0.8164\n",
      "Epoch 58/100\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.3841 - acc: 0.8145\n",
      "Epoch 59/100\n",
      "512/512 [==============================] - 0s 46us/step - loss: 0.3854 - acc: 0.8145\n",
      "Epoch 60/100\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.3871 - acc: 0.8086\n",
      "Epoch 61/100\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.3857 - acc: 0.8047\n",
      "Epoch 62/100\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.3868 - acc: 0.8184\n",
      "Epoch 63/100\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.3865 - acc: 0.8047\n",
      "Epoch 64/100\n",
      "512/512 [==============================] - 0s 45us/step - loss: 0.3849 - acc: 0.8223\n",
      "Epoch 65/100\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.3821 - acc: 0.8145\n",
      "Epoch 66/100\n",
      "512/512 [==============================] - 0s 44us/step - loss: 0.3865 - acc: 0.8203\n",
      "Epoch 67/100\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.3830 - acc: 0.8125\n",
      "Epoch 68/100\n",
      "512/512 [==============================] - 0s 45us/step - loss: 0.3824 - acc: 0.8145\n",
      "Epoch 69/100\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.3806 - acc: 0.8145\n",
      "Epoch 70/100\n",
      "512/512 [==============================] - 0s 48us/step - loss: 0.3802 - acc: 0.8145\n",
      "Epoch 71/100\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.3795 - acc: 0.8223\n",
      "Epoch 72/100\n",
      "512/512 [==============================] - 0s 44us/step - loss: 0.3784 - acc: 0.8164\n",
      "Epoch 73/100\n",
      "512/512 [==============================] - 0s 37us/step - loss: 0.3787 - acc: 0.8164\n",
      "Epoch 74/100\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.3764 - acc: 0.8164\n",
      "Epoch 75/100\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.3789 - acc: 0.8184\n",
      "Epoch 76/100\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.3786 - acc: 0.8223\n",
      "Epoch 77/100\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.3768 - acc: 0.8242\n",
      "Epoch 78/100\n",
      "512/512 [==============================] - 0s 37us/step - loss: 0.3768 - acc: 0.8242\n",
      "Epoch 79/100\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.3747 - acc: 0.8242\n",
      "Epoch 80/100\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.3759 - acc: 0.8184\n",
      "Epoch 81/100\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.3769 - acc: 0.8301\n",
      "Epoch 82/100\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.3725 - acc: 0.8340\n",
      "Epoch 83/100\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.3737 - acc: 0.8359\n",
      "Epoch 84/100\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.3715 - acc: 0.8320\n",
      "Epoch 85/100\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.3717 - acc: 0.8262\n",
      "Epoch 86/100\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.3729 - acc: 0.8340\n",
      "Epoch 87/100\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.3702 - acc: 0.8320\n",
      "Epoch 88/100\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.3697 - acc: 0.8281\n",
      "Epoch 89/100\n",
      "512/512 [==============================] - 0s 36us/step - loss: 0.3688 - acc: 0.8301\n",
      "Epoch 90/100\n",
      "512/512 [==============================] - 0s 35us/step - loss: 0.3687 - acc: 0.8379\n",
      "Epoch 91/100\n",
      "512/512 [==============================] - 0s 36us/step - loss: 0.3709 - acc: 0.8398\n",
      "Epoch 92/100\n",
      "512/512 [==============================] - 0s 46us/step - loss: 0.3678 - acc: 0.8340\n",
      "Epoch 93/100\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.3686 - acc: 0.8301\n",
      "Epoch 94/100\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.3655 - acc: 0.8418\n",
      "Epoch 95/100\n",
      "512/512 [==============================] - 0s 46us/step - loss: 0.3683 - acc: 0.8301\n",
      "Epoch 96/100\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.3648 - acc: 0.8281\n",
      "Epoch 97/100\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.3690 - acc: 0.8320\n",
      "Epoch 98/100\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.3719 - acc: 0.8340\n",
      "Epoch 99/100\n",
      "512/512 [==============================] - 0s 54us/step - loss: 0.3666 - acc: 0.8438\n",
      "Epoch 100/100\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.3666 - acc: 0.8223\n",
      "256/256 [==============================] - 0s 1ms/step\n",
      "512/512 [==============================] - 0s 35us/step\n",
      "[CV]  batch_size=40, epochs=100, score=0.7460937518626451, total=   3.6s\n",
      "[CV] batch_size=40, epochs=100 .......................................\n",
      "Epoch 1/100\n",
      "512/512 [==============================] - 1s 2ms/step - loss: 0.6782 - acc: 0.6445\n",
      "Epoch 2/100\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.6100 - acc: 0.7559\n",
      "Epoch 3/100\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.5264 - acc: 0.7441\n",
      "Epoch 4/100\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.4908 - acc: 0.7598\n",
      "Epoch 5/100\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.4801 - acc: 0.7656\n",
      "Epoch 6/100\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.4742 - acc: 0.7695\n",
      "Epoch 7/100\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.4680 - acc: 0.7715\n",
      "Epoch 8/100\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.4673 - acc: 0.7734\n",
      "Epoch 9/100\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.4575 - acc: 0.7813\n",
      "Epoch 10/100\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.4549 - acc: 0.7754\n",
      "Epoch 11/100\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.4540 - acc: 0.7812\n",
      "Epoch 12/100\n",
      "512/512 [==============================] - 0s 37us/step - loss: 0.4532 - acc: 0.7832\n",
      "Epoch 13/100\n",
      "512/512 [==============================] - 0s 36us/step - loss: 0.4495 - acc: 0.7891\n",
      "Epoch 14/100\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.4491 - acc: 0.7852\n",
      "Epoch 15/100\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.4463 - acc: 0.7773\n",
      "Epoch 16/100\n",
      "512/512 [==============================] - 0s 44us/step - loss: 0.4440 - acc: 0.7832\n",
      "Epoch 17/100\n",
      "512/512 [==============================] - 0s 37us/step - loss: 0.4415 - acc: 0.7871\n",
      "Epoch 18/100\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.4426 - acc: 0.7754\n",
      "Epoch 19/100\n",
      "512/512 [==============================] - 0s 44us/step - loss: 0.4418 - acc: 0.7852\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 43us/step - loss: 0.4397 - acc: 0.7773\n",
      "Epoch 21/100\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.4368 - acc: 0.7852\n",
      "Epoch 22/100\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.4370 - acc: 0.7832\n",
      "Epoch 23/100\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.4352 - acc: 0.7930\n",
      "Epoch 24/100\n",
      "512/512 [==============================] - 0s 44us/step - loss: 0.4342 - acc: 0.7871\n",
      "Epoch 25/100\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.4355 - acc: 0.7773\n",
      "Epoch 26/100\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.4385 - acc: 0.7813\n",
      "Epoch 27/100\n",
      "512/512 [==============================] - 0s 45us/step - loss: 0.4347 - acc: 0.7891\n",
      "Epoch 28/100\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.4320 - acc: 0.7891\n",
      "Epoch 29/100\n",
      "512/512 [==============================] - 0s 44us/step - loss: 0.4319 - acc: 0.7852\n",
      "Epoch 30/100\n",
      "512/512 [==============================] - 0s 44us/step - loss: 0.4308 - acc: 0.7891\n",
      "Epoch 31/100\n",
      "512/512 [==============================] - 0s 37us/step - loss: 0.4316 - acc: 0.7832\n",
      "Epoch 32/100\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.4312 - acc: 0.7930\n",
      "Epoch 33/100\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.4304 - acc: 0.7949\n",
      "Epoch 34/100\n",
      "512/512 [==============================] - ETA: 0s - loss: 0.5512 - acc: 0.800 - 0s 43us/step - loss: 0.4321 - acc: 0.7930\n",
      "Epoch 35/100\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.4300 - acc: 0.7949\n",
      "Epoch 36/100\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.4331 - acc: 0.7969\n",
      "Epoch 37/100\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.4281 - acc: 0.8008\n",
      "Epoch 38/100\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.4257 - acc: 0.7969\n",
      "Epoch 39/100\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.4267 - acc: 0.7969\n",
      "Epoch 40/100\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.4268 - acc: 0.8047\n",
      "Epoch 41/100\n",
      "512/512 [==============================] - 0s 46us/step - loss: 0.4278 - acc: 0.7988\n",
      "Epoch 42/100\n",
      "512/512 [==============================] - 0s 46us/step - loss: 0.4209 - acc: 0.8066\n",
      "Epoch 43/100\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.4239 - acc: 0.7910\n",
      "Epoch 44/100\n",
      "512/512 [==============================] - 0s 46us/step - loss: 0.4222 - acc: 0.7910\n",
      "Epoch 45/100\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.4211 - acc: 0.7969\n",
      "Epoch 46/100\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.4223 - acc: 0.8027\n",
      "Epoch 47/100\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.4238 - acc: 0.8125\n",
      "Epoch 48/100\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.4250 - acc: 0.7910\n",
      "Epoch 49/100\n",
      "512/512 [==============================] - 0s 48us/step - loss: 0.4260 - acc: 0.7910\n",
      "Epoch 50/100\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.4276 - acc: 0.7949\n",
      "Epoch 51/100\n",
      "512/512 [==============================] - 0s 45us/step - loss: 0.4221 - acc: 0.8125\n",
      "Epoch 52/100\n",
      "512/512 [==============================] - 0s 45us/step - loss: 0.4193 - acc: 0.8086\n",
      "Epoch 53/100\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.4211 - acc: 0.8047\n",
      "Epoch 54/100\n",
      "512/512 [==============================] - 0s 36us/step - loss: 0.4151 - acc: 0.8086\n",
      "Epoch 55/100\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.4161 - acc: 0.8105\n",
      "Epoch 56/100\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.4161 - acc: 0.8086\n",
      "Epoch 57/100\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.4152 - acc: 0.8066\n",
      "Epoch 58/100\n",
      "512/512 [==============================] - 0s 50us/step - loss: 0.4134 - acc: 0.8105\n",
      "Epoch 59/100\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.4169 - acc: 0.7969\n",
      "Epoch 60/100\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.4164 - acc: 0.8125\n",
      "Epoch 61/100\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.4179 - acc: 0.8105\n",
      "Epoch 62/100\n",
      "512/512 [==============================] - 0s 44us/step - loss: 0.4126 - acc: 0.8047\n",
      "Epoch 63/100\n",
      "512/512 [==============================] - 0s 44us/step - loss: 0.4134 - acc: 0.8105\n",
      "Epoch 64/100\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.4135 - acc: 0.8047\n",
      "Epoch 65/100\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.4114 - acc: 0.8086\n",
      "Epoch 66/100\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.4131 - acc: 0.8066\n",
      "Epoch 67/100\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.4150 - acc: 0.8086\n",
      "Epoch 68/100\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.4144 - acc: 0.8164\n",
      "Epoch 69/100\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.4083 - acc: 0.8125\n",
      "Epoch 70/100\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.4086 - acc: 0.8145\n",
      "Epoch 71/100\n",
      "512/512 [==============================] - 0s 37us/step - loss: 0.4066 - acc: 0.8242\n",
      "Epoch 72/100\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.4098 - acc: 0.8184\n",
      "Epoch 73/100\n",
      "512/512 [==============================] - 0s 44us/step - loss: 0.4059 - acc: 0.8145\n",
      "Epoch 74/100\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.4052 - acc: 0.8184\n",
      "Epoch 75/100\n",
      "512/512 [==============================] - 0s 37us/step - loss: 0.4093 - acc: 0.8145\n",
      "Epoch 76/100\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.4028 - acc: 0.8164\n",
      "Epoch 77/100\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.4044 - acc: 0.8164\n",
      "Epoch 78/100\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.4043 - acc: 0.8125\n",
      "Epoch 79/100\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.4038 - acc: 0.8262\n",
      "Epoch 80/100\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.4102 - acc: 0.8125\n",
      "Epoch 81/100\n",
      "512/512 [==============================] - 0s 44us/step - loss: 0.3984 - acc: 0.8164\n",
      "Epoch 82/100\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.3989 - acc: 0.8125\n",
      "Epoch 83/100\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.3973 - acc: 0.8145\n",
      "Epoch 84/100\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.3982 - acc: 0.8145\n",
      "Epoch 85/100\n",
      "512/512 [==============================] - 0s 48us/step - loss: 0.3930 - acc: 0.8262\n",
      "Epoch 86/100\n",
      "512/512 [==============================] - 0s 36us/step - loss: 0.3955 - acc: 0.8242\n",
      "Epoch 87/100\n",
      "512/512 [==============================] - 0s 37us/step - loss: 0.3931 - acc: 0.8262\n",
      "Epoch 88/100\n",
      "512/512 [==============================] - 0s 36us/step - loss: 0.3957 - acc: 0.8262\n",
      "Epoch 89/100\n",
      "512/512 [==============================] - 0s 36us/step - loss: 0.3947 - acc: 0.8281\n",
      "Epoch 90/100\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.3919 - acc: 0.8320\n",
      "Epoch 91/100\n",
      "512/512 [==============================] - 0s 37us/step - loss: 0.3961 - acc: 0.8203\n",
      "Epoch 92/100\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.3932 - acc: 0.8281\n",
      "Epoch 93/100\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.3875 - acc: 0.8242\n",
      "Epoch 94/100\n",
      "512/512 [==============================] - 0s 37us/step - loss: 0.3879 - acc: 0.8379\n",
      "Epoch 95/100\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.3907 - acc: 0.8301\n",
      "Epoch 96/100\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.3864 - acc: 0.8320\n",
      "Epoch 97/100\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.3825 - acc: 0.8418\n",
      "Epoch 98/100\n",
      "512/512 [==============================] - 0s 36us/step - loss: 0.3893 - acc: 0.8320\n",
      "Epoch 99/100\n",
      "512/512 [==============================] - 0s 37us/step - loss: 0.3932 - acc: 0.8164\n",
      "Epoch 100/100\n",
      "512/512 [==============================] - 0s 37us/step - loss: 0.3866 - acc: 0.8281\n",
      "256/256 [==============================] - 0s 1ms/step\n",
      "512/512 [==============================] - 0s 29us/step\n",
      "[CV]  batch_size=40, epochs=100, score=0.7812500018626451, total=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.6330 - acc: 0.7435\n",
      "Epoch 2/10\n",
      "768/768 [==============================] - 0s 51us/step - loss: 0.4966 - acc: 0.7682\n",
      "Epoch 3/10\n",
      "768/768 [==============================] - 0s 48us/step - loss: 0.4696 - acc: 0.7682\n",
      "Epoch 4/10\n",
      "768/768 [==============================] - 0s 44us/step - loss: 0.4648 - acc: 0.7721\n",
      "Epoch 5/10\n",
      "768/768 [==============================] - 0s 43us/step - loss: 0.4607 - acc: 0.7747\n",
      "Epoch 6/10\n",
      "768/768 [==============================] - 0s 41us/step - loss: 0.4576 - acc: 0.7669\n",
      "Epoch 7/10\n",
      "768/768 [==============================] - 0s 41us/step - loss: 0.4590 - acc: 0.7708\n",
      "Epoch 8/10\n",
      "768/768 [==============================] - 0s 43us/step - loss: 0.4544 - acc: 0.7682\n",
      "Epoch 9/10\n",
      "768/768 [==============================] - 0s 50us/step - loss: 0.4541 - acc: 0.7643\n",
      "Epoch 10/10\n",
      "768/768 [==============================] - 0s 46us/step - loss: 0.4556 - acc: 0.7617\n",
      "Best: 0.7708333364377419, using {'batch_size': 40, 'epochs': 10}\n",
      "0.7656250003104409 (0.01991804234180557) with: {'batch_size': 10, 'epochs': 10}\n",
      "0.7513020815482984 (0.03226435368447651) with: {'batch_size': 10, 'epochs': 50}\n",
      "0.7395833320915699 (0.030977538778141474) with: {'batch_size': 10, 'epochs': 100}\n",
      "0.759114583954215 (0.024773827647127402) with: {'batch_size': 20, 'epochs': 10}\n",
      "0.7513020836437742 (0.023938519821528097) with: {'batch_size': 20, 'epochs': 50}\n",
      "0.760416665735344 (0.02050523215035881) with: {'batch_size': 20, 'epochs': 100}\n",
      "0.7708333364377419 (0.026748234153778718) with: {'batch_size': 40, 'epochs': 10}\n",
      "0.7526041672875484 (0.023509732794493955) with: {'batch_size': 40, 'epochs': 50}\n",
      "0.7369791666666666 (0.0403855816790688) with: {'batch_size': 40, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "#Do a grid search for the optimal batch size and number of epochs\n",
    "\n",
    "# create the model\n",
    "model = KerasClassifier(build_fn = create_model, verbose = 1)\n",
    "\n",
    "# define the grid search parameters\n",
    "batch_size = [10, 20, 40]\n",
    "epochs = [10, 50, 100]\n",
    "\n",
    "#batch_size = [10]\n",
    "#epochs = [10]\n",
    "\n",
    "# make a dictionary of the grid search parameters\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "# build and fit the GridSearchCV\n",
    "grid = GridSearchCV(estimator = model, param_grid = param_grid, cv = KFold(random_state=seed), verbose = 10)\n",
    "grid_results = grid.fit(X_standardized, y_full)\n",
    "\n",
    "# summarize the results\n",
    "print(\"Best: {0}, using {1}\".format(grid_results.best_score_, grid_results.best_params_))\n",
    "means = grid_results.cv_results_['mean_test_score']\n",
    "stds = grid_results.cv_results_['std_test_score']\n",
    "params = grid_results.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print('{0} ({1}) with: {2}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV] dropout_rate=0.0, learn_rate=0.001 ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learn_rate=0.001, score=0.7343750046566129, total=   5.7s\n",
      "[CV] dropout_rate=0.0, learn_rate=0.001 ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learn_rate=0.001, score=0.7460937388241291, total=   5.8s\n",
      "[CV] dropout_rate=0.0, learn_rate=0.001 ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   11.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learn_rate=0.001, score=0.8007812509313226, total=   5.9s\n",
      "[CV] dropout_rate=0.0, learn_rate=0.01 ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   17.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learn_rate=0.01, score=0.7265624962747097, total=   5.7s\n",
      "[CV] dropout_rate=0.0, learn_rate=0.01 ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   23.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learn_rate=0.01, score=0.7187500009313226, total=   6.0s\n",
      "[CV] dropout_rate=0.0, learn_rate=0.01 ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   29.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learn_rate=0.01, score=0.7929687555879354, total=   6.0s\n",
      "[CV] dropout_rate=0.0, learn_rate=0.1 ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   35.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learn_rate=0.1, score=0.7265625, total=   6.2s\n",
      "[CV] dropout_rate=0.0, learn_rate=0.1 ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   41.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learn_rate=0.1, score=0.7226562472060323, total=   6.3s\n",
      "[CV] dropout_rate=0.0, learn_rate=0.1 ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   47.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learn_rate=0.1, score=0.7695312537252903, total=   6.1s\n",
      "[CV] dropout_rate=0.1, learn_rate=0.001 ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   53.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.1, learn_rate=0.001, score=0.7109375, total=   6.8s\n",
      "[CV] dropout_rate=0.1, learn_rate=0.001 ..............................\n",
      "[CV]  dropout_rate=0.1, learn_rate=0.001, score=0.7460937425494194, total=   6.6s\n",
      "[CV] dropout_rate=0.1, learn_rate=0.001 ..............................\n",
      "[CV]  dropout_rate=0.1, learn_rate=0.001, score=0.8007812518626451, total=   6.8s\n",
      "[CV] dropout_rate=0.1, learn_rate=0.01 ...............................\n",
      "[CV]  dropout_rate=0.1, learn_rate=0.01, score=0.734375, total=   6.8s\n",
      "[CV] dropout_rate=0.1, learn_rate=0.01 ...............................\n",
      "[CV]  dropout_rate=0.1, learn_rate=0.01, score=0.7460937472060323, total=   6.8s\n",
      "[CV] dropout_rate=0.1, learn_rate=0.01 ...............................\n",
      "[CV]  dropout_rate=0.1, learn_rate=0.01, score=0.8046874981373549, total=   7.0s\n",
      "[CV] dropout_rate=0.1, learn_rate=0.1 ................................\n",
      "[CV]  dropout_rate=0.1, learn_rate=0.1, score=0.7617187546566129, total=   7.3s\n",
      "[CV] dropout_rate=0.1, learn_rate=0.1 ................................\n",
      "[CV]  dropout_rate=0.1, learn_rate=0.1, score=0.7265625037252903, total=   7.1s\n",
      "[CV] dropout_rate=0.1, learn_rate=0.1 ................................\n",
      "[CV]  dropout_rate=0.1, learn_rate=0.1, score=0.7148437537252903, total=   7.3s\n",
      "[CV] dropout_rate=0.2, learn_rate=0.001 ..............................\n",
      "[CV]  dropout_rate=0.2, learn_rate=0.001, score=0.7304687397554517, total=   7.2s\n",
      "[CV] dropout_rate=0.2, learn_rate=0.001 ..............................\n",
      "[CV]  dropout_rate=0.2, learn_rate=0.001, score=0.7382812406867743, total=   7.3s\n",
      "[CV] dropout_rate=0.2, learn_rate=0.001 ..............................\n",
      "[CV]  dropout_rate=0.2, learn_rate=0.001, score=0.8007812518626451, total=   7.4s\n",
      "[CV] dropout_rate=0.2, learn_rate=0.01 ...............................\n",
      "[CV]  dropout_rate=0.2, learn_rate=0.01, score=0.7421875, total=   7.5s\n",
      "[CV] dropout_rate=0.2, learn_rate=0.01 ...............................\n",
      "[CV]  dropout_rate=0.2, learn_rate=0.01, score=0.7031249948777258, total=   7.5s\n",
      "[CV] dropout_rate=0.2, learn_rate=0.01 ...............................\n",
      "[CV]  dropout_rate=0.2, learn_rate=0.01, score=0.7851562574505806, total=   7.7s\n",
      "[CV] dropout_rate=0.2, learn_rate=0.1 ................................\n",
      "[CV]  dropout_rate=0.2, learn_rate=0.1, score=0.73046875, total=   7.6s\n",
      "[CV] dropout_rate=0.2, learn_rate=0.1 ................................\n",
      "[CV]  dropout_rate=0.2, learn_rate=0.1, score=0.73828125, total=   8.1s\n",
      "[CV] dropout_rate=0.2, learn_rate=0.1 ................................\n",
      "[CV]  dropout_rate=0.2, learn_rate=0.1, score=0.7734375093132257, total=   7.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  3.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.7617187484477957, using {'dropout_rate': 0.1, 'learn_rate': 0.01}\n",
      "0.7604166648040215 (0.02894024927954672) with: {'dropout_rate': 0.0, 'learn_rate': 0.001}\n",
      "0.7460937509313226 (0.03329873187816337) with: {'dropout_rate': 0.0, 'learn_rate': 0.01}\n",
      "0.7395833336437742 (0.021236338991286484) with: {'dropout_rate': 0.0, 'learn_rate': 0.1}\n",
      "0.7526041648040215 (0.036966328242866754) with: {'dropout_rate': 0.1, 'learn_rate': 0.001}\n",
      "0.7617187484477957 (0.03075784286359837) with: {'dropout_rate': 0.1, 'learn_rate': 0.01}\n",
      "0.7343750040357312 (0.019918045401149047) with: {'dropout_rate': 0.1, 'learn_rate': 0.1}\n",
      "0.7565104107682904 (0.03146627105438127) with: {'dropout_rate': 0.2, 'learn_rate': 0.001}\n",
      "0.7434895841094354 (0.033501776839397576) with: {'dropout_rate': 0.2, 'learn_rate': 0.01}\n",
      "0.7473958364377419 (0.018688415907147447) with: {'dropout_rate': 0.2, 'learn_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# Do a grid search for learning rate and dropout rate\n",
    "\n",
    "from keras.layers import Dropout\n",
    "\n",
    "# Define a random seed\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Start defining the model\n",
    "def create_model(learn_rate, dropout_rate):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim = 8, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(4, input_dim = 8, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # compile the model\n",
    "    adam = Adam(lr = learn_rate)\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = adam, metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "# create the model\n",
    "model = KerasClassifier(build_fn = create_model, epochs = 100, batch_size = 20, verbose = 0)\n",
    "\n",
    "# define the grid search parameters\n",
    "learn_rate = [0.001, 0.01, 0.1]\n",
    "dropout_rate = [0.0, 0.1, 0.2]\n",
    "\n",
    "#learn_rate = [0.001]\n",
    "#dropout_rate = [ 0.2]\n",
    "\n",
    "# make a dictionary of the grid search parameters\n",
    "param_grid = dict(learn_rate=learn_rate, dropout_rate=dropout_rate)\n",
    "\n",
    "# build and fit the GridSearchCV\n",
    "grid = GridSearchCV(estimator = model, param_grid = param_grid, cv = KFold(random_state=seed), verbose = 10)\n",
    "grid_results = grid.fit(X_standardized, y_full)\n",
    "\n",
    "# summarize the results\n",
    "print(\"Best: {0}, using {1}\".format(grid_results.best_score_, grid_results.best_params_))\n",
    "means = grid_results.cv_results_['mean_test_score']\n",
    "stds = grid_results.cv_results_['std_test_score']\n",
    "params = grid_results.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print('{0} ({1}) with: {2}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[CV] activation=softmax, init=uniform ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=softmax, init=uniform, score=0.7382812453433871, total=   7.7s\n",
      "[CV] activation=softmax, init=uniform ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=softmax, init=uniform, score=0.718749986961484, total=   7.6s\n",
      "[CV] activation=softmax, init=uniform ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   15.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=softmax, init=uniform, score=0.800781256519258, total=   7.8s\n",
      "[CV] activation=softmax, init=normal .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   23.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=softmax, init=normal, score=0.726562493480742, total=   7.8s\n",
      "[CV] activation=softmax, init=normal .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   31.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=softmax, init=normal, score=0.7304687397554517, total=   7.7s\n",
      "[CV] activation=softmax, init=normal .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   38.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=softmax, init=normal, score=0.7929687546566129, total=   8.0s\n",
      "[CV] activation=softmax, init=zero ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   46.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=softmax, init=zero, score=0.6171874995343387, total=   7.8s\n",
      "[CV] activation=softmax, init=zero ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   54.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=softmax, init=zero, score=0.6601562472060323, total=   8.1s\n",
      "[CV] activation=softmax, init=zero ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  1.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=softmax, init=zero, score=0.6757812490686774, total=   8.0s\n",
      "[CV] activation=relu, init=uniform ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  1.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=relu, init=uniform, score=0.7421875018626451, total=   7.9s\n",
      "[CV] activation=relu, init=uniform ...................................\n",
      "[CV]  activation=relu, init=uniform, score=0.742187486961484, total=   8.1s\n",
      "[CV] activation=relu, init=uniform ...................................\n",
      "[CV]  activation=relu, init=uniform, score=0.7968750102445483, total=   8.6s\n",
      "[CV] activation=relu, init=normal ....................................\n",
      "[CV]  activation=relu, init=normal, score=0.7226562518626451, total=   8.1s\n",
      "[CV] activation=relu, init=normal ....................................\n",
      "[CV]  activation=relu, init=normal, score=0.7617187416180968, total=   8.2s\n",
      "[CV] activation=relu, init=normal ....................................\n",
      "[CV]  activation=relu, init=normal, score=0.7851562490686774, total=   8.5s\n",
      "[CV] activation=relu, init=zero ......................................\n",
      "[CV]  activation=relu, init=zero, score=0.6171874995343387, total=   8.6s\n",
      "[CV] activation=relu, init=zero ......................................\n",
      "[CV]  activation=relu, init=zero, score=0.6601562472060323, total=   8.6s\n",
      "[CV] activation=relu, init=zero ......................................\n",
      "[CV]  activation=relu, init=zero, score=0.6757812490686774, total=   8.7s\n",
      "[CV] activation=tanh, init=uniform ...................................\n",
      "[CV]  activation=tanh, init=uniform, score=0.7578124953433871, total=   8.6s\n",
      "[CV] activation=tanh, init=uniform ...................................\n",
      "[CV]  activation=tanh, init=uniform, score=0.7539062490686774, total=   8.6s\n",
      "[CV] activation=tanh, init=uniform ...................................\n",
      "[CV]  activation=tanh, init=uniform, score=0.800781256519258, total=   8.8s\n",
      "[CV] activation=tanh, init=normal ....................................\n",
      "[CV]  activation=tanh, init=normal, score=0.7617187462747097, total=   8.7s\n",
      "[CV] activation=tanh, init=normal ....................................\n",
      "[CV]  activation=tanh, init=normal, score=0.749999993480742, total=   8.9s\n",
      "[CV] activation=tanh, init=normal ....................................\n",
      "[CV]  activation=tanh, init=normal, score=0.800781256519258, total=   8.9s\n",
      "[CV] activation=tanh, init=zero ......................................\n",
      "[CV]  activation=tanh, init=zero, score=0.6171874995343387, total=   8.8s\n",
      "[CV] activation=tanh, init=zero ......................................\n",
      "[CV]  activation=tanh, init=zero, score=0.6601562472060323, total=   9.0s\n",
      "[CV] activation=tanh, init=zero ......................................\n",
      "[CV]  activation=tanh, init=zero, score=0.6757812490686774, total=   9.0s\n",
      "[CV] activation=linear, init=uniform .................................\n",
      "[CV]  activation=linear, init=uniform, score=0.7578124953433871, total=   9.0s\n",
      "[CV] activation=linear, init=uniform .................................\n",
      "[CV]  activation=linear, init=uniform, score=0.7304687481373549, total=   9.3s\n",
      "[CV] activation=linear, init=uniform .................................\n",
      "[CV]  activation=linear, init=uniform, score=0.7968750009313226, total=   9.7s\n",
      "[CV] activation=linear, init=normal ..................................\n",
      "[CV]  activation=linear, init=normal, score=0.7578124953433871, total=   9.2s\n",
      "[CV] activation=linear, init=normal ..................................\n",
      "[CV]  activation=linear, init=normal, score=0.7343749990686774, total=   9.1s\n",
      "[CV] activation=linear, init=normal ..................................\n",
      "[CV]  activation=linear, init=normal, score=0.7968750009313226, total=   9.4s\n",
      "[CV] activation=linear, init=zero ....................................\n",
      "[CV]  activation=linear, init=zero, score=0.6171874995343387, total=   9.4s\n",
      "[CV] activation=linear, init=zero ....................................\n",
      "[CV]  activation=linear, init=zero, score=0.6601562472060323, total=   9.6s\n",
      "[CV] activation=linear, init=zero ....................................\n",
      "[CV]  activation=linear, init=zero, score=0.6757812490686774, total=   9.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:  5.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.7708333336437742, using {'activation': 'tanh', 'init': 'uniform'}\n",
      "0.7526041629413763 (0.034987062110673046) with: {'activation': 'softmax', 'init': 'uniform'}\n",
      "0.7499999959642688 (0.030425322322700638) with: {'activation': 'softmax', 'init': 'normal'}\n",
      "0.6510416652696828 (0.024773824547009632) with: {'activation': 'softmax', 'init': 'zero'}\n",
      "0.7604166663562258 (0.025779942194264688) with: {'activation': 'relu', 'init': 'uniform'}\n",
      "0.7565104141831398 (0.025779933006000424) with: {'activation': 'relu', 'init': 'normal'}\n",
      "0.6510416652696828 (0.024773824547009632) with: {'activation': 'relu', 'init': 'zero'}\n",
      "0.7708333336437742 (0.021236340761481117) with: {'activation': 'tanh', 'init': 'uniform'}\n",
      "0.7708333320915699 (0.02171007331334805) with: {'activation': 'tanh', 'init': 'normal'}\n",
      "0.6510416652696828 (0.024773824547009632) with: {'activation': 'tanh', 'init': 'zero'}\n",
      "0.7617187481373549 (0.02725058666893702) with: {'activation': 'linear', 'init': 'uniform'}\n",
      "0.763020831781129 (0.025779935796974542) with: {'activation': 'linear', 'init': 'normal'}\n",
      "0.6510416652696828 (0.024773824547009632) with: {'activation': 'linear', 'init': 'zero'}\n"
     ]
    }
   ],
   "source": [
    "# Do a grid search to optimize kernel initialization and activation functions\n",
    "# import necessary packages\n",
    "\n",
    "# Define a random seed\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Start defining the model\n",
    "def create_model(activation, init):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim = 8, kernel_initializer= init, activation= activation))\n",
    "    model.add(Dense(4, input_dim = 8, kernel_initializer= init, activation= activation))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # compile the model\n",
    "    adam = Adam(lr = 0.001)\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = adam, metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "# create the model\n",
    "model = KerasClassifier(build_fn = create_model, epochs = 100, batch_size = 20, verbose = 0)\n",
    "\n",
    "# define the grid search parameters\n",
    "activation = ['softmax', 'relu', 'tanh', 'linear']\n",
    "init = ['uniform', 'normal', 'zero']\n",
    "\n",
    "# make a dictionary of the grid search parameters\n",
    "param_grid = dict(activation = activation, init = init)\n",
    "\n",
    "# build and fit the GridSearchCV\n",
    "grid = GridSearchCV(estimator = model, param_grid = param_grid, cv = KFold(random_state=seed), verbose = 10)\n",
    "grid_results = grid.fit(X_standardized, y_full)\n",
    "\n",
    "# summarize the results\n",
    "print(\"Best: {0}, using {1}\".format(grid_results.best_score_, grid_results.best_params_))\n",
    "means = grid_results.cv_results_['mean_test_score']\n",
    "stds = grid_results.cv_results_['std_test_score']\n",
    "params = grid_results.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print('{0} ({1}) with: {2}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV] neuron1=4, neuron2=2 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... neuron1=4, neuron2=2, score=0.7578124953433871, total=   9.6s\n",
      "[CV] neuron1=4, neuron2=2 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    9.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... neuron1=4, neuron2=2, score=0.7343749990686774, total=   9.6s\n",
      "[CV] neuron1=4, neuron2=2 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   19.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... neuron1=4, neuron2=2, score=0.7968750009313226, total=   9.8s\n",
      "[CV] neuron1=4, neuron2=4 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   29.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... neuron1=4, neuron2=4, score=0.7617187462747097, total=   9.8s\n",
      "[CV] neuron1=4, neuron2=4 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   39.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... neuron1=4, neuron2=4, score=0.7343749990686774, total=   9.9s\n",
      "[CV] neuron1=4, neuron2=4 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   48.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... neuron1=4, neuron2=4, score=0.7968750009313226, total=   9.9s\n",
      "[CV] neuron1=4, neuron2=8 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   58.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... neuron1=4, neuron2=8, score=0.7578124953433871, total=  10.2s\n",
      "[CV] neuron1=4, neuron2=8 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  1.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... neuron1=4, neuron2=8, score=0.7343749990686774, total=  10.1s\n",
      "[CV] neuron1=4, neuron2=8 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  1.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... neuron1=4, neuron2=8, score=0.7968750009313226, total=  10.1s\n",
      "[CV] neuron1=8, neuron2=2 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  1.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... neuron1=8, neuron2=2, score=0.7617187462747097, total=  10.3s\n",
      "[CV] neuron1=8, neuron2=2 ............................................\n",
      "[CV] ... neuron1=8, neuron2=2, score=0.7343749990686774, total=  10.3s\n",
      "[CV] neuron1=8, neuron2=2 ............................................\n",
      "[CV] ... neuron1=8, neuron2=2, score=0.7968750009313226, total=  10.3s\n",
      "[CV] neuron1=8, neuron2=4 ............................................\n",
      "[CV] ... neuron1=8, neuron2=4, score=0.7617187462747097, total=  10.4s\n",
      "[CV] neuron1=8, neuron2=4 ............................................\n",
      "[CV] ... neuron1=8, neuron2=4, score=0.7343749990686774, total=  11.0s\n",
      "[CV] neuron1=8, neuron2=4 ............................................\n",
      "[CV] ... neuron1=8, neuron2=4, score=0.7968750009313226, total=  10.6s\n",
      "[CV] neuron1=8, neuron2=8 ............................................\n",
      "[CV] ... neuron1=8, neuron2=8, score=0.7617187462747097, total=  10.7s\n",
      "[CV] neuron1=8, neuron2=8 ............................................\n",
      "[CV] ........... neuron1=8, neuron2=8, score=0.73828125, total=  10.5s\n",
      "[CV] neuron1=8, neuron2=8 ............................................\n",
      "[CV] ... neuron1=8, neuron2=8, score=0.7968750009313226, total=  10.6s\n",
      "[CV] neuron1=16, neuron2=2 ...........................................\n",
      "[CV] .. neuron1=16, neuron2=2, score=0.7617187462747097, total=  10.9s\n",
      "[CV] neuron1=16, neuron2=2 ...........................................\n",
      "[CV] .. neuron1=16, neuron2=2, score=0.7343749990686774, total=  10.9s\n",
      "[CV] neuron1=16, neuron2=2 ...........................................\n",
      "[CV] .. neuron1=16, neuron2=2, score=0.7968750009313226, total=  11.0s\n",
      "[CV] neuron1=16, neuron2=4 ...........................................\n",
      "[CV] .. neuron1=16, neuron2=4, score=0.7617187462747097, total=  11.0s\n",
      "[CV] neuron1=16, neuron2=4 ...........................................\n",
      "[CV] .. neuron1=16, neuron2=4, score=0.7343749990686774, total=  11.0s\n",
      "[CV] neuron1=16, neuron2=4 ...........................................\n",
      "[CV] .......... neuron1=16, neuron2=4, score=0.79296875, total=  11.1s\n",
      "[CV] neuron1=16, neuron2=8 ...........................................\n",
      "[CV] .. neuron1=16, neuron2=8, score=0.7617187462747097, total=  11.2s\n",
      "[CV] neuron1=16, neuron2=8 ...........................................\n",
      "[CV] .. neuron1=16, neuron2=8, score=0.7304687481373549, total=  11.1s\n",
      "[CV] neuron1=16, neuron2=8 ...........................................\n",
      "[CV] .. neuron1=16, neuron2=8, score=0.8007812518626451, total=  11.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  4.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.7656249990686774, using {'neuron1': 8, 'neuron2': 8}\n",
      "0.763020831781129 (0.025779935796974542) with: {'neuron1': 4, 'neuron2': 2}\n",
      "0.7643229154249033 (0.025581879406196575) with: {'neuron1': 4, 'neuron2': 4}\n",
      "0.763020831781129 (0.025779935796974542) with: {'neuron1': 4, 'neuron2': 8}\n",
      "0.7643229154249033 (0.025581879406196575) with: {'neuron1': 8, 'neuron2': 2}\n",
      "0.7643229154249033 (0.025581879406196575) with: {'neuron1': 8, 'neuron2': 4}\n",
      "0.7656249990686774 (0.024079742803419527) with: {'neuron1': 8, 'neuron2': 8}\n",
      "0.7643229154249033 (0.025581879406196575) with: {'neuron1': 16, 'neuron2': 2}\n",
      "0.763020831781129 (0.023938511260449297) with: {'neuron1': 16, 'neuron2': 4}\n",
      "0.7643229154249033 (0.028763962612406234) with: {'neuron1': 16, 'neuron2': 8}\n"
     ]
    }
   ],
   "source": [
    "# Do a grid search to find the optimal number of neurons in each hidden layer\n",
    "\n",
    "# Define a random seed\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Start defining the model\n",
    "def create_model(neuron1, neuron2):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neuron1, input_dim = 8, kernel_initializer= 'uniform', activation= 'linear'))\n",
    "    model.add(Dense(neuron2, input_dim = neuron1, kernel_initializer= 'uniform', activation= 'linear'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # compile the model\n",
    "    adam = Adam(lr = 0.001)\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = adam, metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "# create the model\n",
    "model = KerasClassifier(build_fn = create_model, epochs = 100, batch_size = 20, verbose = 0)\n",
    "\n",
    "# define the grid search parameters\n",
    "neuron1 = [4, 8, 16]\n",
    "neuron2 = [2, 4, 8]\n",
    "\n",
    "# make a dictionary of the grid search parameters\n",
    "param_grid = dict(neuron1 = neuron1, neuron2 = neuron2)\n",
    "\n",
    "# build and fit the GridSearchCV\n",
    "grid = GridSearchCV(estimator = model, param_grid = param_grid, cv = KFold(random_state=seed), refit = True, verbose = 10)\n",
    "grid_results = grid.fit(X_standardized, y_full)\n",
    "\n",
    "# summarize the results\n",
    "print(\"Best: {0}, using {1}\".format(grid_results.best_score_, grid_results.best_params_))\n",
    "means = grid_results.cv_results_['mean_test_score']\n",
    "stds = grid_results.cv_results_['std_test_score']\n",
    "params = grid_results.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print('{0} ({1}) with: {2}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate predictions with optimal hyperparameters\n",
    "y_pred = grid.predict(X_standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7747395833333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.88      0.84       500\n",
      "           1       0.72      0.58      0.64       268\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       768\n",
      "   macro avg       0.76      0.73      0.74       768\n",
      "weighted avg       0.77      0.77      0.77       768\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate a classification report\n",
    "print(accuracy_score(y_full, y_pred))\n",
    "print(classification_report(y_full, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
